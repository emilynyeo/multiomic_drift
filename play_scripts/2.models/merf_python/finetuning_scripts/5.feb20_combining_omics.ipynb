{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from merf import MERF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools \n",
    "sns.set_context(\"poster\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (11,8)\n",
    "from merf.merf import MERF\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from merf.viz import plot_merf_training_stats\n",
    "\n",
    "current_dir = os.getcwd() # Get the current working directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from em_utils import *\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/5.combined\"\n",
    "df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/5.combined\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in prior DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta / clinical\n",
    "clin_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim2/merf_ready/\"\n",
    "test_long = pd.read_csv(os.path.join(clin_dir, 'test_clinical_no_na.csv'))  \n",
    "train_long = pd.read_csv(os.path.join(clin_dir, 'train_clinical_no_na.csv'))  \n",
    "full_long = pd.read_csv(os.path.join(clin_dir, 'full_train_clinical.csv'))  \n",
    "raw_train = pd.read_csv(os.path.join(clin_dir, 'raw__train_clinical.csv'))  \n",
    "raw_test = pd.read_csv(os.path.join(clin_dir, 'raw_test_clinical.csv'))\n",
    "\n",
    "print(\"---------- Read metadata ----------\")\n",
    "m1_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim2\"\n",
    "#met_test = read_data(m1_dir, \"long_a2_test_samples_standard_clinical_feb20.csv\")\n",
    "#met_train = read_data(m1_dir, \"long_a2_train_samples_standard_clinical_feb20.csv\")\n",
    "met_test = read_data(m1_dir, \"long_a2_test_samples_extra_clinical_feb20.csv\")\n",
    "met_train = read_data(m1_dir, \"long_a2_train_samples_extra_clinical_feb20.csv\")\n",
    "#met_full = read_data(m1_dir, \"a2_meta_Transformed_standard_clinical.csv\")\n",
    "#met_full_raw = read_data(m1_dir, \"a2_meta_not_Transformed_standard_clinical.csv\")\n",
    "\n",
    "# Genetic \n",
    "gen_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/genetic/\"\n",
    "gen_test = pd.read_csv(os.path.join(gen_dir, 'genetic_risk_testing.csv'))  \n",
    "gen_train = pd.read_csv(os.path.join(gen_dir, 'genetic_risk_training.csv')) \n",
    "\n",
    "# Taxa\n",
    "tax_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim2_transformed/genus/\"\n",
    "test_tax_no_na = pd.read_csv(os.path.join(tax_dir, 'aim2_clr_testing_feb20.csv'))\n",
    "train_tax_no_na = pd.read_csv(os.path.join(tax_dir, 'aim2_clr_training_feb20.csv'))\n",
    "#full_train_tax = pd.read_csv(os.path.join(tax_dir, 'full_train_tax.csv'))\n",
    "#full_test_tax = pd.read_csv(os.path.join(tax_dir, 'full_test_tax.csv'))\n",
    "\n",
    "# Functional\n",
    "func_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/functional/aim2/\"\n",
    "test_func_no_na = pd.read_csv(os.path.join(func_dir, 'all_clr_testing_feb20.csv'))  # Read test_tax_no_na\n",
    "train_func_no_na = pd.read_csv(os.path.join(func_dir, 'all_clr_training_feb20.csv'))  # Read train_tax_no_na\n",
    "#full_train_func = pd.read_csv(os.path.join(func_dir, 'full_train_functional.csv'))  # Read full_train_tax\n",
    "#full_test_func = pd.read_csv(os.path.join(func_dir, 'full_test_functional.csv'))\n",
    "\n",
    "# Micom fluxes\n",
    "micom_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/micom/aim2/\"\n",
    "test_micom_no_na = pd.read_csv(os.path.join(micom_dir, 'flux_all_testing_feb20.csv'))  # Read in test_micom_no_na\n",
    "train_micom_no_na = pd.read_csv(os.path.join(micom_dir, 'flux_all_training_feb20.csv'))  # Read in train_micom_no_na\n",
    "#full_train_micom = pd.read_csv(os.path.join(micom_dir, 'full_train_micom.csv'))  # Read in full_train_micom\n",
    "#full_test_micom = pd.read_csv(os.path.join(micom_dir, 'full_test_micom.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"meta test = \", met_train.shape)\n",
    "print(\"Meta tst columns\", met_train.columns.to_list())\n",
    "\n",
    "print(\"meta train shape = \", met_test.shape)\n",
    "print(\"Meta train df columns\", met_test.columns.to_list())\n",
    "\n",
    "print(\"genetic df shape = \", gen_train.shape)\n",
    "print(\"Genetic df columns\", gen_train.columns.to_list())\n",
    "print(\"Taxa df shape = \", train_tax_no_na.shape)\n",
    "print(\"Taxa df columns\", train_tax_no_na.columns.to_list())\n",
    "print(\"Functional df shape = \", train_func_no_na.shape)\n",
    "print(\"Functional df columns\", train_func_no_na.columns.to_list())\n",
    "print(\"Micom df shape = \", train_micom_no_na.shape)\n",
    "print(\"Micom df columns\", train_micom_no_na.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"meta subject_id values:\", met_train['subject_id'])\n",
    "print(\"meta time values:\", met_train['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"genetic subject_id values:\", gen_train['subject_id'])\n",
    "print(\"unnamed column in the gennetic data: \", gen_train['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"taxa all_samples values:\", train_tax_no_na['all_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"functional all_samples values:\", train_func_no_na['all_samples'])\n",
    "print(\"functional time values:\", train_func_no_na['time'])\n",
    "print(\"functional SampleID values:\", train_func_no_na['SampleID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Micom all_samples values:\", train_micom_no_na['all_samples'])\n",
    "print(\"Micom time values:\", train_micom_no_na['time'])\n",
    "print(\"Micom sample_id values:\", train_micom_no_na['sample_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Micom and Functional data\n",
    "\n",
    "Micom all_samples column matches Functional Sample.ID\n",
    "##### For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert data types for merging\n",
    "train_micom_no_na['sample_id'] = train_micom_no_na['sample_id'].astype(str)  # Convert to string\n",
    "train_func_no_na['SampleID'] = train_func_no_na['SampleID'].astype(str)  # Ensure SampleID is string\n",
    "\n",
    "print(\"Micom sample_id values:\", train_micom_no_na['sample_id'])\n",
    "print(\"Functional SampleID values:\", train_func_no_na['SampleID']) \n",
    "\n",
    "# Count the number of matching rows between 'sample_id' and 'SampleID'\n",
    "matching_rows_count = train_micom_no_na['sample_id'].isin(train_func_no_na['SampleID']).sum()\n",
    "print(\"Number of matching rows between Micom sample_id and Functional SampleID:\", matching_rows_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64 samples are in the pathway dataset that are not in the micom dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge Micom and Functional data\n",
    "merged_micom_func = pd.merge(train_micom_no_na, train_func_no_na, \n",
    "                     left_on='sample_id', right_on='SampleID', \n",
    "                     how='inner')\n",
    "print(\"Merged micom_func shape: \", merged_micom_func.shape)\n",
    "print(\"Merged micom_func columns: \", merged_micom_func.columns.to_list())\n",
    "print(\"Merged micom_func id: \", merged_micom_func['sample_id'])\n",
    "print(\"Merged micom_func all_samples: \", merged_micom_func['all_samples_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert data types for merging\n",
    "test_micom_no_na['sample_id'] = test_micom_no_na['sample_id'].astype(str)  # Convert to string\n",
    "test_func_no_na['SampleID'] = test_func_no_na['SampleID'].astype(str)  # Ensure SampleID is string\n",
    "\n",
    "print(\"Micom sample_id values:\", test_micom_no_na['sample_id'])\n",
    "print(\"Functional SampleID values:\", test_func_no_na['SampleID']) \n",
    "\n",
    "# Count the number of matching rows between 'sample_id' and 'SampleID'\n",
    "matching_rows_count = test_micom_no_na['sample_id'].isin(test_func_no_na['SampleID']).sum()\n",
    "print(\"Number of matching rows between Micom sample_id and Functional SampleID:\", matching_rows_count)\n",
    "\n",
    "### Merge Micom and Functional data for testing\n",
    "test_merged_micom_func = pd.merge(test_micom_no_na, test_func_no_na, \n",
    "                     left_on='sample_id', right_on='SampleID', \n",
    "                     how='inner')\n",
    "print(\"Merged micom_func shape: \", test_merged_micom_func.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 samples in functional id test set is not in micom test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Micom and Functional data with Taxa data \n",
    "\n",
    "Using all_samples and time somehow\n",
    "\n",
    "For training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge merged_micom_func with taxa_train\n",
    "\n",
    "micom_func_tax = pd.merge(merged_micom_func, train_tax_no_na, \n",
    "                         left_on=['all_samples_y', 'time_y'], \n",
    "                         right_on=['all_samples', 'time'], \n",
    "                         how='inner')\n",
    "\n",
    "print(\"Final merged shape: \", micom_func_tax.shape)\n",
    "print(\"Micom, taxa and functional df sample_id: \", micom_func_tax['sample_id'])\n",
    "print(\"Micom, taxa and functional df all_sampls: \", micom_func_tax['all_samples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "299 all sample variables (duplicates included)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testig: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_micom_func_tax = pd.merge(test_merged_micom_func, test_tax_no_na, \n",
    "                         left_on=['all_samples_y', 'time_y'], \n",
    "                         right_on=['all_samples', 'time'], \n",
    "                         how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final merged columns: \", test_micom_func_tax.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge genetic data \n",
    "for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subject_id column by modifying sample_id\n",
    "micom_func_tax['subject_id'] = micom_func_tax['sample_id'].str.split('.').str[0]  # Remove '.' and following characters\n",
    "print(\"Subject_id column to match that of genetic data: \", micom_func_tax['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gen_train columns: \", gen_train.columns.to_list())\n",
    "gen_train = gen_train[['subject_id', 'bmi_prs']]\n",
    "print(\"gen train subject_id: \", gen_train['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(micom_func_tax, \n",
    "                       gen_train, \n",
    "                       on='subject_id', \n",
    "                       how='left')\n",
    "\n",
    "print(\"Merged data shape: \", merged_data.shape)\n",
    "print(\"Merged data columns: \", merged_data.columns.to_list())\n",
    "# Count unique subject_id values\n",
    "unique_subject_ids_gen = gen_train['subject_id'].nunique()\n",
    "print(\"Number of unique subject_id values in merged: \", unique_subject_ids_gen)\n",
    "\n",
    "unique_subject_ids_count = merged_data['subject_id'].nunique()\n",
    "print(\"Number of unique subject_id values in merged: \", unique_subject_ids_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subject_ids from both DataFrames\n",
    "gen_train_subject_ids = set(gen_train['subject_id'])\n",
    "meta_train_subject_ids = set(train_long['subject_id'])\n",
    "micom_func_tax_subject_ids = set(micom_func_tax['subject_id'])\n",
    "\n",
    "# Find subject_ids in meta not in genetic data\n",
    "subject_ids_in_meta_not_in_gen = meta_train_subject_ids - gen_train_subject_ids\n",
    "print(\"Subject IDs in gen_train but not in micom_func_tax:\", subject_ids_in_meta_not_in_gen)\n",
    "\n",
    "subject_ids_in_meta_not_in_merged = meta_train_subject_ids - micom_func_tax_subject_ids\n",
    "print(\"Subject IDs in meta but not in micom_func_tax:\", subject_ids_in_meta_not_in_merged)\n",
    "\n",
    "# Find subject_ids in gen_train but not in micom_func_tax\n",
    "subject_ids_in_gen_not_in_micom = gen_train_subject_ids - micom_func_tax_subject_ids\n",
    "print(\"Subject IDs in gen_train but not in micom_func_tax:\", subject_ids_in_gen_not_in_micom)\n",
    "\n",
    "# Find subject_ids in micom_func_tax but not in gen_train\n",
    "subject_ids_in_micom_not_in_gen = micom_func_tax_subject_ids - gen_train_subject_ids\n",
    "print(\"Subject IDs in micom_func_tax but not in gen_train:\", subject_ids_in_micom_not_in_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gen_test columns: \", gen_test.columns.to_list())\n",
    "gen_test = gen_test[['subject_id', 'bmi_prs']]\n",
    "print(\"gen train subject_id: \", gen_test['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subject_id column by modifying sample_id\n",
    "test_micom_func_tax['subject_id'] = test_micom_func_tax['sample_id'].str.split('.').str[0]  # Remove '.' and following characters\n",
    "print(\"Subject_id column to match that of genetic data: \", test_micom_func_tax['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_data = pd.merge(test_micom_func_tax, \n",
    "                       gen_test, \n",
    "                       on='subject_id', \n",
    "                       how='left')\n",
    "\n",
    "print(\"Merged data shape: \", test_merged_data.shape)\n",
    "print(\"Merged data columns: \", test_merged_data.columns.to_list())\n",
    "# Count unique subject_id values\n",
    "unique_subject_ids_gen = gen_test['subject_id'].nunique()\n",
    "print(\"Number of unique subject_id values in merged: \", unique_subject_ids_gen)\n",
    "\n",
    "unique_subject_ids_count = test_merged_data['subject_id'].nunique()\n",
    "print(\"Number of unique subject_id values in merged: \", unique_subject_ids_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge meta data to other omics \n",
    "\n",
    "for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meta train columns: \", met_train.columns.to_list())\n",
    "print(\"Meta train subject_id column: \", met_train['subject_id'])\n",
    "print(\"test_micom_func_tax subject_id column: \", merged_data['subject_id'])\n",
    "\n",
    "merged_data[\"time\"] = merged_data[\"time\"].astype(int)\n",
    "met_train[\"time\"] = met_train[\"time\"].astype(int)\n",
    "print(\"test_micom_func_tax time column: \", merged_data['time'])\n",
    "print(\"met_train time column: \", met_train['time'])\n",
    "\n",
    "# Count matching subject_id values\n",
    "matching_subjects = merged_data['subject_id'].isin(met_train['subject_id']).sum()\n",
    "print(\"Number of matching subject_id values:\", matching_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all = pd.merge(met_train, merged_data, \n",
    "                         left_on=['subject_id', 'time'], \n",
    "                         right_on=['subject_id', 'time'], \n",
    "                         how='inner',\n",
    "                         suffixes=('_train_long', '_merged_data'))\n",
    "\n",
    "print(\"Merged all shape: \", merged_all.shape)\n",
    "print(\"Merged all columns: \", merged_all.columns.to_list())\n",
    "# Count unique subject_id values\n",
    "unique_subject_ids_all = merged_all['subject_id'].nunique()\n",
    "print(\"Number of unique subject_id values in merged_all: \", unique_subject_ids_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_all = pd.merge(met_test, \n",
    "                       test_merged_data, \n",
    "                        left_on=['subject_id', 'time'], \n",
    "                        right_on=['subject_id', 'time'],\n",
    "                        how='inner',\n",
    "                        suffixes=('_test_long', '_merged_data'))  # Specify suffixes for duplicate columns\n",
    "\n",
    "print(\"Merged all shape: \", test_merged_all.shape)\n",
    "print(\"Merged all columns: \", test_merged_all.columns.to_list())\n",
    "# Count unique subject_id values\n",
    "unique_subject_ids_all = test_merged_all['subject_id'].nunique()\n",
    "print(\"Number of unique subject_id values in merged_all: \", unique_subject_ids_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specified columns from merged_all\n",
    "merged_all = merged_all.drop(columns=['Unnamed: 0_train_long', 'Unnamed: 0_x', 'all_samples_x', 'time_x', \n",
    "                                       'Unnamed: 0_y', 'SampleID_x', 'SampleID_y'])\n",
    "\n",
    "# Remove specified columns from test_merged_all\n",
    "test_merged_all = test_merged_all.drop(columns=['Unnamed: 0_test_long', 'Unnamed: 0_x', 'all_samples_x', 'time_x', \n",
    "                                               'Unnamed: 0_y', 'SampleID_x', 'SampleID_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save combined training and testing files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_all.to_csv(os.path.join(df_dir, 'feb20_training_merged_all_omics_raw_meta.csv'), index=False)  # Save merged_all to CSV\n",
    "#test_merged_all.to_csv(os.path.join(df_dir, 'feb20_test_merged_all_omics_raw_meta.csv'), index=False)  # Save test_merged_all to CSV\n",
    "\n",
    "merged_all.to_csv(os.path.join(df_dir, 'feb20_training_merged_all_omics_extra_meta.csv'), index=False)  # Save merged_all to CSV\n",
    "test_merged_all.to_csv(os.path.join(df_dir, 'feb20_test_merged_all_omics_extra_meta.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
