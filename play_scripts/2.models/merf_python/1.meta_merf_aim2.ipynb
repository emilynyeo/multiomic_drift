{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from merf import MERF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (11,8)\n",
    "from merf.merf import MERF\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from merf.viz import plot_merf_training_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set thresholds\n",
    "max_iter = 200\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "mse_rf = []\n",
    "mse_rfplus = []\n",
    "mse_mrf = []\n",
    "mse_mrf_id = []\n",
    "mse_mrf_id_both = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots\"\n",
    "df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_data(directory, filename):\n",
    "    \"\"\"Read CSV data from specified directory and filename\"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "print(\"---------- Read metadata ----------\")\n",
    "m1_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim2\"\n",
    "test = read_data(m1_dir, \"a2_test_samples_standard_clinical.csv\")\n",
    "train = read_data(m1_dir, \"a2_train_samples_standard_clinical.csv\")\n",
    "full = read_data(m1_dir, \"a2_meta_Transformed_standard_clinical.csv\")\n",
    "full_raw = read_data(m1_dir, \"a2_meta_not_Transformed_standard_clinical.csv\")\n",
    "\n",
    "print(full_raw.columns.to_list() == train.columns.to_list())\n",
    "print(train.columns.to_list() == test.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make long format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process metadata to long format\n",
    "def make_long(wide_data):\n",
    "    \"\"\"\n",
    "    Converts a wide-format DataFrame into a long-format DataFrame,\n",
    "    aligning with the structure produced by the R transformation.\n",
    "    \n",
    "    Args:\n",
    "        wide_data (pd.DataFrame): Input DataFrame in wide format.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame in long format.\n",
    "    \"\"\"\n",
    "    # Extract measurement columns and id columns\n",
    "    id_vars = [col for col in wide_data.columns if not re.search(r'_(BL|6m|12m)$', col)]\n",
    "    value_vars = [col for col in wide_data.columns if re.search(r'_(BL|6m|12m)$', col)]\n",
    "\n",
    "    # Melt the DataFrame to long format\n",
    "    long_data = wide_data.melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name=\"measurement_time\",\n",
    "        value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    # Extract measurement type and time from the variable name\n",
    "    long_data[['measurement_type', 'time']] = long_data['measurement_time'].str.extract(r'(.+)_(BL|6m|12m)')\n",
    "\n",
    "    # Map time values\n",
    "    time_mapping = {'BL': 0, '6m': 6, '12m': 12}\n",
    "    long_data['time'] = long_data['time'].map(time_mapping)\n",
    "\n",
    "    # Drop the original melted column\n",
    "    long_data = long_data.drop(columns=['measurement_time'])\n",
    "\n",
    "    # Pivot the data back to wide format for measurements\n",
    "    long_data = long_data.pivot_table(\n",
    "        index=id_vars + ['time'], \n",
    "        columns='measurement_type', \n",
    "        values='value'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Flatten the column MultiIndex from pivot_table\n",
    "    long_data.columns.name = None\n",
    "    long_data.columns = [str(col) for col in long_data.columns]\n",
    "\n",
    "    return long_data\n",
    "\n",
    "\n",
    "# Apply the function to each meta dataset\n",
    "print(\"---------- Convert metadata to long format ----------\")\n",
    "full_long = make_long(full_raw)\n",
    "full_long['x_t'] = full_long['subject_id'].astype(str) + '.' + full_long['time'].astype(str)\n",
    "\n",
    "train_long = make_long(train)\n",
    "train_long['x_t'] = train_long['subject_id'].astype(str) + '.' + train_long['time'].astype(str)\n",
    "\n",
    "test_long = make_long(test)\n",
    "test_long['x_t'] = test_long['subject_id'].astype(str) + '.' + test_long['time'].astype(str)\n",
    "\n",
    "print(\"train data outcome_BMI_fnl values:\", train_long['outcome_BMI_fnl'])\n",
    "print(\"Full columns after transformation:\", full_long.columns.to_list())\n",
    "print(\"Test columns after transformation:\", test_long.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define columns to drop if necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 0', 'cohort_number', 'record_id', 'x_t']\n",
    "# Drop columns only if they exist in the DataFrame (since some may not be present after merge)\n",
    "full_long = full_long.drop([col for col in columns_to_drop if col in full.columns], axis=1)\n",
    "train_long = train_long.drop([col for col in columns_to_drop if col in train_long.columns], axis=1)\n",
    "test_long = test_long.drop([col for col in columns_to_drop if col in test_long.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the final columns\n",
    "print(\"Final columns after drop:\", full_long.columns.to_list())\n",
    "print(\"Final test columns after drop:\", test_long.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA \n",
    "test_long = test_long.dropna()\n",
    "train_long = train_long.dropna()\n",
    "full_long = full_long.dropna()\n",
    "raw_train = full_long[full_long['subject_id'].isin(train_long['subject_id'])]\n",
    "raw_test = full_long[full_long['subject_id'].isin(test_long['subject_id'])]\n",
    "\n",
    "print(\"raw_train shape = \", raw_train.shape)\n",
    "print(\"raw_test shape = \", raw_test.shape)\n",
    "\n",
    "print(\"test_long shape = \", test_long.shape)\n",
    "print(\"train_long shape = \", train_long.shape)\n",
    "\n",
    "print(\"---------- raw train and tax ----------\")\n",
    "print(\"full shape = \", full_long.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = raw_train\n",
    "X = train_set.drop(['outcome_BMI_fnl', 'subject_id'], axis=1)\n",
    "#X = X.drop(columns=['Unnamed: 0_tax', 'x_t'], errors='ignore')\n",
    "Y = train_set[['outcome_BMI_fnl']]\n",
    "Y = Y['outcome_BMI_fnl'].to_numpy() # Convert Y to numeric array\n",
    "clusters_train = train_set['subject_id'].to_numpy() # Get ID variables\n",
    "Z = np.ones((train_set.shape[0], 1)) # Create random effects matrix with ones\n",
    "time = train_set['time'].astype(float).to_numpy() # Get time values as numeric array \n",
    "\n",
    "# Check the final columns\n",
    "print(\"Final columns after drop:\", X.columns.to_list())\n",
    "# print(\"X values:\", train_long['outcome_BMI_fnl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = raw_test\n",
    "X_new = test_set.drop(['outcome_BMI_fnl', 'subject_id'], axis=1)\n",
    "\n",
    "X_new = X_new[X.columns]  # Reorder and select columns to match training set\n",
    "X_new = X_new.astype(X.dtypes)  # Ensure data types match\n",
    "# X_new = X_new.drop(columns=['Unnamed: 0_tax', 'x_t'], errors='ignore')\n",
    "# X_new = X_new.drop(columns=['Unnamed: 0', 'character_id', 'timepoint'], errors='ignore')\n",
    "\n",
    "Y_new = test_set['outcome_BMI_fnl'].to_numpy()  # Convert Y to numeric array\n",
    "clusters_new = pd.Series(test_set['subject_id'])  # Convert to pandas Series\n",
    "# Create random effects matrix with ones\n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "time_new = test_set['time'].astype(float).to_numpy()  # Convert time values to numeric array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- RUN MERF BASICðŸŒ± ----------\")\n",
    "#mrf = MERF()\n",
    "mrf = MERF(fixed_effects_model=RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score= True),\n",
    "        gll_early_stop_threshold=None,\n",
    "        max_iterations=max_iter)\n",
    "\n",
    "mrf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_merf_training_stats(mrf)\n",
    "plt.savefig(os.path.join(output_dir, '1.clinical/merf_raw_metrics.png'), dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the fitted model\n",
    "X_new = X_new.drop(columns=['x_t'], errors='ignore')\n",
    "y_hat_new = mrf.predict(X_new, Z_new, clusters_new)\n",
    "print(y_hat_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between actual and predicted values: 0.2777\n",
      "Root Mean Squared Error: 5.1978\n",
      "R-squared Score: -0.0847\n",
      " % Variation: 65.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print RMSE and R-squared\n",
    "rmse = np.sqrt(np.mean((Y_new - y_hat_new)**2))\n",
    "correlation = np.corrcoef(Y_new, y_hat_new)[0,1]\n",
    "print(f\"Correlation between actual and predicted values: {correlation:.4f}\")\n",
    "r2 = 1 - (np.sum((Y_new - y_hat_new)**2) / np.sum((Y_new - np.mean(Y_new))**2))\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "forest = mrf.trained_fe_model\n",
    "oob = str(round(forest.oob_score_*100, 1))  # percent variation\n",
    "print(f\" % Variation in training set: {oob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the components of forest to a csv file\n",
    "# Convert forest.__dict__ to a DataFrame with a single row\n",
    "df = pd.DataFrame.from_dict(forest.__dict__, orient='index')\n",
    "df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs\"\n",
    "df.to_csv(os.path.join(df_dir,'merf_basic_raw_forest_components.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R - squared version for mixed model\n",
    "PREV maybe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names and importances\n",
    "feature_names = forest.feature_names_in_\n",
    "feature_importances = forest.feature_importances_\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "plt.bar(np.array(feature_names)[sorted_indices], np.array(feature_importances)[sorted_indices], color='skyblue')\n",
    "plt.xlabel('Feature Names')\n",
    "plt.ylabel('Feature Importances')\n",
    "plt.title('Feature Importances')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, '1.clinical/merf_raw_feature_importances.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~ Metrics Generation ~~~~~~~~~~ #\n",
    "# compute the ptev and prev\n",
    "sigma_fixed = self.m * sigma_g\n",
    "ptev = 100 * ((sigma_fixed ** 2 + self.sigma_b ** 2) / (sigma_fixed ** 2 + self.sigma_b ** 2 + self.sigma_e ** 2))\n",
    "prev = 100 * (self.sigma_b ** 2 / (sigma_fixed ** 2 + self.sigma_b ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of predicted vs actual values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Y_new, y_hat_new, alpha=0.5)\n",
    "plt.xlabel('Actual BMI Values')\n",
    "plt.ylabel('Clinical Predicted Values')\n",
    "plt.title('Predicted vs Actual Values with Trend Line')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(Y_new, y_hat_new, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(Y_new, p(Y_new), \"r--\", alpha=0.8)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Save plot as PNG and PDF\n",
    "plt.savefig(os.path.join(output_dir, '1.clinical/clinical_predicted_vs_actual.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- RUN MERF with participant RE ðŸŒ±ðŸŒ¸ ----------\")\n",
    " # Mixed Effects Random Forest Training with participant RE and time cluster \n",
    "train_set = train_long \n",
    "X_train = train_set.drop(['outcome_BMI_fnl', 'subject_id', 'time'], axis=1).to_numpy()\n",
    "Z_train = np.array((np.ones(len(train_set)), train_set['subject_id'].apply(lambda s: int(s[-3:])))).T\n",
    "clusters_train = pd.Series(train_set['subject_id'].apply(lambda s: int(s[-3:]))).astype(float)  # Convert to float if necessary\n",
    "y_train = train_set[['outcome_BMI_fnl']]\n",
    "y_train = y_train['outcome_BMI_fnl'].to_numpy() # Convert Y to numeric array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dimensions of X_train: {X_train.shape}\")\n",
    "print(f\"Dimensions of Z_train: {Z_train.shape}\")\n",
    "print(f\"Number of unique inputs for clusters_train: {clusters_train.nunique()}\")\n",
    "print(f\"Inputs to clusters_train: {clusters_train}\")\n",
    "print(f\"Dimensions of y_train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrf_id_fe = MERF(fixed_effects_model=RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score= True),\n",
    "        gll_early_stop_threshold=None,\n",
    "        max_iterations=max_iter)\n",
    "mrf_id_fe.fit(X_train, Z_train, clusters_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = mrf_id_fe.trained_fe_model\n",
    "oob = str(round(forest.oob_score_*100, 1))  # percent variation\n",
    "# Save all the components of forest to a csv file\n",
    "# Convert forest.__dict__ to a DataFrame with a single row\n",
    "df = pd.DataFrame.from_dict(forest.__dict__, orient='index')\n",
    "df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs\"\n",
    "df.to_csv(os.path.join(df_dir,'merf_id_forest_components.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Mixed Effects Random Forests (MERF), the Generalized Log-Likelihood (GLL) is used to evaluate the quality of the model at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_merf_training_stats(mrf_id_fe, num_clusters_to_plot=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test MERF if RE on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data (repeat similar steps)\n",
    "test_set = test_long\n",
    "X_test = test_set.drop(['outcome_BMI_fnl', 'subject_id', 'time'], axis=1).to_numpy()\n",
    "Z_test = np.array((np.ones(len(test_set)), test_set['subject_id'].apply(lambda s: int(s[-3:])))).T\n",
    "clusters_test = pd.Series(test_set['subject_id'].apply(lambda s: int(s[-3:]))).astype(float)  # Convert to float if necessary\n",
    "\n",
    "# Make predictions\n",
    "yhat_merf = mrf_id_fe.predict(X_test, Z_test, clusters_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mse_merf = np.sqrt(np.mean((test_set['outcome_BMI_fnl'] - yhat_merf)**2))\n",
    "mae_merf = np.mean(np.abs(test_set['outcome_BMI_fnl'] - yhat_merf))\n",
    "r2_merf = np.corrcoef(test_set['outcome_BMI_fnl'], yhat_merf)[0, 1]**2\n",
    "\n",
    "print(f\"Mean Squared Error (MERF): {mse_merf}\")\n",
    "print(f\"Mean Absolute Error (MERF): {mae_merf}\")\n",
    "print(f\"R-Squared (MERF): {r2_merf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- RUN MERF with time RE ðŸŒ±ðŸŒ¸ðŸŒ±ðŸŒ¸ ----------\")\n",
    "train_set = train_long \n",
    "mrf_time_fe = MERF(fixed_effects_model=RandomForestRegressor(n_estimators=100, n_jobs=-1),\n",
    "        gll_early_stop_threshold=None,\n",
    "        max_iterations=max_iter)\n",
    "\n",
    "# Extract fixed effects (X), outcome (y), and clusters (subject_id)\n",
    "X_train = train_set.drop(['outcome_BMI_fnl', 'subject_id', 'time'], axis=1).to_numpy()\n",
    "y_train = train_set['outcome_BMI_fnl'].to_numpy()\n",
    "clusters_train = train_set['subject_id']\n",
    "# Create random effects design matrix (Z) : intercept + time random effects\n",
    "Z_train = np.column_stack((np.ones(len(train_set)), train_set['time']))\n",
    "# Z_train = np.array((np.ones(len(train_set)), train_set['subject_id'].apply(lambda s: int(s[-3:])))).T\n",
    "\n",
    "print(f\"Dimensions of X_train: {X_train.shape}\")\n",
    "print(f\"Dimensions of Z_train: {Z_train.shape}\")\n",
    "print(f\"Dimensions of clusters_train: {clusters_train.shape}\")\n",
    "print(f\"Dimensions of y_train: {y_train.shape}\")\n",
    "\n",
    "# Fit MERF model\n",
    "mrf_time_fe.fit(X_train, Z_train, clusters_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_merf_training_stats(mrf_time_fe, num_clusters_to_plot=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
