{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "Run many models looking at:\n",
    "1 - BMI and omic variables longitudinally \n",
    "2 - BMI and variable changes from BL-6m and 6m-12m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools \n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib as mpl\n",
    "from merf.merf import MERF\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from merf.viz import plot_merf_training_stats\n",
    "from joblib import dump\n",
    "sns.set_context(\"poster\")\n",
    "mpl.rcParams['figure.figsize'] = (11,8)\n",
    "\n",
    "current_dir = os.getcwd() # Get the current working directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from em_utils import *\n",
    "\n",
    "# test and train set directories for input data\n",
    "longitudinal_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/5.combined/\"\n",
    "delta_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/zachs_rerun/drift_fs/csv/all_omic_processed_data/deltas/\"\n",
    "clin_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim2/merf_ready\"\n",
    "# Where hyperparameter training results are\n",
    "delta_df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/6.two_timepoints_deltas\"\n",
    "long_df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/5.combined\"\n",
    "func_df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/3.functional\"\n",
    "taxa_long_df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/2.taxa\"\n",
    "clinical_df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/1.clinical\"\n",
    "micom_df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/4.micom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and train longitudinal files \n",
    "test_all = pd.read_csv(os.path.join(longitudinal_dir, 'test_merged_all_omics_raw_meta.csv'))  \n",
    "train_all = pd.read_csv(os.path.join(longitudinal_dir, 'training_merged_all_omics_raw_meta.csv'))  \n",
    "print(\"test long shape = \", test_all.shape)\n",
    "print(\"train long shape = \", train_all.shape)\n",
    "print(\"test longitudinal: \", test_all.columns)\n",
    "print(\"train longitudinal: \", train_all.columns)\n",
    "\n",
    "# test and train delta files \n",
    "test_delta = read_data(delta_dir, \"jan30_all_delta_test_imp_varcheck.csv\")\n",
    "train_delta = read_data(delta_dir, \"jan30_all_delta_train_imp_varcheck.csv\")\n",
    "print(\"test delta shape = \", test_delta.shape)\n",
    "print(\"train delta shape = \", train_delta.shape)\n",
    "print(\"test delta: \", test_delta.columns)\n",
    "print(\"train delta: \", train_delta.columns)\n",
    "\n",
    "# hyperparameter training files \n",
    "delta_df = pd.read_csv(os.path.join(delta_df_dir, 'jan30_2times_all_omic_deltas_BMI_remove_time_var_imputed_swapped.csv'))\n",
    "long_df = pd.read_csv(os.path.join(long_df_dir, 'jan13_params_fine_tuning_results_all_omics.csv'))\n",
    "func_df = pd.read_csv(os.path.join(func_df_dir, 'dec6_magggie_params_fine_tuning_results_raw_functional.csv'))\n",
    "taxa_df = pd.read_csv(os.path.join(taxa_long_df_dir, 'dec6_maggie_params_tuning_raw_taxa_oob.csv'))\n",
    "micom_df = pd.read_csv(os.path.join(micom_df_dir, 'dec6_maggie_params_fine_tuning_results_raw_micom.csv'))\n",
    "meta_df = pd.read_csv(os.path.join(clinical_df_dir, 'dec5_maggie_params_tuning_raw_clinical_oob.csv'))\n",
    "#meta_df = pd.read_csv('/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/1.clinical/fine_tuning_results_raw_clinical.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longitudinal BMI first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns \n",
    "train_long = train_all.drop(['Unnamed: 0_y','Unnamed: 0_x', 'Unnamed: 0_train_long', 'Unnamed: 0_merged_data',\n",
    "                    'sample_id','subject_id', 'all_samples_x', 'all_samples_y', 'record_id','SampleID',\n",
    "                    'time_x', 'time_y', 'x_t', 't', 'time', 'outcome_BMI_fnl_x', 'outcome_BMI_fnl_y', \n",
    "                    'outcome_BMI_fnl_merged_data', 'old_or_new', 'predicted_BL_BMI', \n",
    "                    'differences_BL_BMI', 'diff_BMI_quartile', 'diff_BMI_std', 'methyl_bmi_rs', 'methyl_bmi_rs_standardized'], \n",
    "                    axis=1)\n",
    "\n",
    "test_long = test_all.drop(['Unnamed: 0_y','Unnamed: 0_x', 'Unnamed: 0_test_long', 'Unnamed: 0_merged_data',\n",
    "                    'sample_id','subject_id', 'all_samples_x', 'all_samples_y', 'record_id', 'SampleID',\n",
    "                    'time_x', 'time_y', 'x_t', 't', 'time', 'outcome_BMI_fnl_x', 'outcome_BMI_fnl_y', \n",
    "                    'outcome_BMI_fnl_merged_data', 'old_or_new', 'predicted_BL_BMI', \n",
    "                    'differences_BL_BMI', 'diff_BMI_quartile', 'diff_BMI_std', 'methyl_bmi_rs', 'methyl_bmi_rs_standardized'], \n",
    "                    axis=1)\n",
    "print(\"test long shape = \", test_long.shape)\n",
    "print(\"train long shape = \", train_long.shape)\n",
    "\n",
    "test_long.rename(columns={'outcome_BMI_fnl_test_long': 'outcome_bmi_fnl'}, inplace=True)\n",
    "train_long.rename(columns={'outcome_BMI_fnl_train_long': 'outcome_bmi_fnl'}, inplace=True)\n",
    "\n",
    "print(\"test longitudinal: \", list(test_long.columns))\n",
    "print(\"train longitudinal: \", list(train_long.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the column numbers for \"proton\" and \"Carbon.dioxide\" in train_set\n",
    "proton_column = train_long.columns.get_loc(\"proton\")\n",
    "carbon_dioxide_column = train_long.columns.get_loc(\"Carbon.dioxide\")\n",
    "proton_column_test = test_long.columns.get_loc(\"proton\")\n",
    "carbon_dioxide_column_test = test_long.columns.get_loc(\"Carbon.dioxide\")\n",
    "\n",
    "# Columns to KEEP for only meta \n",
    "meta_keep = ['all_samples','outcome_bmi_fnl', 'randomized_group', 'cohort_number', 'sex', 'race', 'age', 'Glucose', 'HDL_Total_Direct_lipid', 'HOMA_IR', 'Insulin_endo', 'LDL_Calculated', 'Triglyceride_lipid']\n",
    "only_grs = ['all_samples','outcome_bmi_fnl', 'bmi_prs']\n",
    "only_taxa = ['all_samples','outcome_bmi_fnl'] + [col for col in train_long.columns if col.startswith(\"g__\")]\n",
    "only_micom = ['all_samples','outcome_bmi_fnl'] + [col for col in train_long.columns if col in train_long.columns[proton_column:carbon_dioxide_column+1]]\n",
    "# Create a set of all columns to exclude\n",
    "exclude_columns = set(meta_keep + only_grs + only_taxa + only_micom)\n",
    "only_pathway = ['all_samples', 'outcome_bmi_fnl'] + [col for col in train_long.columns if col not in exclude_columns]\n",
    "\n",
    "# Columns to KEEP for only meta + GRS\n",
    "meta_grs = ['all_samples','outcome_bmi_fnl', 'randomized_group', 'cohort_number', 'sex', 'race', 'age', 'Glucose', 'HDL_Total_Direct_lipid', 'HOMA_IR', 'Insulin_endo', 'LDL_Calculated', 'Triglyceride_lipid', 'bmi_prs']\n",
    "# Columns to KEEP for only meta + GRS + taxa\n",
    "meta_grs_taxa = meta_grs + [col for col in train_long.columns if col.startswith(\"g__\")]\n",
    "meta_grs_taxa_test = meta_grs + [col for col in test_long.columns if col.startswith(\"g__\")]\n",
    "# Columns to KEEP for only meta + GRS + taxa + pathway/functional \n",
    "meta_grs_taxa_functional = meta_grs_taxa + [col for col in train_long.columns if col not in train_long.columns[proton_column:carbon_dioxide_column+1]]\n",
    "meta_grs_taxa_functional_test = meta_grs_taxa + [col for col in test_long.columns if col not in test_long.columns[proton_column_test:carbon_dioxide_column_test+1]]\n",
    "# Columns to DROP for only GRS + taxa + pathway/functional + micom (no meta)\n",
    "all_but_meta = ['randomized_group', 'cohort_number', 'sex', 'race', 'age', 'Glucose', 'HDL_Total_Direct_lipid', 'HOMA_IR', 'Insulin_endo', 'LDL_Calculated', 'Triglyceride_lipid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Trying Meta from omic DF\n",
    "\n",
    "PTEV is the best one \n",
    "First 5 columns for the lowest mean_ptev_score:\n",
    "n_estimators         500.00\n",
    "max_depth               NaN\n",
    "min_samples_split      0.05\n",
    "max_iter               2.00\n",
    "n_splits              10.00\n",
    "Name: 20, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long[meta_keep]\n",
    "test_l = test_long[meta_keep]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/for_score_long\"\n",
    "r2_out = 'r2_only_meta_merf_bmi_long_feb10_all.png'\n",
    "feature_imp_out = 'fi_only_meta_merf_bmi_long_feb10_all.png'\n",
    "results_filename = 'merf_results_long_only_meta.csv'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#r2_run1, fi_run1 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "#                             X_new, Y_new, Z_new, clusters_new, \n",
    "#                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "r2_values, results_df = run_merf_analysis2(\n",
    "    X, Y, Z, clusters_train,\n",
    "    X_new, Y_new, Z_new, clusters_new,\n",
    "    long_df,\n",
    "    output_dir, r2_out, feature_imp_out, results_filename\n",
    ")\n",
    "\n",
    "# Print the R-squared values and the results DataFrame\n",
    "print(\"R-squared values:\", r2_values)\n",
    "print(\"Results DataFrame:\\n\", results_df)\n",
    "\n",
    "#print(\"---------- Run best MERF ðŸ§® ----------\")# Define the parameter grid list\n",
    "# param_grid_list = [\n",
    "#     {'n_estimators': 500, 'max_depth': None, \n",
    "#      'min_samples_split': 0.05, 'max_iter': 2}\n",
    "# ]\n",
    "# # Call the run_merf function with the required parameters\n",
    "# only_meta = run_merf(X, Y, Z, clusters_train,\n",
    "#                      X_new, Y_new, Z_new, clusters_new, \n",
    "#                      param_grid_list, results_name=\"only_meta_results\")\n",
    "# # View the \"only_meta\" output\n",
    "# print(\"Viewing the 'only_meta' output:\")\n",
    "# for result in only_meta:\n",
    "#     print(f\"Model Parameters: {result['params']}\")\n",
    "#     print(f\"R-squared: {result['r2']:.4f}\")\n",
    "#     print(\"Feature Importances:\")\n",
    "#     for feature, importance in zip(X.columns, result['feature_importances']):\n",
    "#         print(f\"{feature}: {importance:.4f}\")\n",
    "#     print(\"\\n\")\n",
    "# # End of Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only PRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long[only_grs]\n",
    "test_l = test_long[only_grs]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/for_score_long\"\n",
    "r2_out = 'r2_only_grs_merf_bmi_long_feb10_all.png'\n",
    "feature_imp_out = 'fi_only_grs_merf_bmi_long_feb10_all.png'\n",
    "results_filename = 'merf_results_long_meta_grs.csv'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#r2_run2, fi_run2 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "#                             X_new, Y_new, Z_new, clusters_new, \n",
    "#                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "# Call the function\n",
    "r2_values, results_df = run_merf_analysis2(\n",
    "    X, Y, Z, clusters_train,\n",
    "    X_new, Y_new, Z_new, clusters_new,\n",
    "    long_df,\n",
    "    output_dir, r2_out, feature_imp_out, results_filename\n",
    ")\n",
    "\n",
    "# Print the R-squared values and the results DataFrame\n",
    "print(\"R-squared values:\", r2_values)\n",
    "print(\"Results DataFrame:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long[only_taxa]\n",
    "test_l = test_long[only_taxa]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/for_score_long\"\n",
    "r2_out = 'r2_only_taxa_merf_bmi_long_feb10.png'\n",
    "feature_imp_out = 'fi_only_taxa_merf_bmi_long_feb10.png'\n",
    "results_filename = 'merf_results_long_only_taxa.csv'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#r2_run2, fi_run2 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "#                             X_new, Y_new, Z_new, clusters_new, \n",
    "#                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "# Call the function\n",
    "r2_values, results_df = run_merf_analysis2(\n",
    "    X, Y, Z, clusters_train,\n",
    "    X_new, Y_new, Z_new, clusters_new,\n",
    "    long_df,\n",
    "    output_dir, r2_out, feature_imp_out, results_filename\n",
    ")\n",
    "\n",
    "# Print the R-squared values and the results DataFrame\n",
    "print(\"R-squared values:\", r2_values)\n",
    "print(\"Results DataFrame:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Micom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long[only_micom]\n",
    "test_l = test_long[only_micom]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/for_score_long\"\n",
    "r2_out = 'r2_only_micom_merf_bmi_long_feb10.png'\n",
    "feature_imp_out = 'fi_only_micom_merf_bmi_long_feb10.png'\n",
    "results_filename = 'merf_results_long_only_micom.csv'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#r2_run2, fi_run2 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "#                             X_new, Y_new, Z_new, clusters_new, \n",
    "#                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "# Call the function\n",
    "r2_values, results_df = run_merf_analysis2(\n",
    "    X, Y, Z, clusters_train,\n",
    "    X_new, Y_new, Z_new, clusters_new,\n",
    "    long_df,\n",
    "    output_dir, r2_out, feature_imp_out, results_filename\n",
    ")\n",
    "\n",
    "# Print the R-squared values and the results DataFrame\n",
    "print(\"R-squared values:\", r2_values)\n",
    "print(\"Results DataFrame:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only pathway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long[only_pathway]\n",
    "test_l = test_long[only_pathway]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/for_score_long\"\n",
    "r2_out = 'r2_only_pathway_merf_bmi_long_feb10.png'\n",
    "feature_imp_out = 'fi_only_pathway_merf_bmi_long_feb10.png'\n",
    "results_filename = 'merf_results_long_only_pathway.csv'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#r2_run2, fi_run2 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "#                             X_new, Y_new, Z_new, clusters_new, \n",
    "#                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "# Call the function\n",
    "r2_values, results_df = run_merf_analysis2(\n",
    "    X, Y, Z, clusters_train,\n",
    "    X_new, Y_new, Z_new, clusters_new,\n",
    "    long_df,\n",
    "    output_dir, r2_out, feature_imp_out, results_filename\n",
    ")\n",
    "\n",
    "# Print the R-squared values and the results DataFrame\n",
    "print(\"R-squared values:\", r2_values)\n",
    "print(\"Results DataFrame:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the dataframes from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model_merf_results_long_only_pathway  \\\n",
      "0                            MSE Model   \n",
      "1                            MSE Model   \n",
      "2                            MSE Model   \n",
      "3                            MSE Model   \n",
      "4                            MSE Model   \n",
      "\n",
      "   y_hat_new_merf_results_long_only_pathway  \\\n",
      "0                                 31.691785   \n",
      "1                                 31.691785   \n",
      "2                                 31.691785   \n",
      "3                                 31.691785   \n",
      "4                                 31.691785   \n",
      "\n",
      "   R_squared_merf_results_long_only_pathway  \\\n",
      "0                                  -0.04819   \n",
      "1                                  -0.04819   \n",
      "2                                  -0.04819   \n",
      "3                                  -0.04819   \n",
      "4                                  -0.04819   \n",
      "\n",
      "  Top_15_Feature_Importances_merf_results_long_only_pathway  Cluster  \\\n",
      "0  [{'Feature': 'TCA.cycle.VII..acetate.producers...               4   \n",
      "1  [{'Feature': 'TCA.cycle.VII..acetate.producers...               4   \n",
      "2  [{'Feature': 'TCA.cycle.VII..acetate.producers...               4   \n",
      "3  [{'Feature': 'TCA.cycle.VII..acetate.producers...               4   \n",
      "4  [{'Feature': 'TCA.cycle.VII..acetate.producers...               4   \n",
      "\n",
      "  Model_merf_results_long_only_taxa  y_hat_new_merf_results_long_only_taxa  \\\n",
      "0                         MSE Model                              31.859594   \n",
      "1                         MSE Model                              31.859594   \n",
      "2                         MSE Model                              31.859594   \n",
      "3                         MSE Model                              31.859594   \n",
      "4                         MSE Model                              31.859594   \n",
      "\n",
      "   R_squared_merf_results_long_only_taxa  \\\n",
      "0                              -0.130078   \n",
      "1                              -0.130078   \n",
      "2                              -0.130078   \n",
      "3                              -0.130078   \n",
      "4                              -0.130078   \n",
      "\n",
      "  Top_15_Feature_Importances_merf_results_long_only_taxa  \\\n",
      "0  [{'Feature': 'g__UBA1417', 'Importance': 0.290...       \n",
      "1  [{'Feature': 'g__UBA1417', 'Importance': 0.290...       \n",
      "2  [{'Feature': 'g__UBA1417', 'Importance': 0.290...       \n",
      "3  [{'Feature': 'g__UBA1417', 'Importance': 0.290...       \n",
      "4  [{'Feature': 'g__UBA1417', 'Importance': 0.290...       \n",
      "\n",
      "  Model_merf_results_long_only_micom  ...  \\\n",
      "0                          MSE Model  ...   \n",
      "1                          MSE Model  ...   \n",
      "2                          MSE Model  ...   \n",
      "3                          MSE Model  ...   \n",
      "4                          MSE Model  ...   \n",
      "\n",
      "   R_squared_merf_results_long_only_micom  \\\n",
      "0                               -0.169003   \n",
      "1                               -0.169003   \n",
      "2                               -0.169003   \n",
      "3                               -0.169003   \n",
      "4                               -0.169003   \n",
      "\n",
      "   Top_15_Feature_Importances_merf_results_long_only_micom  \\\n",
      "0  [{'Feature': 'Isochorismate', 'Importance': 0....         \n",
      "1  [{'Feature': 'Isochorismate', 'Importance': 0....         \n",
      "2  [{'Feature': 'Isochorismate', 'Importance': 0....         \n",
      "3  [{'Feature': 'Isochorismate', 'Importance': 0....         \n",
      "4  [{'Feature': 'Isochorismate', 'Importance': 0....         \n",
      "\n",
      "  Model_merf_results_long_meta_grs y_hat_new_merf_results_long_meta_grs  \\\n",
      "0                        MSE Model                            32.381971   \n",
      "1                        MSE Model                            32.381971   \n",
      "2                        MSE Model                            32.381971   \n",
      "3                        MSE Model                            32.381971   \n",
      "4                        MSE Model                            32.381971   \n",
      "\n",
      "   R_squared_merf_results_long_meta_grs  \\\n",
      "0                             -0.480552   \n",
      "1                             -0.480552   \n",
      "2                             -0.480552   \n",
      "3                             -0.480552   \n",
      "4                             -0.480552   \n",
      "\n",
      "   Top_15_Feature_Importances_merf_results_long_meta_grs  \\\n",
      "0        [{'Feature': 'bmi_prs', 'Importance': 1.0}]       \n",
      "1        [{'Feature': 'bmi_prs', 'Importance': 1.0}]       \n",
      "2        [{'Feature': 'bmi_prs', 'Importance': 1.0}]       \n",
      "3        [{'Feature': 'bmi_prs', 'Importance': 1.0}]       \n",
      "4        [{'Feature': 'bmi_prs', 'Importance': 1.0}]       \n",
      "\n",
      "  Model_merf_results_long_only_meta y_hat_new_merf_results_long_only_meta  \\\n",
      "0                         MSE Model                             29.328198   \n",
      "1                         MSE Model                             33.831435   \n",
      "2                        Prev Model                             29.245101   \n",
      "3                        Prev Model                             34.038287   \n",
      "4                        PTEV Model                             28.524371   \n",
      "\n",
      "   R_squared_merf_results_long_only_meta  \\\n",
      "0                               0.073204   \n",
      "1                               0.073204   \n",
      "2                               0.087519   \n",
      "3                               0.087519   \n",
      "4                               0.161652   \n",
      "\n",
      "   Top_15_Feature_Importances_merf_results_long_only_meta  \n",
      "0  [{'Feature': 'HOMA_IR', 'Importance': 0.644718...       \n",
      "1  [{'Feature': 'HOMA_IR', 'Importance': 0.644718...       \n",
      "2  [{'Feature': 'HOMA_IR', 'Importance': 0.635517...       \n",
      "3  [{'Feature': 'HOMA_IR', 'Importance': 0.635517...       \n",
      "4  [{'Feature': 'HOMA_IR', 'Importance': 0.467639...       \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read all CSV files into a list of DataFrames\n",
    "csv_files = glob.glob(\"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/for_score_long/*.csv\")  # Adjust the path to your CSV files\n",
    "dataframes = []\n",
    "\n",
    "for file in csv_files:\n",
    "    model_name = file.split('/')[-1].replace('.csv', '')  # Get the model name from the file name\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Step 2: Add a suffix to all columns except 'Cluster'\n",
    "    df = df.rename(columns=lambda x: f\"{x}_{model_name}\" if x != 'Cluster' else x)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Step 3: Merge all DataFrames on the 'Cluster' column\n",
    "merged_df = dataframes[0]  # Start with the first DataFrame\n",
    "\n",
    "for df in dataframes[1:]:\n",
    "    merged_df = merged_df.merge(df, on='Cluster', how='outer')  # Merge on 'Cluster'\n",
    "print(merged_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Cluster  y_hat_new_merf_results_long_only_pathway  \\\n",
      "6         4                                 31.691785   \n",
      "7         4                                 31.691785   \n",
      "14        4                                 31.691785   \n",
      "15        4                                 31.691785   \n",
      "22        4                                 31.691785   \n",
      "\n",
      "    y_hat_new_merf_results_long_only_taxa  \\\n",
      "6                               31.859594   \n",
      "7                               31.859594   \n",
      "14                              31.859594   \n",
      "15                              31.859594   \n",
      "22                              31.859594   \n",
      "\n",
      "    y_hat_new_merf_results_long_only_micom  \\\n",
      "6                                31.382381   \n",
      "7                                31.382381   \n",
      "14                               31.382381   \n",
      "15                               31.382381   \n",
      "22                               31.382381   \n",
      "\n",
      "    y_hat_new_merf_results_long_meta_grs  \\\n",
      "6                              32.381971   \n",
      "7                              32.381971   \n",
      "14                             32.381971   \n",
      "15                             32.381971   \n",
      "22                             32.386354   \n",
      "\n",
      "    y_hat_new_merf_results_long_only_meta  \n",
      "6                               29.231085  \n",
      "7                               32.902488  \n",
      "14                              29.231085  \n",
      "15                              32.902488  \n",
      "22                              29.231085  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify columns that start with \"Model\"\n",
    "model_columns = [col for col in merged_df.columns if col.startswith('Model')]\n",
    "\n",
    "# Step 2: Filter for rows that belong to the OOB model\n",
    "# Replace 'OOB' with the actual identifier used in your DataFrame to denote OOB models\n",
    "oob_df = merged_df[merged_df[model_columns].apply(lambda row: row.str.contains('OOB', na=False).any(), axis=1)]\n",
    "\n",
    "# Step 3: Select the \"Cluster\" column and columns that start with \"y_hat_new\"\n",
    "filtered_df = oob_df[['Cluster'] + [col for col in oob_df.columns if col.startswith('y_hat_new')]]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge predicted outcomes with test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_short = test_long[['all_samples', 'outcome_bmi_fnl']] \n",
    "merged_df = pd.merge(filtered_df, test_long, left_on='Cluster', right_on='all_samples', how='inner')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 trying Meta + Genetic info from omic DF\n",
    "PTEV model\n",
    "First 5 columns for the lowest mean_ptev_score:\n",
    "n_estimators         500.00\n",
    "max_depth               NaN\n",
    "min_samples_split      0.05\n",
    "max_iter               2.00\n",
    "n_splits              10.00\n",
    "Name: 20, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long[meta_grs]\n",
    "test_l = test_long[meta_grs]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/for_score_long\"\n",
    "r2_out = 'r2_meta_grs_merf_bmi_long_feb10_all.png'\n",
    "feature_imp_out = 'fi_meta_grs_merf_bmi_long_feb10_all.png'\n",
    "results_filename = 'merf_results_long_meta_grs.csv'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#r2_run2, fi_run2 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "#                             X_new, Y_new, Z_new, clusters_new, \n",
    "#                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "# Call the function\n",
    "r2_values, results_df = run_merf_analysis2(\n",
    "    X, Y, Z, clusters_train,\n",
    "    X_new, Y_new, Z_new, clusters_new,\n",
    "    long_df,\n",
    "    output_dir, r2_out, feature_imp_out, results_filename\n",
    ")\n",
    "\n",
    "# Print the R-squared values and the results DataFrame\n",
    "print(\"R-squared values:\", r2_values)\n",
    "print(\"Results DataFrame:\\n\", results_df)\n",
    "\n",
    "print(\"---------- Run best MERF ðŸ§® ----------\")# Define the parameter grid list\n",
    "# param_grid_list = [\n",
    "#     {'n_estimators': 500, 'max_depth': None, \n",
    "#      'min_samples_split': 0.05, 'max_iter': 2}\n",
    "# ]\n",
    "# # Call the run_merf function with the required parameters\n",
    "# only_meta_grs = run_merf(X, Y, Z, clusters_train,\n",
    "#                      X_new, Y_new, Z_new, clusters_new, \n",
    "#                      param_grid_list, results_name=\"only_meta_grs_results\")\n",
    "# # View the \"only_meta\" output\n",
    "# print(\"Viewing the 'only_meta' output:\")\n",
    "# for result in only_meta_grs:\n",
    "#     print(f\"Model Parameters: {result['params']}\")\n",
    "#     print(f\"R-squared: {result['r2']:.4f}\")\n",
    "#     print(\"Feature Importances:\")\n",
    "#     for feature, importance in zip(X.columns, result['feature_importances']):\n",
    "#         print(f\"{feature}: {importance:.4f}\")\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 trying Meta + Genetic + Taxa info from omic DF\n",
    "\n",
    "First 5 columns for the lowest mean_ptev_score:\n",
    "n_estimators         500.00\n",
    "max_depth               NaN\n",
    "min_samples_split      0.05\n",
    "max_iter               2.00\n",
    "n_splits              10.00\n",
    "Name: 20, dtype: float64\n",
    "\n",
    "First 5 columns for the lowest mean_ptev_score:\n",
    "n_estimators         100.00\n",
    "max_depth               NaN\n",
    "min_samples_split      0.05\n",
    "max_iter               2.00\n",
    "n_splits              10.00\n",
    "Name: 2, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long[meta_grs_taxa]\n",
    "test_l = test_long[meta_grs_taxa_test]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_meta_grs_taxa_merf_bmi_long_feb6.png'\n",
    "feature_imp_out = 'fi_meta_grs_taxa_merf_bmi_long_feb6.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  long_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "r2_run3, fi_run3 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "                             X_new, Y_new, Z_new, clusters_new, \n",
    "                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "print(\"---------- Run best MERF ðŸ§® ----------\")\n",
    "# param_grid_list = [\n",
    "#     {'n_estimators': 500, 'max_depth': None, \n",
    "#      'min_samples_split': 0.05, 'max_iter': 2}\n",
    "# ]\n",
    "# # Call the run_merf function with the required parameters\n",
    "# meta_grs_tax = run_merf(X, Y, Z, clusters_train,\n",
    "#                      X_new, Y_new, Z_new, clusters_new, \n",
    "#                      param_grid_list, results_name=\"meta_grs_tax_results\")\n",
    "# # View the \"only_meta\" output\n",
    "# print(\"Viewing the 'only_meta' output:\")\n",
    "# for result in meta_grs_tax:\n",
    "#     print(f\"Model Parameters: {result['params']}\")\n",
    "#     print(f\"R-squared: {result['r2']:.4f}\")\n",
    "#     print(\"Feature Importances:\")\n",
    "#     for feature, importance in zip(X.columns, result['feature_importances']):\n",
    "#         print(f\"{feature}: {importance:.4f}\")\n",
    "#     print(\"\\n\")\n",
    "# # End of Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 trying Meta + Genetic + Taxa + Functional info from omic DF\n",
    "\n",
    "lowest mean_ptev_score:\n",
    "n_estimators         500.00\n",
    "max_depth               NaN\n",
    "min_samples_split      0.05\n",
    "max_iter               2.00\n",
    "n_splits              10.00\n",
    "Name: 20, dtype: float64\n",
    "\n",
    "First 5 columns for the lowest mean_prev_score:\n",
    "n_estimators         500.00\n",
    "max_depth               NaN\n",
    "min_samples_split      0.15\n",
    "max_iter               2.00\n",
    "n_splits               5.00\n",
    "Name: 31, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long[meta_grs_taxa_functional]\n",
    "test_l = test_long[meta_grs_taxa_functional_test]\n",
    "# Check for duplicate column names in test_l\n",
    "duplicates_test = test_l.columns[test_l.columns.duplicated()].unique()\n",
    "duplicates_train = train_l.columns[train_l.columns.duplicated()].unique()\n",
    "# Remove duplicate columns\n",
    "test_l = test_l.loc[:, ~test_l.columns.duplicated()]\n",
    "train_l = train_l.loc[:, ~train_l.columns.duplicated()]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_meta_grs_taxa_functional_merf_bmi_long_feb6.png'\n",
    "feature_imp_out = 'fi_meta_grs_taxa_functional_merf_bmi_long_feb6.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  long_df, output_dir, r2_out, feature_imp_out)\n",
    "# Run the analysis multiple times\n",
    "r2_run4, fi_run4 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "                             X_new, Y_new, Z_new, clusters_new, \n",
    "                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "print(\"---------- Run best MERF ðŸ§® ----------\")\n",
    "param_grid_list = [\n",
    "    {'n_estimators': 500, 'max_depth': None, \n",
    "     'min_samples_split': 0.05, 'max_iter': 2}\n",
    "]\n",
    "# Call the run_merf function with the required parameters\n",
    "#meta_grs_tax_func = run_merf(X, Y, Z, clusters_train,\n",
    "#                     X_new, Y_new, Z_new, clusters_new, \n",
    "#                     param_grid_list, results_name=\"meta_grs_tax_func_results\")\n",
    "# View the \"only_meta\" output\n",
    "#print(\"Viewing the 'only_meta' output:\")\n",
    "#for result in meta_grs_tax_func:\n",
    "#    print(f\"Model Parameters: {result['params']}\")\n",
    "#    print(f\"R-squared: {result['r2']:.4f}\")\n",
    "#    print(\"Feature Importances:\")\n",
    "#    for feature, importance in zip(X.columns, result['feature_importances']):\n",
    "#        print(f\"{feature}: {importance:.4f}\")\n",
    "#    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 all but meta omic df \n",
    "\n",
    "First 5 columns for the lowest mean_mse_score:\n",
    "n_estimators         500.0\n",
    "max_depth              NaN\n",
    "min_samples_split      0.1\n",
    "max_iter              10.0\n",
    "n_splits              10.0\n",
    "Name: 29, dtype: float64\n",
    "\n",
    "First 5 columns for the highest oob_score:\n",
    "n_estimators         1000.00\n",
    "max_depth                NaN\n",
    "min_samples_split       0.05\n",
    "max_iter               10.00\n",
    "n_splits               10.00\n",
    "Name: 41, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_long.drop(all_but_meta, axis = 1)\n",
    "test_l = test_long.drop(all_but_meta, axis = 1)\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_all_but_meta_merf_bmi_long_feb6.png'\n",
    "feature_imp_out = 'fi_all_but_meta_merf_bmi_long_feb6.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  long_df, output_dir, r2_out, feature_imp_out)\n",
    "r2_run5, fi_run5 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "                             X_new, Y_new, Z_new, clusters_new, \n",
    "                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "print(\"---------- Run best MERF ðŸ§® ----------\")\n",
    "# param_grid_list = [\n",
    "#     {'n_estimators': 500, 'max_depth': None, \n",
    "#      'min_samples_split': 0.05, 'max_iter': 2}\n",
    "# ]\n",
    "# # Call the run_merf function with the required parameters\n",
    "# grs_tax_func_micom = run_merf(X, Y, Z, clusters_train,\n",
    "#                      X_new, Y_new, Z_new, clusters_new, \n",
    "#                      param_grid_list, results_name=\"grs_tax_func_micom\")\n",
    "# # View the \"only_meta\" output\n",
    "# print(\"Viewing the 'only_meta' output:\")\n",
    "# for result in grs_tax_func_micom:\n",
    "#     print(f\"Model Parameters: {result['params']}\")\n",
    "#     print(f\"R-squared: {result['r2']:.4f}\")\n",
    "#     print(\"Feature Importances:\")\n",
    "#     for feature, importance in zip(X.columns, result['feature_importances']):\n",
    "#         print(f\"{feature}: {importance:.4f}\")\n",
    "#     print(\"\\n\")\n",
    "# # End of Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 All omics \n",
    "\n",
    "First 5 columns for the lowest mean_ptev_score:\n",
    "n_estimators         500.00\n",
    "max_depth               NaN\n",
    "min_samples_split      0.05\n",
    "max_iter               2.00\n",
    "n_splits              10.00\n",
    "Name: 20, dtype: float64\n",
    "\n",
    "First 5 columns for the lowest mean_ptev_score:\n",
    "n_estimators         100.00\n",
    "max_depth               NaN\n",
    "min_samples_split      0.05\n",
    "max_iter               2.00\n",
    "n_splits              10.00\n",
    "Name: 2, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_all_omics_merf_bmi_long_feb6.png'\n",
    "feature_imp_out = 'fi_all_omics_merf_bmi_long_feb6.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_long\n",
    "X = train_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set['outcome_bmi_fnl'].to_numpy()\n",
    "clusters_train = train_set['all_samples'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_long\n",
    "X_new = test_set.drop(['outcome_bmi_fnl', 'all_samples'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['outcome_bmi_fnl'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['all_samples'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  long_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "r2_run6, fi_run6 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "                             X_new, Y_new, Z_new, clusters_new, \n",
    "                             long_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "print(\"---------- Run best MERF ðŸ§® ----------\")\n",
    "param_grid_list = [\n",
    "    {'n_estimators': 100, 'max_depth': None, \n",
    "     'min_samples_split': 0.05, 'max_iter': 2}\n",
    "]\n",
    "# Call the run_merf function with the required parameters\n",
    "# all_omic = run_merf(X, Y, Z, clusters_train,\n",
    "#                      X_new, Y_new, Z_new, clusters_new, \n",
    "#                      param_grid_list, results_name=\"grs_tax_func_micom\")\n",
    "# # View the \"only_meta\" output\n",
    "# print(\"Viewing the 'only_meta' output:\")\n",
    "# for result in all_omic:\n",
    "#     print(f\"Model Parameters: {result['params']}\")\n",
    "#     print(f\"R-squared: {result['r2']:.4f}\")\n",
    "#     print(\"Feature Importances:\")\n",
    "#     for feature, importance in zip(X.columns, result['feature_importances']):\n",
    "#         print(f\"{feature}: {importance:.4f}\")\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now looking at Delta models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test delta: \", list(test_delta.shape))\n",
    "print(\"train delta: \", list(train_delta.shape))\n",
    "print(\"test delta: \", list(test_delta.columns))\n",
    "print(\"train delta: \", list(train_delta.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the column numbers for \"proton\" and \"Carbon.dioxide\" in train_set\n",
    "proton_column = train_delta.columns.get_loc(\"proton\")\n",
    "carbon_dioxide_column = train_delta.columns.get_loc(\"Carbon.dioxide\")\n",
    "proton_column_test = test_delta.columns.get_loc(\"proton\")\n",
    "carbon_dioxide_column_test = test_delta.columns.get_loc(\"Carbon.dioxide\")\n",
    "print(\"Column number for 'proton': \", proton_column)\n",
    "print(\"Column number for 'Carbon.dioxide': \", carbon_dioxide_column)\n",
    "\n",
    "# Columns to KEEP for only meta \n",
    "meta_keep = ['subject_id','BMI', 'randomized_group', 'sex', 'race', 'age', 'HDL', 'homo_ir', 'insulin', 'LDL', 'tgcyd']\n",
    "\n",
    "# Columns to KEEP for only meta + GRS + taxa\n",
    "meta_grs_taxa = meta_keep + [col for col in train_delta.columns if col.startswith(\"g__\")]\n",
    "meta_grs_taxa_test = meta_keep + [col for col in test_delta.columns if col.startswith(\"g__\")]\n",
    "\n",
    "# Columns to KEEP for only meta + GRS + taxa + pathway/functional \n",
    "meta_grs_taxa_functional = meta_grs_taxa + [col for col in train_delta.columns if col not in train_delta.columns[proton_column:carbon_dioxide_column+1]]\n",
    "meta_grs_taxa_functional_test = meta_grs_taxa_test + [col for col in test_delta.columns if col not in test_delta.columns[proton_column_test:carbon_dioxide_column_test+1]]\n",
    "\n",
    "# Columns to DROP for only GRS + taxa + pathway/functional + micom (no meta)\n",
    "all_but_meta = ['randomized_group', 'sex', 'race', 'age', 'HDL', 'homo_ir', 'insulin', 'LDL', 'tgcyd', 'Weight', 'CRP', 'cholesterol', 'ghrelin', 'HbA1C', 'leptin', 'peptide_yy', 'range']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Only Meta Delta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing columns in train_delta\n",
    "missing_columns = [col for col in meta_keep if col not in train_delta.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(\"Missing columns in train_delta:\", missing_columns)\n",
    "else:\n",
    "    print(\"All columns in meta_keep are present in train_delta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_delta[meta_keep]\n",
    "test_l = test_delta[meta_keep]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_only_meta_merf_bmi_delta_feb7.png'\n",
    "feature_imp_out = 'fi_only_meta_merf_bmi_delta_feb7.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['BMI','subject_id'], axis=1)\n",
    "Y = train_set['BMI'].to_numpy()\n",
    "clusters_train = train_set['subject_id'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['BMI', 'subject_id'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['BMI'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['subject_id'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  meta_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "r2_delta_run1, fi_delta_run1 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "                             X_new, Y_new, Z_new, clusters_new, \n",
    "                             long_df, output_dir, r2_out, feature_imp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Ok now include meta and taxa deltas \n",
    "\n",
    "There is no change in bmi_prs so that is not included in the delta models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_delta[meta_grs_taxa]\n",
    "test_l = test_delta[meta_grs_taxa_test]\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_meta_taxa_merf_bmi_delta_feb7.png'\n",
    "feature_imp_out = 'fi_meta_taxa_merf_bmi_delta_feb7.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['BMI','subject_id'], axis=1)\n",
    "Y = train_set['BMI'].to_numpy()\n",
    "clusters_train = train_set['subject_id'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['BMI', 'subject_id'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['BMI'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['subject_id'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  meta_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "r2_delta_run2, fi_delta_run2 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "                             X_new, Y_new, Z_new, clusters_new, \n",
    "                             delta_df, output_dir, r2_out, feature_imp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Delta variables Meta + Taxa + Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_delta[meta_grs_taxa]\n",
    "test_l = test_delta[meta_grs_taxa_test]\n",
    "\n",
    "# Check for duplicate column names in train_l and test_l\n",
    "duplicates_train = train_l.columns[train_l.columns.duplicated()].unique()\n",
    "duplicates_test = test_l.columns[test_l.columns.duplicated()].unique()\n",
    "\n",
    "# Count of duplicate columns\n",
    "num_duplicates_train = len(duplicates_train)\n",
    "num_duplicates_test = len(duplicates_test)\n",
    "\n",
    "# Remove duplicate columns from train_l\n",
    "train_l = train_l.loc[:, ~train_l.columns.duplicated()]\n",
    "test_l = test_l.loc[:, ~test_l.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_delta[meta_grs_taxa_functional]\n",
    "test_l = test_delta[meta_grs_taxa_functional_test]\n",
    "\n",
    "# Check for duplicate column names in train_l and test_l\n",
    "duplicates_train = train_l.columns[train_l.columns.duplicated()].unique()\n",
    "duplicates_test = test_l.columns[test_l.columns.duplicated()].unique()\n",
    "\n",
    "# Count of duplicate columns\n",
    "num_duplicates_train = len(duplicates_train)\n",
    "num_duplicates_test = len(duplicates_test)\n",
    "\n",
    "# Remove duplicate columns from train_l\n",
    "train_l = train_l.loc[:, ~train_l.columns.duplicated()]\n",
    "test_l = test_l.loc[:, ~test_l.columns.duplicated()]\n",
    "\n",
    "print(\"Columns in train_l DataFrame:\")\n",
    "print(list(train_l.columns))  # Convert to list for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_delta[meta_grs_taxa_functional]\n",
    "test_l = test_delta[meta_grs_taxa_functional_test]\n",
    "\n",
    "# Check for duplicate column names in train_l and test_l\n",
    "duplicates_train = train_l.columns[train_l.columns.duplicated()].unique()\n",
    "duplicates_test = test_l.columns[test_l.columns.duplicated()].unique()\n",
    "\n",
    "# Count of duplicate columns\n",
    "num_duplicates_train = len(duplicates_train)\n",
    "num_duplicates_test = len(duplicates_test)\n",
    "\n",
    "# Remove duplicate columns from train_l\n",
    "train_l = train_l.loc[:, ~train_l.columns.duplicated()]\n",
    "test_l = test_l.loc[:, ~test_l.columns.duplicated()]\n",
    "\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_meta_taxa_functional_merf_bmi_delta_feb7.png'\n",
    "feature_imp_out = 'fi_meta_taxa_functional_merf_bmi_delta_feb7.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['BMI','Weight','subject_id', 'CRP', 'cholesterol', 'ghrelin', 'HbA1C', 'leptin', 'peptide_yy', 'range'], axis=1)\n",
    "Y = train_set['BMI'].to_numpy()\n",
    "clusters_train = train_set['subject_id'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['BMI', 'Weight','subject_id', 'CRP', 'cholesterol', 'ghrelin', 'HbA1C', 'leptin', 'peptide_yy', 'range'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['BMI'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['subject_id'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  meta_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "r2_delta_run3, fi_delta_run3 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "                             X_new, Y_new, Z_new, clusters_new, \n",
    "                             delta_df, output_dir, r2_out, feature_imp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 all delta omics except meta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"test longitudinal: \", list(test_l.columns))\n",
    "print(\"train longitudinal: \", list(train_l.columns))\n",
    "\n",
    "# Print duplicated column names in test_l\n",
    "duplicates_test = test_l.columns[test_l.columns.duplicated()].unique()\n",
    "print(\"Duplicated columns in test_l: \", duplicates_test)\n",
    "\n",
    "# Print duplicated column names in train_l\n",
    "duplicates_train = train_l.columns[train_l.columns.duplicated()].unique()\n",
    "print(\"Duplicated columns in train_l: \", duplicates_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train_delta.drop(all_but_meta, axis = 1)\n",
    "test_l = test_delta.drop(all_but_meta, axis = 1)\n",
    "\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_taxa_functional_micom_merf_bmi_delta_feb7.png'\n",
    "feature_imp_out = 'fi_taxa_functional_micom_merf_bmi_delta_feb7.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_l\n",
    "X = train_set.drop(['BMI','subject_id', 'range'], axis=1)\n",
    "Y = train_set['BMI'].to_numpy()\n",
    "clusters_train = train_set['subject_id'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_l\n",
    "X_new = test_set.drop(['BMI','subject_id', 'range'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['BMI'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['subject_id'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  meta_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "r2_delta_run4, fi_delta_run4 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "                             X_new, Y_new, Z_new, clusters_new, \n",
    "                             delta_df, output_dir, r2_out, feature_imp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 all delta varibles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/long_combined\"\n",
    "r2_out = 'r2_all_omic_merf_bmi_delta_feb7.png'\n",
    "feature_imp_out = 'fi_all_omic_merf_bmi_delta_feb7.png'\n",
    "\n",
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_delta\n",
    "X = train_set.drop(['BMI','Weight','subject_id', 'CRP', 'cholesterol', 'ghrelin', 'HbA1C', 'leptin', 'peptide_yy', 'range'], axis=1)\n",
    "Y = train_set['BMI'].to_numpy()\n",
    "clusters_train = train_set['subject_id'].to_numpy() \n",
    "Z = np.ones((train_set.shape[0], 1)) \n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_delta\n",
    "X_new = test_set.drop(['BMI','Weight','subject_id', 'CRP', 'cholesterol', 'ghrelin', 'HbA1C', 'leptin', 'peptide_yy', 'range'], axis=1)[X.columns].astype(X.dtypes)\n",
    "Y_new = test_set['BMI'].to_numpy()  \n",
    "clusters_new = pd.Series(test_set['subject_id'])  \n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"---------- Run MERF models ----------\")\n",
    "#run_merf_analysis(X, Y, Z, clusters_train, \n",
    "#                  X_new, Y_new, Z_new, clusters_new, \n",
    "#                  meta_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "#r2_delta_run5 = run_merf_analysis2(X, Y, Z, clusters_train,\n",
    "#                             X_new, Y_new, Z_new, clusters_new, \n",
    "#                             delta_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "r2_delta_run5, fi_delta_run5 = run_merf_analysis2(X, Y, Z, clusters_train, \n",
    "                                              X_new, Y_new, Z_new, clusters_new, \n",
    "                                              delta_df, output_dir, r2_out, feature_imp_out)\n",
    "\n",
    "# Now you can use `top_features` for plotting or further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing all models above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_r2_values1(model_names, *r2_dicts):\n",
    "    # Create a DataFrame to hold the R-squared values\n",
    "    r2_comparison_df = pd.DataFrame(r2_dicts).T\n",
    "    r2_comparison_df.columns = model_names \n",
    "    print(r2_comparison_df.head(10).columns[:10])\n",
    "    print(r2_comparison_df.head(10))\n",
    "\n",
    "    # Sort the DataFrame by R-squared values in descending order\n",
    "    r2_comparison_df = r2_comparison_df.sort_values(by=model_names, ascending=False)\n",
    "\n",
    "    # Set up the bar positions\n",
    "    num_runs = len(r2_comparison_df.columns)\n",
    "    bar_width = 0.15  # Width of each bar\n",
    "    x = np.arange(len(r2_comparison_df))  # The label locations\n",
    "\n",
    "    # Create a color map for the models\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, num_runs))\n",
    "\n",
    "    # Create bars for each model in each run\n",
    "    for i in range(num_runs):\n",
    "        plt.bar(x + i * bar_width, r2_comparison_df.iloc[:, i],  # Use plt.bar for vertical bars\n",
    "                 width=bar_width, label=model_names[i], color=colors[i])  # Use model names for labels\n",
    "\n",
    "    # Add labels, title, and custom x-axis tick labels\n",
    "    plt.ylabel('R-squared Value')  # Change to y-label\n",
    "    plt.title('R-squared Comparison of Different Runs')\n",
    "    plt.ylim(0, 0.55)  # Assuming R-squared values are between 0 and 1\n",
    "    plt.xticks(x + bar_width * (num_runs - 1) / 2, r2_comparison_df.index)  # Center the x-ticks\n",
    "    plt.legend(title='Models', loc='upper right', fontsize=10, \n",
    "               title_fontsize=10, ncol = 2, frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Only Meta', 'Meta GRS', \n",
    "               'Meta GRS Tax', 'Meta GRS Tax Func', \n",
    "               'All But Meta', 'All Omic']\n",
    "compare_r2_values1(model_names, r2_run1, r2_run2, r2_run3, r2_run4, r2_run5, r2_run6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_delta = ['Only Meta Delta',  \n",
    "               'Meta Tax Delta', 'Meta Tax Func Delta', \n",
    "               'All But Meta Delta', 'All Omic Delta']\n",
    "compare_r2_values1(model_names_delta, r2_delta_run1, r2_delta_run2, \n",
    "                   r2_delta_run3, r2_delta_run4, r2_delta_run5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_r2_values2(model_names, *r2_dicts):\n",
    "    # Create a DataFrame to hold the R-squared values\n",
    "    r2_comparison_df = pd.DataFrame(r2_dicts).T\n",
    "    r2_comparison_df.columns = model_names \n",
    "\n",
    "    # Reset index to use row names as a column\n",
    "    r2_comparison_df.reset_index(inplace=True)\n",
    "    r2_comparison_df = r2_comparison_df.melt(id_vars='index', var_name='Model', value_name='R-squared')\n",
    "\n",
    "    # Rename the 'index' column to 'Metric' for clarity\n",
    "    r2_comparison_df.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "\n",
    "    # Create the bar plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=r2_comparison_df, x='Model', y='R-squared', hue='Metric', palette='viridis')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.ylabel('R-squared Value')\n",
    "    plt.title('R-squared Comparison of Different Models')\n",
    "    plt.ylim(0.0, 0.35)  # Adjust y-limits based on your data range\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='hyperparameter optimization settings', loc='upper right', fontsize=9, \n",
    "               title_fontsize=8, ncol = 4, frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Only Meta', 'Meta GRS', \n",
    "               'Meta GRS Tax', 'Meta GRS Tax Func', \n",
    "               'All But Meta', 'All Omic']\n",
    "compare_r2_values2(model_names, r2_run1, r2_run2, r2_run3, r2_run4, r2_run5, r2_run6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_r2_values2(model_names_delta, r2_delta_run1, r2_delta_run2, \n",
    "                   r2_delta_run3, r2_delta_run4, r2_delta_run5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_both = ['Only Meta Long', 'Meta GRS Long', \n",
    "               'Meta GRS Tax Long', 'Meta GRS Tax Func Long', \n",
    "               'All But Meta Long', 'All Omic Long', \n",
    "               'Only Meta Delta', 'Meta Tax Delta', 'Meta Tax Func Delta', \n",
    "               'All But Meta Delta', 'All Omic Delta']\n",
    "\n",
    "compare_r2_values2(model_names_both, \n",
    "                   r2_run1, r2_run2, r2_run3, r2_run4, r2_run5, r2_run6,\n",
    "                   r2_delta_run1, r2_delta_run2, \n",
    "                   r2_delta_run3, r2_delta_run4, r2_delta_run5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_r2_values3(model_names, *r2_dicts):\n",
    "    # Create a DataFrame to hold the R-squared values\n",
    "    r2_comparison_df = pd.DataFrame(r2_dicts).T\n",
    "    r2_comparison_df.columns = model_names \n",
    "\n",
    "    # Reset index to use row names as a column\n",
    "    r2_comparison_df.reset_index(inplace=True)\n",
    "    r2_comparison_df = r2_comparison_df.melt(id_vars='index', var_name='Model', value_name='R-squared')\n",
    "\n",
    "    # Rename the 'index' column to 'Metric' for clarity\n",
    "    r2_comparison_df.rename(columns={'index': 'Metric'}, inplace=True)\n",
    "\n",
    "    # Sort the DataFrame by 'Model' and then by 'R-squared' in descending order\n",
    "    r2_comparison_df = r2_comparison_df.sort_values(by=['Metric', 'R-squared'], ascending=[True, False])\n",
    "\n",
    "    # Create the bar plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=r2_comparison_df, x='Model', y='R-squared', hue='Metric', palette='viridis')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.ylabel('R-squared Value')\n",
    "    plt.title('R-squared Comparison of Different Models')\n",
    "    plt.ylim(-0.2, 0.2)  # Adjust y-limits based on your data range\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='hyperparameter optimization settings', loc='upper right', fontsize=10, \n",
    "               title_fontsize=10, ncol = 2, frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Only Meta', 'Meta GRS', \n",
    "               'Meta GRS Tax', 'Meta GRS Tax Func', \n",
    "               'All But Meta', 'All Omic']\n",
    "compare_r2_values3(model_names, r2_run1, r2_run2, r2_run3, r2_run4, r2_run5, r2_run6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance(dataframes):\n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dataframes)\n",
    "    \n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bar_width = 0.08\n",
    "    # Plot each model's feature importance\n",
    "    for model in combined_df['Model'].unique():\n",
    "        model_data = combined_df[combined_df['Model'] == model]\n",
    "        plt.bar(model_data['Feature'], model_data['Importance'], label=model)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Features', fontsize=10)\n",
    "    plt.ylabel('Importance', fontsize=10)\n",
    "    plt.title('Feature Importance by Model')\n",
    "    plt.xticks(rotation=45, fontsize=9)\n",
    "    plt.legend(title='Model', fontsize=9, ncol=2)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "feature_importance_dfs = [fi_run1, fi_run2, fi_run3, fi_run4, fi_run5, fi_run6, fi_delta_run1, fi_delta_run2]\n",
    "plot_feature_importance(feature_importance_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(dataframes):\n",
    "    combined_df = pd.concat(dataframes) # Combine all DataFrames \n",
    "    # Filter features with importance < 0.02 & negative importance in all models\n",
    "    combined_df = combined_df[(combined_df['Importance'] >= 0.02) & \n",
    "                          (combined_df.groupby('Feature')['Importance'].transform('min') >= 0)]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bar_width = 0.15 \n",
    "    num_models = len(combined_df['Model'].unique())\n",
    "    \n",
    "    # Get unique features\n",
    "    features = combined_df['Feature'].unique()\n",
    "    x = np.arange(len(features))  # The label locations\n",
    "\n",
    "    # Plot each model's feature importance\n",
    "    for i, model in enumerate(combined_df['Model'].unique()):\n",
    "        model_data = combined_df[combined_df['Model'] == model]\n",
    "        \n",
    "        # Ensure heights only includes matching features\n",
    "        heights = model_data[model_data['Feature'].isin(features)]['Importance'] \n",
    "        model_x = x[:len(heights)] + i * bar_width  # Adjust x-coordinates for the current model\n",
    "        plt.bar(model_x, heights, width=bar_width, label=model)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Features', fontsize=10)\n",
    "    plt.ylabel('Importance', fontsize=10)\n",
    "    plt.title('Feature Importance by Model')\n",
    "    plt.xticks(x + bar_width * (num_models - 1) / 2, features, rotation=45, fontsize=9)  # Center x-ticks\n",
    "    plt.legend(title='Model', fontsize=9, ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(0, 0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(dataframes, model_labels):\n",
    "    combined_df = pd.concat(dataframes)  # Combine all DataFrames \n",
    "    # Filter features with importance < 0.02 & negative importance in all models\n",
    "    combined_df = combined_df[(combined_df['Importance'] >= 0.02) & \n",
    "                              (combined_df.groupby('Feature')['Importance'].transform('min') >= 0)]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bar_width = 0.15 \n",
    "    num_models = len(combined_df['Model'].unique())\n",
    "    \n",
    "    # Get unique features\n",
    "    features = combined_df['Feature'].unique()\n",
    "    x = np.arange(len(features))  # The label locations\n",
    "\n",
    "    # Plot each model's feature importance\n",
    "    for i, model in enumerate(combined_df['Model'].unique()):\n",
    "        model_data = combined_df[combined_df['Model'] == model]\n",
    "        \n",
    "        # Ensure heights only includes matching features\n",
    "        heights = model_data[model_data['Feature'].isin(features)]['Importance'] \n",
    "        model_x = x[:len(heights)] + i * bar_width  # Adjust x-coordinates for the current model\n",
    "        plt.bar(model_x, heights, width=bar_width, label=model_labels[i])  # Use custom labels\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Features', fontsize=10)\n",
    "    plt.ylabel('Importance', fontsize=10)\n",
    "    plt.title('Feature Importance by Model')\n",
    "    plt.xticks(x + bar_width * (num_models - 1) / 2, features, rotation=45, fontsize=9)  # Center x-ticks\n",
    "    plt.legend(title='Model', fontsize=9, ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.ylim(0, 0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels_long = ['Only Meta', 'Meta GRS', 'Meta GRS Tax', 'Meta GRS Tax Func', 'All But Meta', 'All Omic']\n",
    "model_labels_delta = ['Only Meta Delta', 'Meta Tax Delta', 'Meta Tax Func Delta', 'All But Meta Delta', 'All Omic Delta']\n",
    "fi_long = [fi_run1, fi_run2, fi_run3, fi_run3, fi_run4, fi_run5, fi_run6]\n",
    "fi_delta = [fi_delta_run1, fi_delta_run2, fi_delta_run3, fi_delta_run4, fi_delta_run5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(fi_long, model_labels_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(fi_delta, model_labels_delta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
