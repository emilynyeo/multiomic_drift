{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from merf import MERF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools \n",
    "sns.set_context(\"poster\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (11,8)\n",
    "from merf.merf import MERF\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from merf.viz import plot_merf_training_stats\n",
    "\n",
    "current_dir = os.getcwd() # Get the current working directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from em_utils import *\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/5.combined/jan15_5foldcv\"\n",
    "df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/5.combined\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read in combined test and train sets \n",
    "test_all = pd.read_csv(os.path.join(df_dir, 'test_merged_all_omics_raw_meta.csv'))  \n",
    "train_all = pd.read_csv(os.path.join(df_dir, 'training_merged_all_omics_raw_meta.csv'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select testinng and training predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = train_all\n",
    "X = train_set.drop(['Unnamed: 0_y','Unnamed: 0_x', 'Unnamed: 0_train_long', 'Unnamed: 0_merged_data',\n",
    "                    'sample_id','all_samples', 'all_samples_x', 'all_samples_y', 'record_id', 'subject_id','SampleID',\n",
    "                    'time_x', 'time_y', 'x_t', 't', 'time',\n",
    "                    'outcome_BMI_fnl_x', 'outcome_BMI_fnl_y', 'outcome_BMI_fnl_merged_data','outcome_BMI_fnl_train_long',\n",
    "                    'old_or_new', 'predicted_BL_BMI', 'differences_BL_BMI', 'diff_BMI_quartile', 'diff_BMI_std',\n",
    "                    'methyl_bmi_rs', 'methyl_bmi_rs_standardized'], \n",
    "                    axis=1)\n",
    "\n",
    "#X = X.drop(columns=['Unnamed: 0_tax', 'x_t'], errors='ignore')\n",
    "Y = train_set[['outcome_BMI_fnl_train_long']]\n",
    "Y = Y['outcome_BMI_fnl_train_long'].to_numpy() # Convert Y to numeric array\n",
    "clusters_train = train_set['all_samples'].to_numpy() # Get ID variables\n",
    "Z = np.ones((train_set.shape[0], 1)) # Create random effects matrix with ones\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"X data: \\n\", X)\n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = test_all\n",
    "X_new = test_set.drop(['Unnamed: 0_y','Unnamed: 0_x', 'Unnamed: 0_test_long', 'Unnamed: 0_merged_data',\n",
    "                    'sample_id','all_samples', 'all_samples_x', 'all_samples_y', 'record_id', 'subject_id', \n",
    "                    'time_x', 'time_y', 'x_t', 't', 'time',\n",
    "                    'outcome_BMI_fnl_x', 'outcome_BMI_fnl_y', 'outcome_BMI_fnl_merged_data','outcome_BMI_fnl_test_long',\n",
    "                    'old_or_new', 'predicted_BL_BMI', 'differences_BL_BMI', 'diff_BMI_quartile', 'diff_BMI_std',\n",
    "                    'methyl_bmi_rs', 'methyl_bmi_rs_standardized'], \n",
    "                    axis=1)\n",
    "\n",
    "X_new = X_new[X.columns]  # Reorder and select columns to match training set\n",
    "X_new = X_new.astype(X.dtypes)  # Ensure data types match\n",
    "\n",
    "Y_new = test_set['outcome_BMI_fnl_test_long'].to_numpy()  # Convert Y to numeric array\n",
    "clusters_new = pd.Series(test_set['all_samples'])  # Convert to pandas Series\n",
    "# Create random effects matrix with ones\n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "\n",
    "print(\"X_new shape: \", X_new.shape)\n",
    "print(\"X_new data: \\n\", X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"X data: \\n\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_new clusters: \", clusters_new.shape)\n",
    "print(\"X_new clusters: \\n\", clusters_new)\n",
    "print(\"Number of unique clusters in testing : \", clusters_new.nunique())\n",
    "\n",
    "# ... existing code ...\n",
    "clusters_train_count = pd.Series(train_set['all_samples']).to_numpy() # Convert to pandas Series\n",
    "print(\"Number of unique clusters in training : \", pd.Series(clusters_train_count).nunique())  # Convert back to Series for nunique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read finetuned parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(df_dir, 'jan13_params_fine_tuning_results_all_omics.csv'))\n",
    "# the line below filters out certain folds\n",
    "df = df[df['n_splits'] == 5]\n",
    "# Find the row with the lowest mean_mse_score\n",
    "lowest_mse_row = df.loc[df['mean_mse_score'].idxmin()]\n",
    "print(\"First 5 columns for the lowest mean_mse_score:\")\n",
    "print(lowest_mse_row.iloc[:5])\n",
    "\n",
    "# Find the row with the lowest mean_prev_score\n",
    "lowest_prev_row = df.loc[df['mean_prev'].idxmin()]\n",
    "print(\"First 5 columns for the lowest mean_prev_score:\")\n",
    "print(lowest_prev_row.iloc[:5])\n",
    "\n",
    "# Find the row with the lowest mean_prev_score\n",
    "lowest_ptev_row = df.loc[df['mean_ptev'].idxmin()]\n",
    "print(\"First 5 columns for the lowest mean_ptev_score:\")\n",
    "print(lowest_ptev_row.iloc[:5])\n",
    "\n",
    "# Find the row with the highest oob_score\n",
    "highest_oob_row = df.loc[df['oob_score'].idxmax()]\n",
    "print(\"\\nFirst 5 columns for the highest oob_score:\")\n",
    "print(highest_oob_row.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the rows for the parameter grids\n",
    "lowest_mse_row = df.loc[df['mean_mse_score'].idxmin()]\n",
    "lowest_prev_row = df.loc[df['mean_prev'].idxmin()]\n",
    "lowest_ptev_row = df.loc[df['mean_ptev'].idxmin()]\n",
    "highest_oob_row = df.loc[df['oob_score'].idxmax()]\n",
    "\n",
    "# Create parameter grids from the extracted rows\n",
    "best_mse_param_grid = {\n",
    "    'n_estimators': [int(lowest_mse_row['n_estimators'])],\n",
    "    #'max_depth': [int(lowest_mse_row['max_depth'])],\n",
    "    'max_depth': [None if pd.isna(lowest_mse_row['max_depth']) else int(lowest_mse_row['max_depth'])],\n",
    "    'min_samples_split': [float(lowest_mse_row['min_samples_split'])],\n",
    "    #'min_samples_split': [float(lowest_mse_row['min_samples_split']) if lowest_mse_row['min_samples_split'] != 0 else 0.0],  # Convert 0 to 0.0\n",
    "    'max_iter': [int(lowest_mse_row['max_iter'])],\n",
    "    'n_splits': [int(lowest_mse_row['n_splits'])]\n",
    "}\n",
    "print(\"Best MSE Parameter Grid:\")\n",
    "print(\"n_estimators:\", best_mse_param_grid['n_estimators'][0])\n",
    "print(\"max_depth:\", best_mse_param_grid['max_depth'][0])\n",
    "print(\"min_samples_split:\", best_mse_param_grid['min_samples_split'][0])\n",
    "print(\"max_iter:\", best_mse_param_grid['max_iter'][0])\n",
    "print(\"n_splits:\", best_mse_param_grid['n_splits'][0])\n",
    "\n",
    "lowest_prev_param_grid = {\n",
    "    'n_estimators': [int(lowest_prev_row['n_estimators'])],\n",
    "    #'max_depth': [int(lowest_prev_row['max_depth'])],\n",
    "    'max_depth': [None if pd.isna(lowest_prev_row['max_depth']) else int(lowest_prev_row['max_depth'])],\n",
    "    'min_samples_split': [float(lowest_prev_row['min_samples_split'])],\n",
    "    'max_iter': [int(lowest_prev_row['max_iter'])],\n",
    "    'n_splits': [int(lowest_prev_row['n_splits'])]\n",
    "}\n",
    "print(\"\\nLowest Prev Parameter Grid:\")\n",
    "print(\"n_estimators:\", lowest_prev_param_grid['n_estimators'][0])\n",
    "print(\"max_depth:\", lowest_prev_param_grid['max_depth'][0])\n",
    "print(\"min_samples_split:\", lowest_prev_param_grid['min_samples_split'][0])\n",
    "print(\"max_iter:\", lowest_prev_param_grid['max_iter'][0])\n",
    "print(\"n_splits:\", lowest_prev_param_grid['n_splits'][0])\n",
    "\n",
    "lowest_ptev_param_grid = {\n",
    "    'n_estimators': [int(lowest_ptev_row['n_estimators'])],\n",
    "    #'max_depth': [int(lowest_ptev_row['max_depth'])],\n",
    "    'max_depth': [None if pd.isna(lowest_ptev_row['max_depth']) else int(lowest_ptev_row['max_depth'])],\n",
    "    'min_samples_split': [float(lowest_ptev_row['min_samples_split'])],\n",
    "    'max_iter': [int(lowest_ptev_row['max_iter'])],\n",
    "    'n_splits': [int(lowest_ptev_row['n_splits'])]\n",
    "}\n",
    "print(\"\\nLowest PTEV Parameter Grid:\")\n",
    "print(\"n_estimators:\", lowest_ptev_param_grid['n_estimators'][0])\n",
    "print(\"max_depth:\", lowest_ptev_param_grid['max_depth'][0])\n",
    "print(\"min_samples_split:\", lowest_ptev_param_grid['min_samples_split'][0])\n",
    "print(\"max_iter:\", lowest_ptev_param_grid['max_iter'][0])\n",
    "print(\"n_splits:\", lowest_ptev_param_grid['n_splits'][0])\n",
    "\n",
    "highest_oob_param_grid = {\n",
    "    'n_estimators': [int(highest_oob_row['n_estimators'])],\n",
    "    'max_depth': [None if pd.isna(highest_oob_row['max_depth']) else int(highest_oob_row['max_depth'])],\n",
    "    'min_samples_split': [float(highest_oob_row['min_samples_split'])],\n",
    "    'max_iter': [int(highest_oob_row['max_iter'])],\n",
    "    'n_splits': [int(highest_oob_row['n_splits'])]\n",
    "}\n",
    "print(\"\\Highest OOB Parameter Grid:\")\n",
    "print(\"n_estimators:\", highest_oob_row['n_estimators'])\n",
    "print(\"max_depth:\", highest_oob_row['max_depth'])\n",
    "print(\"min_samples_split:\", highest_oob_row['min_samples_split'])\n",
    "print(\"max_iter:\", highest_oob_row['max_iter'])\n",
    "print(\"n_splits:\", highest_oob_row['n_splits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up different merf models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MERF models for each parameter grid\n",
    "mse_merf = MERF(fixed_effects_model =\n",
    "           RandomForestRegressor(n_estimators = best_mse_param_grid['n_estimators'][0], \n",
    "                                max_depth = best_mse_param_grid['max_depth'][0], \n",
    "                                min_samples_split = best_mse_param_grid['min_samples_split'][0], \n",
    "                                n_jobs = 1, \n",
    "                                oob_score= True),\n",
    "            gll_early_stop_threshold=None,\n",
    "            max_iterations = best_mse_param_grid['max_iter'][0])\n",
    "\n",
    "prev_merf = MERF(fixed_effects_model =\n",
    "           RandomForestRegressor(n_estimators = lowest_prev_param_grid['n_estimators'][0], \n",
    "                                max_depth = lowest_prev_param_grid['max_depth'][0], \n",
    "                                min_samples_split = lowest_prev_param_grid['min_samples_split'][0], \n",
    "                                n_jobs = 1, \n",
    "                                oob_score= True),\n",
    "            gll_early_stop_threshold=None,\n",
    "            max_iterations = lowest_prev_param_grid['max_iter'][0])\n",
    "\n",
    "ptev_merf = MERF(fixed_effects_model =\n",
    "           RandomForestRegressor(n_estimators = lowest_ptev_param_grid['n_estimators'][0], \n",
    "                                max_depth = lowest_ptev_param_grid['max_depth'][0], \n",
    "                                min_samples_split = lowest_ptev_param_grid['min_samples_split'][0], \n",
    "                                n_jobs = 1, \n",
    "                                oob_score= True),\n",
    "            gll_early_stop_threshold=None,\n",
    "            max_iterations = lowest_ptev_param_grid['max_iter'][0])\n",
    "\n",
    "oob_merf = MERF(fixed_effects_model =\n",
    "           RandomForestRegressor(n_estimators = highest_oob_param_grid['n_estimators'][0], \n",
    "                                max_depth = highest_oob_param_grid['max_depth'][0], \n",
    "                                min_samples_split = highest_oob_param_grid['min_samples_split'][0], \n",
    "                                n_jobs = 1, \n",
    "                                oob_score= True),\n",
    "            gll_early_stop_threshold=None,\n",
    "            max_iterations = highest_oob_param_grid['max_iter'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MERF Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- RUN MERF RAW WITH TUNING PARAMETERS ðŸŒ± ----------\")\n",
    "mrf_mse = mse_merf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "mrf_prev = prev_merf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "mrf_ptev = ptev_merf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "mrf_oob = oob_merf.fit(X.select_dtypes(include=[np.number]), \n",
    "                Z, \n",
    "                pd.Series(clusters_train), \n",
    "                Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_merf_training_stats(mrf_mse)\n",
    "plt.savefig(os.path.join(output_dir, 'jan31_cv_tuned_mse_merf_raw_metrics_all.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "plot_merf_training_stats(mrf_prev)\n",
    "plt.savefig(os.path.join(output_dir, 'jan31_cv_tuned_prev_merf_raw_metrics_all.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "plot_merf_training_stats(mrf_ptev)\n",
    "plt.savefig(os.path.join(output_dir, 'jan31_cv_tuned_ptev_merf_raw_metrics_all.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "plot_merf_training_stats(mrf_oob)\n",
    "plt.savefig(os.path.join(output_dir, 'jan31_cv_tuned_oob_merf_raw_metrics_all.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions using the fitted models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the fitted model\n",
    "clusters_new = pd.Series(test_set['all_samples'])\n",
    "X_new = X_new.drop(columns=['x_t'], errors='ignore')\n",
    "y_hat_new_mse = mrf_mse.predict(X_new, Z_new, clusters_new)\n",
    "forest_mse = mrf_mse.trained_fe_model\n",
    "oob_score_mse = round(forest_mse.oob_score_*100, 1)\n",
    "\n",
    "y_hat_new_prev = mrf_prev.predict(X_new, Z_new, clusters_new)\n",
    "forest_prev = mrf_prev.trained_fe_model\n",
    "oob_score_prev = round(forest_prev.oob_score_*100, 1)\n",
    "\n",
    "y_hat_new_ptev = mrf_ptev.predict(X_new, Z_new, clusters_new)\n",
    "forest_ptev = mrf_ptev.trained_fe_model\n",
    "oob_score_ptev = round(forest_ptev.oob_score_*100, 1)\n",
    "\n",
    "y_hat_new_oob = mrf_oob.predict(X_new, Z_new, clusters_new)\n",
    "forest_oob = mrf_oob.trained_fe_model\n",
    "oob_score_tuned = round(forest_oob.oob_score_*100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot predicted vs actual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_vs_actual(y_hat_new_mse, Y_new,\n",
    "                         output_dir, 'jan31_all_predicted_vs_actual_mse_tuned.png', \n",
    "                         best_mse_param_grid, oob_score_mse, '#F88F79', 'all omics mse predicted vs actual BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_vs_actual(y_hat_new_prev, Y_new,\n",
    "                         output_dir, 'jan31_all_predicted_vs_actual_prev_tuned.png', \n",
    "                         lowest_prev_param_grid, oob_score_prev, '#F0F879', 'all omics predicted vs actual BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(Y_new, y_hat_new_ptev) #(Y_true, Y_pred)\n",
    "plot_predicted_vs_actual(y_hat_new_ptev, Y_new,\n",
    "                         output_dir, 'jan31_all_predicted_vs_actual_ptev_tuned.png', \n",
    "                         lowest_ptev_param_grid, oob_score_ptev, '#ACF0F8', 'all omics predicted vs actual BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(Y_new, y_hat_new_oob) #(Y_true, Y_pred)\n",
    "plot_predicted_vs_actual(y_hat_new_oob, Y_new,\n",
    "                         output_dir, 'jan31_all_predicted_vs_actual_oob_tuned.png', \n",
    "                         highest_oob_param_grid, oob_score_tuned, '#86B874', 'all predicted vs actual BMI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at feature importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse\n",
    "mse_forest = mrf_mse.trained_fe_model\n",
    "mse_feature_names = mse_forest.feature_names_in_\n",
    "mse_feature_importances = mse_forest.feature_importances_\n",
    "\n",
    "print(\"Top 20 feature importances for best MSE parameters:\")\n",
    "for name, importance in zip(mse_feature_names[:20], \n",
    "                            mse_feature_importances[:20]):\n",
    "    print(f\"{name}: {importance}\")\n",
    "\n",
    "plot_top_20_feature_importances(mse_feature_names, mse_feature_importances, \n",
    "                         output_dir, 'jan31_mse_feature_importances_all', '#F88F79')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_forest = prev_merf.trained_fe_model\n",
    "prev_feature_names = prev_forest.feature_names_in_\n",
    "prev_feature_importances = prev_forest.feature_importances_\n",
    "\n",
    "print(\"Top 20 feature importances for best PREV parameters:\")\n",
    "for name, importance in zip(prev_feature_names[:20], \n",
    "                            prev_feature_importances[:20]):\n",
    "    print(f\"{name}: {importance}\")\n",
    "\n",
    "plot_top_20_feature_importances(prev_feature_names, prev_feature_importances, \n",
    "                         output_dir, 'jan31_prev_feature_importances_all', '#F0F879')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptev_forest = ptev_merf.trained_fe_model\n",
    "ptev_feature_names = ptev_forest.feature_names_in_\n",
    "ptev_feature_importances = ptev_forest.feature_importances_\n",
    "\n",
    "print(\"Top 20 feature importances for best PTEV parameters:\")\n",
    "for name, importance in zip(ptev_feature_names[:20], \n",
    "                            ptev_feature_importances[:20]):\n",
    "    print(f\"{name}: {importance}\")\n",
    "\n",
    "plot_top_20_feature_importances(ptev_feature_names, ptev_feature_importances, \n",
    "                         output_dir, 'jan31_ptev_feature_importances_all', '#ACF0F8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_forest = oob_merf.trained_fe_model\n",
    "oob_feature_names = oob_forest.feature_names_in_\n",
    "oob_feature_importances = oob_forest.feature_importances_\n",
    "\n",
    "print(\"Top 20 feature importances for best OOB parameters:\")\n",
    "for name, importance in zip(oob_feature_names[:20], \n",
    "                            oob_feature_importances[:20]):\n",
    "    print(f\"{name}: {importance}\")\n",
    "\n",
    "plot_top_20_feature_importances(oob_feature_names, oob_feature_importances, \n",
    "                         output_dir, 'jan31_oob_feature_importances_all', '#86B874')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.5 (main, Jun 11 2025, 15:36:57) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "sys.version_info(major=3, minor=13, micro=5, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)          # Full version string (e.g., 3.11.6 (main, ...) ...)\n",
    "print(sys.version_info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import merf\n",
    "print(merf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
