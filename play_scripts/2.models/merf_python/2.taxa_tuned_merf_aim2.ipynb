{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from merf import MERF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools \n",
    "sns.set_context(\"poster\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (11,8)\n",
    "from merf.merf import MERF\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from merf.viz import plot_merf_training_stats\n",
    "from em_utils import *\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/2.taxa\"\n",
    "df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/2.taxa\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where the files are located\n",
    "data_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim2_transformed/genus/merf_ready_sets/\"\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "test_tax_no_na = pd.read_csv(os.path.join(data_dir, 'test_tax_no_na.csv'))\n",
    "train_tax_no_na = pd.read_csv(os.path.join(data_dir, 'train_tax_no_na.csv'))\n",
    "full_train_tax = pd.read_csv(os.path.join(data_dir, 'full_train_tax.csv'))\n",
    "full_test_tax = pd.read_csv(os.path.join(data_dir, 'full_test_tax.csv'))\n",
    "\n",
    "# Optionally, print the shapes of the DataFrames to confirm they were read correctly\n",
    "print(\"test_tax_no_na shape:\", test_tax_no_na.shape)\n",
    "print(\"train_tax_no_na shape:\", train_tax_no_na.shape)\n",
    "print(\"full_train_tax shape:\", full_train_tax.shape)\n",
    "print(\"full_test_tax shape:\", full_test_tax.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = full_train_tax\n",
    "X = train_set.drop(['t', 'outcome_BMI_fnl', 'all_samples'], axis=1)\n",
    "X = X.drop(columns=['Unnamed: 0_tax', 'x_t'], errors='ignore')\n",
    "Y = train_set[['outcome_BMI_fnl']]\n",
    "Y = Y['outcome_BMI_fnl'].to_numpy() # Convert Y to numeric array\n",
    "clusters_train = train_set['all_samples'].to_numpy() # Get ID variables\n",
    "Z = np.ones((train_set.shape[0], 1)) # Create random effects matrix with ones\n",
    "\n",
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = full_test_tax\n",
    "# Drop any unwanted columns and align test set features with training features\n",
    "X_new = test_set.drop(['t', 'outcome_BMI_fnl', 'all_samples'], axis=1)  # Drop non-predictor columns\n",
    "X_new = X_new[X.columns]  # Reorder and select columns to match training set\n",
    "X_new = X_new.astype(X.dtypes)  # Ensure data types match\n",
    "X_new = X_new.drop(columns=['Unnamed: 0_tax', 'x_t'], errors='ignore')\n",
    "X_new = X_new.drop(columns=['Unnamed: 0', 'character_id', 'timepoint'], errors='ignore')\n",
    "\n",
    "Y_new = test_set['outcome_BMI_fnl'].to_numpy()  # Convert Y to numeric array\n",
    "clusters_new = pd.Series(test_set['all_samples'])  # Convert to pandas Series\n",
    "# Create random effects matrix with ones\n",
    "Z_new = np.ones((len(X_new), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set thresholds\n",
    "best_mse_param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [5],\n",
    "    'max_iter': [2]\n",
    "}\n",
    "\n",
    "lowest_prev_param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [5],\n",
    "    'max_iter': [3]\n",
    "}\n",
    "\n",
    "lowest_ptev_param_grid = {\n",
    "    'n_estimators': [1],\n",
    "    'max_depth': [1],\n",
    "    'min_samples_split': [2],\n",
    "    'max_iter': [3]\n",
    "}\n",
    "\n",
    "tuned_param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [100],\n",
    "    'min_samples_split': [2],\n",
    "    'max_iter': [3]\n",
    "}\n",
    "\n",
    "mse_mrf = MERF(fixed_effects_model =\n",
    "           RandomForestRegressor(n_estimators = best_mse_param_grid['n_estimators'][0], \n",
    "                                max_depth = best_mse_param_grid['max_depth'][0], \n",
    "                                min_samples_split = best_mse_param_grid['min_samples_split'][0], \n",
    "                                n_jobs = 1, \n",
    "                                oob_score= True),\n",
    "            gll_early_stop_threshold=None,\n",
    "            max_iterations = best_mse_param_grid['max_iter'][0])\n",
    "\n",
    "prev_merf = MERF(fixed_effects_model =\n",
    "           RandomForestRegressor(n_estimators = lowest_prev_param_grid['n_estimators'][0], \n",
    "                                max_depth = lowest_prev_param_grid['max_depth'][0], \n",
    "                                min_samples_split = lowest_prev_param_grid['min_samples_split'][0], \n",
    "                                n_jobs = 1, \n",
    "                                oob_score= True),\n",
    "            gll_early_stop_threshold=None,\n",
    "            max_iterations = lowest_prev_param_grid['max_iter'][0])\n",
    "\n",
    "ptev_merf = MERF(fixed_effects_model =\n",
    "           RandomForestRegressor(n_estimators = lowest_ptev_param_grid['n_estimators'][0], \n",
    "                                max_depth = lowest_ptev_param_grid['max_depth'][0], \n",
    "                                min_samples_split = lowest_ptev_param_grid['min_samples_split'][0], \n",
    "                                n_jobs = 1, \n",
    "                                oob_score= True),\n",
    "            gll_early_stop_threshold=None,\n",
    "            max_iterations = lowest_ptev_param_grid['max_iter'][0])\n",
    "\n",
    "tuned_model = MERF(fixed_effects_model=RandomForestRegressor(\n",
    "                    n_estimators= tuned_param_grid['n_estimators'][0],  # Number of trees in the forest\n",
    "                    max_depth= tuned_param_grid['max_depth'][0],  # Maximum depth of each tree\n",
    "                    min_samples_split= tuned_param_grid['min_samples_split'][0],  # Minimum samples required to split an internal node\n",
    "                    n_jobs=1,  # Number of jobs to run in parallel\n",
    "                    oob_score=True),  # Whether to use out-of-bag samples to estimate the R^2 on unseen data\n",
    "                gll_early_stop_threshold=None,  # No early stopping threshold set\n",
    "                max_iterations= tuned_param_grid['max_iter'][0])  # Maximum number of iterations to run the MERF algorithm\n",
    "\n",
    "print(\"---------- RUN MERF RAW BASICðŸŒ± ----------\")\n",
    "mrf_mse = mse_mrf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "mrf_prev = prev_merf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "mrf_ptev = ptev_merf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "tuned_model = tuned_model.fit(X.select_dtypes(include=[np.number]), \n",
    "                Z, \n",
    "                pd.Series(clusters_train), \n",
    "                Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run merf with the tuned parameters above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- RUN MERF ðŸŒ± ----------\")\n",
    "mrf_mse = mse_mrf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "mrf_prev = prev_merf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "mrf_ptev = ptev_merf.fit(X.select_dtypes(include=[np.number]), \n",
    "        Z, \n",
    "        pd.Series(clusters_train), \n",
    "        Y)\n",
    "\n",
    "tuned_model = tuned_model.fit(X.select_dtypes(include=[np.number]), \n",
    "                Z, \n",
    "                pd.Series(clusters_train), \n",
    "                Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_merf_training_stats(mrf_mse)\n",
    "plt.savefig(os.path.join(output_dir, 'tuned_high_mse_merf_raw_metrics_tax.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_merf_training_stats(mrf_prev)\n",
    "plt.savefig(os.path.join(output_dir, 'tuned_low_prev_merf_raw_metrics_taxa.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_merf_training_stats(mrf_ptev)\n",
    "plt.savefig(os.path.join(output_dir, 'tuned_low_ptev_merf_raw_metrics_taxa.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_merf_training_stats(tuned_model)\n",
    "plt.savefig(os.path.join(output_dir, 'taxa_merf_raw_metrics_tuned_taxa.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the fitted model\n",
    "X_new = X_new.drop(columns=['x_t'], errors='ignore')\n",
    "y_hat_new_mse = mrf_mse.predict(X_new, Z_new, clusters_new)\n",
    "y_hat_new_prev = mrf_prev.predict(X_new, Z_new, clusters_new)\n",
    "y_hat_new_ptev = mrf_ptev.predict(X_new, Z_new, clusters_new)\n",
    "y_hat_new_tuned = tuned_model.predict(X_new, Z_new, clusters_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_vs_actual(y_hat_new_mse, Y_new, output_dir, 'taxa_predicted_vs_actual_mse_tuned.png', best_mse_param_grid, plot_color='#F88F79')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_vs_actual(y_hat_new_prev, Y_new, 'taxa_predicted_vs_actual_highest_prev_tuned.png', None, '#F0F879')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_vs_actual(y_hat_new_ptev, Y_new, output_dir, 'clinical_predicted_vs_actual_highest_ptev_tuned.png', lowest_ptev_param_grid, '#ACF0F8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_predicted_vs_actual(y_hat_new_tuned, Y_new, output_dir, 'clinical_predicted_vs_actual_tuned.png', tuned_param_grid, '#C9ACF8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse\n",
    "mse_forest = mrf_mse.trained_fe_model\n",
    "mse_feature_names = mse_forest.feature_names_in_\n",
    "mse_feature_importances = mse_forest.feature_importances_\n",
    "plot_top_20_feature_importances(mse_feature_names, mse_feature_importances, \n",
    "                         output_dir, 'mse_feature_importances_taxa', '#F88F79')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev\n",
    "prev_forest = prev_merf.trained_fe_model\n",
    "prev_feature_names = prev_forest.feature_names_in_\n",
    "prev_feature_importances = prev_forest.feature_importances_\n",
    "plot_top_20_feature_importances(prev_feature_names, prev_feature_importances, \n",
    "                         output_dir, 'prev_feature_importances_taxa', '#F0F879')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptev\n",
    "ptev_forest = ptev_merf.trained_fe_model\n",
    "ptev_feature_names = ptev_forest.feature_names_in_\n",
    "ptev_feature_importances = ptev_forest.feature_importances_\n",
    "plot_top_20_feature_importances(ptev_feature_names, ptev_feature_importances, \n",
    "                         output_dir, 'ptev_feature_importances_taxa', '#ACF0F8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned\n",
    "forest = tuned_model.trained_fe_model\n",
    "feature_names = forest.feature_names_in_\n",
    "feature_importances = forest.feature_importances_\n",
    "plot_top_20_feature_importances(feature_names, feature_importances, \n",
    "                                output_dir, 'tuned_feature_importances_taxa', '#C9ACF8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
