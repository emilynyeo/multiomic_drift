{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecdb6f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Read taxonomy data ---------- \n",
      "---------- Read metadata ----------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from merf import MERF\n",
    "\n",
    "def read_data(directory, filename):\n",
    "    \"\"\"Read CSV data from specified directory and filename\"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "print(\"---------- Read taxonomy data ---------- \")\n",
    "t_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim2_transformed/\"\n",
    "tax_test = read_data(t_dir, \"genus/aim2_clr_testing.csv\")\n",
    "tax_train = read_data(t_dir, \"genus/aim2_clr_training.csv\") \n",
    "tax_full = read_data(t_dir, \"genus/clr_taxa_all.csv\")\n",
    "\n",
    "print(\"---------- Read metadata ----------\")\n",
    "m1_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim2\"\n",
    "test = read_data(m1_dir, \"a2_test_samples_standard_clinical.csv\")\n",
    "train = read_data(m1_dir, \"a2_train_samples_standard_clinical.csv\")\n",
    "full = read_data(m1_dir, \"a2_meta_Transformed_standard_clinical.csv\")\n",
    "full_raw = read_data(m1_dir, \"a2_meta_not_Transformed_standard_clinical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aba46de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Split X column into character_id and timepoint ----------\n",
      "0      AAL-144.12m\n",
      "1       AAL-144.3m\n",
      "2       AAL-144.6m\n",
      "3       AAL-144.BL\n",
      "4       ABR-079.3m\n",
      "          ...     \n",
      "590     YSU-097.6m\n",
      "591     YSU-097.BL\n",
      "592     ZVU-096.3m\n",
      "593     ZVU-096.6m\n",
      "594     ZVU-096.BL\n",
      "Name: Unnamed: 0, Length: 595, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Process Taxa Input data\n",
    "# FULL dataset\n",
    "# Split X column into character_id and timepoint\n",
    "print(\"---------- Split X column into character_id and timepoint ----------\")\n",
    "tax_full_t = tax_full.copy()\n",
    "X_LABEL = 'Unnamed: 0'\n",
    "print(tax_full_t[X_LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4fba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_full_t[['character_id', 'timepoint']] = tax_full_t[X_LABEL].str.split('.', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0c51ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Create time column ----------\n",
      "---------- Create x_t column combining character_id and t ----------\n"
     ]
    }
   ],
   "source": [
    "# Create time column (assuming create_t_column functionality maps timepoints to numeric values)\n",
    "def create_t_column(df):\n",
    "    # Map timepoints to numeric values\n",
    "    time_map = {'BL': '0', 'V1': '1', 'V2': '2', 'V3': '3', \n",
    "                'V4': '6', 'V5': '12', 'V6': '18'}\n",
    "    return df['timepoint'].map(time_map)\n",
    "\n",
    "print(\"---------- Create time column ----------\")\n",
    "tax_full_t['t'] = create_t_column(tax_full_t)\n",
    "\n",
    "print(\"---------- Create x_t column combining character_id and t ----------\")\n",
    "tax_full_t['x_t'] = tax_full_t['character_id'] + '.' + tax_full_t['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd4ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Filter and select columns ----------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Filter and select columns ----------\")\n",
    "tax = tax_full_t[~tax_full_t['t'].isin(['3', '18'])]\n",
    "tax = tax.drop(['t', 'timepoint', 'character_id', X_LABEL], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acb63f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Build training dataset ----------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Build training dataset ----------\")\n",
    "train_t = tax_train.copy()\n",
    "train_t[['character_id', 'timepoint']] = train_t[X_LABEL].str.split('.', expand=True)\n",
    "train_t['t'] = create_t_column(train_t)\n",
    "train_t['x_t'] = train_t['character_id'] + '.' + train_t['t']\n",
    "train_t = train_t[~train_t['t'].isin(['3', '18'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf42cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Build testing dataset ----------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Build testing dataset ----------\")\n",
    "test_t = tax_test.copy()\n",
    "test_t[['character_id', 'timepoint']] = test_t[X_LABEL].str.split('.', expand=True)\n",
    "test_t['t'] = create_t_column(test_t)\n",
    "test_t['x_t'] = test_t['character_id'] + '.' + test_t['t']\n",
    "test_t = test_t[~test_t['t'].isin(['3', '18'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5494f59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Clean up ----------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Clean up ----------\")\n",
    "del tax_test, tax_train, tax, tax_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e846965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'record_id', 'subject_id', 'randomized_group', 'cohort_number', 'sex', 'race', 'age', 'outcome_BMI_fnl_BL', 'Glucose_BL', 'HOMA_IR_BL', 'Insulin_endo_BL', 'HDL_Total_Direct_lipid_BL', 'LDL_Calculated_BL', 'Triglyceride_lipid_BL', 'outcome_BMI_fnl_6m', 'Glucose_6m', 'HOMA_IR_6m', 'Insulin_endo_6m', 'HDL_Total_Direct_lipid_6m', 'LDL_Calculated_6m', 'Triglyceride_lipid_6m', 'outcome_BMI_fnl_12m', 'Glucose_12m', 'HOMA_IR_12m', 'Insulin_endo_12m', 'HDL_Total_Direct_lipid_12m', 'LDL_Calculated_12m', 'Triglyceride_lipid_12m']\n",
      "---\n",
      "['Unnamed: 0', 'record_id', 'subject_id', 'randomized_group', 'cohort_number', 'sex', 'race', 'age', 'outcome_BMI_fnl_BL', 'Glucose_BL', 'HOMA_IR_BL', 'Insulin_endo_BL', 'HDL_Total_Direct_lipid_BL', 'LDL_Calculated_BL', 'Triglyceride_lipid_BL', 'outcome_BMI_fnl_6m', 'Glucose_6m', 'HOMA_IR_6m', 'Insulin_endo_6m', 'HDL_Total_Direct_lipid_6m', 'LDL_Calculated_6m', 'Triglyceride_lipid_6m', 'outcome_BMI_fnl_12m', 'Glucose_12m', 'HOMA_IR_12m', 'Insulin_endo_12m', 'HDL_Total_Direct_lipid_12m', 'LDL_Calculated_12m', 'Triglyceride_lipid_12m']\n",
      "---\n",
      "['Unnamed: 0', 'record_id', 'subject_id', 'randomized_group', 'cohort_number', 'sex', 'race', 'age', 'outcome_BMI_fnl_BL', 'Glucose_BL', 'HOMA_IR_BL', 'Insulin_endo_BL', 'HDL_Total_Direct_lipid_BL', 'LDL_Calculated_BL', 'Triglyceride_lipid_BL', 'outcome_BMI_fnl_6m', 'Glucose_6m', 'HOMA_IR_6m', 'Insulin_endo_6m', 'HDL_Total_Direct_lipid_6m', 'LDL_Calculated_6m', 'Triglyceride_lipid_6m', 'outcome_BMI_fnl_12m', 'Glucose_12m', 'HOMA_IR_12m', 'Insulin_endo_12m', 'HDL_Total_Direct_lipid_12m', 'LDL_Calculated_12m', 'Triglyceride_lipid_12m']\n"
     ]
    }
   ],
   "source": [
    "print(full_raw.columns.to_list())\n",
    "print(\"---\")\n",
    "print(train.columns.to_list())\n",
    "print(\"---\")\n",
    "print(test.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6586df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(full_raw.columns.to_list() == train.columns.to_list())\n",
    "print(train.columns.to_list() == test.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba2e607c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Convert metadata to long format ----------\n",
      "Columns after transformation: ['Unnamed: 0', 'record_id', 'subject_id', 'randomized_group', 'cohort_number', 'sex', 'race', 'age', 'time', 'Glucose', 'HDL_Total_Direct_lipid', 'HOMA_IR', 'Insulin_endo', 'LDL_Calculated', 'Triglyceride_lipid', 'outcome_BMI_fnl', 'x_t']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Process metadata to long format\n",
    "def make_long(wide_data):\n",
    "    \"\"\"\n",
    "    Converts a wide-format DataFrame into a long-format DataFrame,\n",
    "    aligning with the structure produced by the R transformation.\n",
    "    \n",
    "    Args:\n",
    "        wide_data (pd.DataFrame): Input DataFrame in wide format.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Transformed DataFrame in long format.\n",
    "    \"\"\"\n",
    "    # Extract measurement columns and id columns\n",
    "    id_vars = [col for col in wide_data.columns if not re.search(r'_(BL|6m|12m)$', col)]\n",
    "    value_vars = [col for col in wide_data.columns if re.search(r'_(BL|6m|12m)$', col)]\n",
    "\n",
    "    # Melt the DataFrame to long format\n",
    "    long_data = wide_data.melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name=\"measurement_time\",\n",
    "        value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    # Extract measurement type and time from the variable name\n",
    "    long_data[['measurement_type', 'time']] = long_data['measurement_time'].str.extract(r'(.+)_(BL|6m|12m)')\n",
    "\n",
    "    # Map time values\n",
    "    time_mapping = {'BL': 0, '6m': 6, '12m': 12}\n",
    "    long_data['time'] = long_data['time'].map(time_mapping)\n",
    "\n",
    "    # Drop the original melted column\n",
    "    long_data = long_data.drop(columns=['measurement_time'])\n",
    "\n",
    "    # Pivot the data back to wide format for measurements\n",
    "    long_data = long_data.pivot_table(\n",
    "        index=id_vars + ['time'], \n",
    "        columns='measurement_type', \n",
    "        values='value'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Flatten the column MultiIndex from pivot_table\n",
    "    long_data.columns.name = None\n",
    "    long_data.columns = [str(col) for col in long_data.columns]\n",
    "\n",
    "    return long_data\n",
    "\n",
    "\n",
    "# Apply the function to each dataset\n",
    "print(\"---------- Convert metadata to long format ----------\")\n",
    "full_long = make_long(full_raw)\n",
    "full_long['x_t'] = full_long['subject_id'].astype(str) + '.' + full_long['time'].astype(str)\n",
    "\n",
    "train_long = make_long(train)\n",
    "train_long['x_t'] = train_long['subject_id'].astype(str) + '.' + train_long['time'].astype(str)\n",
    "\n",
    "test_long = make_long(test)\n",
    "test_long['x_t'] = test_long['subject_id'].astype(str) + '.' + test_long['time'].astype(str)\n",
    "\n",
    "# Inspect the final column names for test_long\n",
    "print(\"Columns after transformation:\", test_long.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b337bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'record_id', 'subject_id', 'randomized_group', 'cohort_number', 'sex', 'race', 'age', 'time', 'Glucose', 'HDL_Total_Direct_lipid', 'HOMA_IR', 'Insulin_endo', 'LDL_Calculated', 'Triglyceride_lipid', 'outcome_BMI_fnl', 'x_t']\n"
     ]
    }
   ],
   "source": [
    "print(test_long.columns.to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f861665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Clean up ----------\n",
      "---------- Select and prepare metadata for merging ----------\n",
      "---------- Merge training data ----------\n",
      "---------- Merge testing data ----------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Clean up ----------\")\n",
    "del test, train, full_raw, full\n",
    "\n",
    "print(\"---------- Select and prepare metadata for merging ----------\")\n",
    "test_meta = test_long[['x_t', 'outcome_BMI_fnl']]\n",
    "train_meta = train_long[['x_t', 'outcome_BMI_fnl']]\n",
    "\n",
    "print(\"---------- Merge training data ----------\")\n",
    "train_tax = train_t.merge(train_meta, on='x_t')\n",
    "train_tax = train_tax.drop(['x_t', X_LABEL, 'character_id', 'timepoint'], axis=1)\n",
    "\n",
    "print(\"---------- Merge testing data ----------\")\n",
    "test_tax = test_t.merge(test_meta, on='x_t')\n",
    "test_tax = test_tax.drop(['x_t', X_LABEL, 'character_id', 'timepoint'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bcbede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'g__Parabacteroides_B_862066', 'g__Coprenecus', 'g__Butyricimonas', 'g__Odoribacter_865974', 'g__Alistipes_A_871404', 'g__Paramuribaculum', 'g__Alistipes_A_871400', 'g__Barnesiella', 'g__Coprobacter', 'g__Phocaeicola_A_858004', 'g__Bacteroides_H', 'g__Prevotella', 'g__Paraprevotella', 'g__Methanobrevibacter_A', 'g__DTU012', 'g__Escherichia_710834', 'g__Parasutterella', 'g__Sutterella', 'g__Haemophilus_D_735815', 'g__Enterobacter_B_713587', 'g__Akkermansia', 'g__Eubacterium_O_258270', 'g__Anaerofustis', 'g__Peptococcus', 'g__QAMH01', 'g__Senegalimassilia', 'g__Adlercreutzia_404257', 'g__Slackia_A', 'g__Eggerthella', 'g__CAG.1427', 'g__Gordonibacter', 'g__Collinsella', 'g__Holdemania', 'g__Longibaculum', 'g__Catenibacterium', 'g__Erysipelatoclostridium', 'g__Faecalibacillus', 'g___2', 'g__Holdemanella', 'g__Merdibacter', 'g__Clostridium_AQ', 'g__Amedibacillus', 'g__Longicatena', 'g__Dielma', 'g__Pauljensenia', 'g__Bifidobacterium_388775', 'g__Acidaminococcus', 'g__Phascolarctobacterium_A', 'g__Veillonella_A', 'g__Dialister', 'g__Streptococcus', 'g__Lactococcus_A_346120', 'g__Lacticaseibacillus', 'g__Turicibacter', 'g__Gemella', 'g__Limiplasma', 'g__SFMI01', 'g___3', 'g__Onthenecus', 'g__Copromorpha', 'g__BX12', 'g___4', 'g__Romboutsia_B', 'g__CCUG.7971', 'g__Intestinibacter', 'g__Terrisporobacter', 'g___5', 'g__PeH17', 'g__Clostridium_T', 'g__CAG.269', 'g___6', 'g__CAG.273', 'g__Merdicola', 'g__CAG.41', 'g__Monoglobus', 'g__ER4', 'g___7', 'g__Dysosmobacter', 'g__Vescimonas', 'g__CAG.83', 'g__Limivicinus', 'g__Faecousia', 'g__Agathobaculum', 'g__Lawsonibacter', 'g__Intestinimonas', 'g__Pseudobutyricicoccus', 'g__Evtepia', 'g__Onthomonas', 'g___8', 'g__RUG13077', 'g__Avispirillum', 'g__SFLA01', 'g__WQUU01', 'g__UMGS1071', 'g__Clostridium_A', 'g__Acutalibacter', 'g__UBA1417', 'g__Anaeromassilibacillus', 'g__Hydrogeniiclostridium', 'g__Ruminococcus_E', 'g__UBA5905', 'g__Bittarella', 'g__Fimenecus', 'g__Faecalibacterium', 'g__Gemmiger_A_73129', 'g__Ruthenibacterium', 'g__Ruminiclostridium_E', 'g___9', 'g__CAG.177', 'g__CAG.217', 'g__Angelakisella', 'g__Massilioclostridium', 'g__Phocea', 'g__Anaerotruncus', 'g__Negativibacillus', 'g__UBA1394', 'g__Ruminococcus_C_58660', 'g__Ruminococcus_D', 'g___10', 'g___11', 'g__Anaerotignum_189125', 'g__CAG.274', 'g__Anaerobutyricum', 'g__Eubacterium_I', 'g__Roseburia', 'g__Agathobacter_164117', 'g__Butyribacter', 'g__RUG115', 'g__CAG.45', 'g__Eubacterium_J', 'g__Eubacterium_G', 'g__Howardella', 'g___1', 'g__Anaerostipes', 'g__Coprococcus_A_121497', 'g__CAG.127', 'g__Lachnospira', 'g__Eubacterium_F', 'g__Coprococcus_A_187866', 'g__Catenibacillus', 'g__Frisingicoccus', 'g__Merdisoma', 'g__Marvinbryantia', 'g__Blautia_A_141780', 'g__Blautia_A_141781', 'g__UMGS1375', 'g__Limivivens', 'g__UBA9414', 'g__Oliverpabstia', 'g__Mediterraneibacter_A_155507', 'g__COE1', 'g__Acetatifactor', 'g__CAG.95', 'g__Hungatella_A_128155', 'g__Hungatella_A_127239', 'g__Sellimonas', 'g__Eisenbergiella', 'g__UBA3402', 'g__Scatomonas', 'g__Clostridium_Q_134516', 'g__Faecalimonas', 'g__Ruminococcus_B', 'g__Clostridium_AP', 'g__CAG.317_146760', 'g__Bariatricus', 'g__Muricomes_149725', 'g__Lachnoclostridium_B', 'g__Schaedlerella', 'g__Mediterraneibacter_A_155590', 'g__Lactonifactor', 'g__Enterocloster', 'g__Ventrisoma', 'g__Clostridium_Q_135853', 'g__Clostridium_Q_135822', 'g__Porcincola', 'g__Copromonas', 'g__Ventrimonas', 'g__Dorea_A', 'g__Massilistercora', 'all_samples', 'character_id', 'timepoint', 't', 'x_t']\n",
      "---------- Merge full dataset ----------\n",
      "Columns after merge: ['Unnamed: 0_tax', 'g__Parabacteroides_B_862066', 'g__Coprenecus', 'g__Butyricimonas', 'g__Odoribacter_865974', 'g__Alistipes_A_871404', 'g__Paramuribaculum', 'g__Alistipes_A_871400', 'g__Barnesiella', 'g__Coprobacter', 'g__Phocaeicola_A_858004', 'g__Bacteroides_H', 'g__Prevotella', 'g__Paraprevotella', 'g__Methanobrevibacter_A', 'g__DTU012', 'g__Escherichia_710834', 'g__Parasutterella', 'g__Sutterella', 'g__Haemophilus_D_735815', 'g__Enterobacter_B_713587', 'g__Akkermansia', 'g__Eubacterium_O_258270', 'g__Anaerofustis', 'g__Peptococcus', 'g__QAMH01', 'g__Senegalimassilia', 'g__Adlercreutzia_404257', 'g__Slackia_A', 'g__Eggerthella', 'g__CAG.1427', 'g__Gordonibacter', 'g__Collinsella', 'g__Holdemania', 'g__Longibaculum', 'g__Catenibacterium', 'g__Erysipelatoclostridium', 'g__Faecalibacillus', 'g___2', 'g__Holdemanella', 'g__Merdibacter', 'g__Clostridium_AQ', 'g__Amedibacillus', 'g__Longicatena', 'g__Dielma', 'g__Pauljensenia', 'g__Bifidobacterium_388775', 'g__Acidaminococcus', 'g__Phascolarctobacterium_A', 'g__Veillonella_A', 'g__Dialister', 'g__Streptococcus', 'g__Lactococcus_A_346120', 'g__Lacticaseibacillus', 'g__Turicibacter', 'g__Gemella', 'g__Limiplasma', 'g__SFMI01', 'g___3', 'g__Onthenecus', 'g__Copromorpha', 'g__BX12', 'g___4', 'g__Romboutsia_B', 'g__CCUG.7971', 'g__Intestinibacter', 'g__Terrisporobacter', 'g___5', 'g__PeH17', 'g__Clostridium_T', 'g__CAG.269', 'g___6', 'g__CAG.273', 'g__Merdicola', 'g__CAG.41', 'g__Monoglobus', 'g__ER4', 'g___7', 'g__Dysosmobacter', 'g__Vescimonas', 'g__CAG.83', 'g__Limivicinus', 'g__Faecousia', 'g__Agathobaculum', 'g__Lawsonibacter', 'g__Intestinimonas', 'g__Pseudobutyricicoccus', 'g__Evtepia', 'g__Onthomonas', 'g___8', 'g__RUG13077', 'g__Avispirillum', 'g__SFLA01', 'g__WQUU01', 'g__UMGS1071', 'g__Clostridium_A', 'g__Acutalibacter', 'g__UBA1417', 'g__Anaeromassilibacillus', 'g__Hydrogeniiclostridium', 'g__Ruminococcus_E', 'g__UBA5905', 'g__Bittarella', 'g__Fimenecus', 'g__Faecalibacterium', 'g__Gemmiger_A_73129', 'g__Ruthenibacterium', 'g__Ruminiclostridium_E', 'g___9', 'g__CAG.177', 'g__CAG.217', 'g__Angelakisella', 'g__Massilioclostridium', 'g__Phocea', 'g__Anaerotruncus', 'g__Negativibacillus', 'g__UBA1394', 'g__Ruminococcus_C_58660', 'g__Ruminococcus_D', 'g___10', 'g___11', 'g__Anaerotignum_189125', 'g__CAG.274', 'g__Anaerobutyricum', 'g__Eubacterium_I', 'g__Roseburia', 'g__Agathobacter_164117', 'g__Butyribacter', 'g__RUG115', 'g__CAG.45', 'g__Eubacterium_J', 'g__Eubacterium_G', 'g__Howardella', 'g___1', 'g__Anaerostipes', 'g__Coprococcus_A_121497', 'g__CAG.127', 'g__Lachnospira', 'g__Eubacterium_F', 'g__Coprococcus_A_187866', 'g__Catenibacillus', 'g__Frisingicoccus', 'g__Merdisoma', 'g__Marvinbryantia', 'g__Blautia_A_141780', 'g__Blautia_A_141781', 'g__UMGS1375', 'g__Limivivens', 'g__UBA9414', 'g__Oliverpabstia', 'g__Mediterraneibacter_A_155507', 'g__COE1', 'g__Acetatifactor', 'g__CAG.95', 'g__Hungatella_A_128155', 'g__Hungatella_A_127239', 'g__Sellimonas', 'g__Eisenbergiella', 'g__UBA3402', 'g__Scatomonas', 'g__Clostridium_Q_134516', 'g__Faecalimonas', 'g__Ruminococcus_B', 'g__Clostridium_AP', 'g__CAG.317_146760', 'g__Bariatricus', 'g__Muricomes_149725', 'g__Lachnoclostridium_B', 'g__Schaedlerella', 'g__Mediterraneibacter_A_155590', 'g__Lactonifactor', 'g__Enterocloster', 'g__Ventrisoma', 'g__Clostridium_Q_135853', 'g__Clostridium_Q_135822', 'g__Porcincola', 'g__Copromonas', 'g__Ventrimonas', 'g__Dorea_A', 'g__Massilistercora', 'all_samples', 'character_id', 'timepoint', 't', 'x_t', 'Unnamed: 0_long', 'record_id', 'subject_id', 'randomized_group', 'cohort_number', 'sex', 'race', 'age', 'time', 'Glucose', 'HDL_Total_Direct_lipid', 'HOMA_IR', 'Insulin_endo', 'LDL_Calculated', 'Triglyceride_lipid', 'outcome_BMI_fnl']\n",
      "Final columns after drop: ['Unnamed: 0_tax', 'g__Parabacteroides_B_862066', 'g__Coprenecus', 'g__Butyricimonas', 'g__Odoribacter_865974', 'g__Alistipes_A_871404', 'g__Paramuribaculum', 'g__Alistipes_A_871400', 'g__Barnesiella', 'g__Coprobacter', 'g__Phocaeicola_A_858004', 'g__Bacteroides_H', 'g__Prevotella', 'g__Paraprevotella', 'g__Methanobrevibacter_A', 'g__DTU012', 'g__Escherichia_710834', 'g__Parasutterella', 'g__Sutterella', 'g__Haemophilus_D_735815', 'g__Enterobacter_B_713587', 'g__Akkermansia', 'g__Eubacterium_O_258270', 'g__Anaerofustis', 'g__Peptococcus', 'g__QAMH01', 'g__Senegalimassilia', 'g__Adlercreutzia_404257', 'g__Slackia_A', 'g__Eggerthella', 'g__CAG.1427', 'g__Gordonibacter', 'g__Collinsella', 'g__Holdemania', 'g__Longibaculum', 'g__Catenibacterium', 'g__Erysipelatoclostridium', 'g__Faecalibacillus', 'g___2', 'g__Holdemanella', 'g__Merdibacter', 'g__Clostridium_AQ', 'g__Amedibacillus', 'g__Longicatena', 'g__Dielma', 'g__Pauljensenia', 'g__Bifidobacterium_388775', 'g__Acidaminococcus', 'g__Phascolarctobacterium_A', 'g__Veillonella_A', 'g__Dialister', 'g__Streptococcus', 'g__Lactococcus_A_346120', 'g__Lacticaseibacillus', 'g__Turicibacter', 'g__Gemella', 'g__Limiplasma', 'g__SFMI01', 'g___3', 'g__Onthenecus', 'g__Copromorpha', 'g__BX12', 'g___4', 'g__Romboutsia_B', 'g__CCUG.7971', 'g__Intestinibacter', 'g__Terrisporobacter', 'g___5', 'g__PeH17', 'g__Clostridium_T', 'g__CAG.269', 'g___6', 'g__CAG.273', 'g__Merdicola', 'g__CAG.41', 'g__Monoglobus', 'g__ER4', 'g___7', 'g__Dysosmobacter', 'g__Vescimonas', 'g__CAG.83', 'g__Limivicinus', 'g__Faecousia', 'g__Agathobaculum', 'g__Lawsonibacter', 'g__Intestinimonas', 'g__Pseudobutyricicoccus', 'g__Evtepia', 'g__Onthomonas', 'g___8', 'g__RUG13077', 'g__Avispirillum', 'g__SFLA01', 'g__WQUU01', 'g__UMGS1071', 'g__Clostridium_A', 'g__Acutalibacter', 'g__UBA1417', 'g__Anaeromassilibacillus', 'g__Hydrogeniiclostridium', 'g__Ruminococcus_E', 'g__UBA5905', 'g__Bittarella', 'g__Fimenecus', 'g__Faecalibacterium', 'g__Gemmiger_A_73129', 'g__Ruthenibacterium', 'g__Ruminiclostridium_E', 'g___9', 'g__CAG.177', 'g__CAG.217', 'g__Angelakisella', 'g__Massilioclostridium', 'g__Phocea', 'g__Anaerotruncus', 'g__Negativibacillus', 'g__UBA1394', 'g__Ruminococcus_C_58660', 'g__Ruminococcus_D', 'g___10', 'g___11', 'g__Anaerotignum_189125', 'g__CAG.274', 'g__Anaerobutyricum', 'g__Eubacterium_I', 'g__Roseburia', 'g__Agathobacter_164117', 'g__Butyribacter', 'g__RUG115', 'g__CAG.45', 'g__Eubacterium_J', 'g__Eubacterium_G', 'g__Howardella', 'g___1', 'g__Anaerostipes', 'g__Coprococcus_A_121497', 'g__CAG.127', 'g__Lachnospira', 'g__Eubacterium_F', 'g__Coprococcus_A_187866', 'g__Catenibacillus', 'g__Frisingicoccus', 'g__Merdisoma', 'g__Marvinbryantia', 'g__Blautia_A_141780', 'g__Blautia_A_141781', 'g__UMGS1375', 'g__Limivivens', 'g__UBA9414', 'g__Oliverpabstia', 'g__Mediterraneibacter_A_155507', 'g__COE1', 'g__Acetatifactor', 'g__CAG.95', 'g__Hungatella_A_128155', 'g__Hungatella_A_127239', 'g__Sellimonas', 'g__Eisenbergiella', 'g__UBA3402', 'g__Scatomonas', 'g__Clostridium_Q_134516', 'g__Faecalimonas', 'g__Ruminococcus_B', 'g__Clostridium_AP', 'g__CAG.317_146760', 'g__Bariatricus', 'g__Muricomes_149725', 'g__Lachnoclostridium_B', 'g__Schaedlerella', 'g__Mediterraneibacter_A_155590', 'g__Lactonifactor', 'g__Enterocloster', 'g__Ventrisoma', 'g__Clostridium_Q_135853', 'g__Clostridium_Q_135822', 'g__Porcincola', 'g__Copromonas', 'g__Ventrimonas', 'g__Dorea_A', 'g__Massilistercora', 'all_samples', 't', 'x_t', 'Unnamed: 0_long', 'outcome_BMI_fnl']\n",
      "---------- Clean up ----------\n"
     ]
    }
   ],
   "source": [
    "# Inspect the columns of the tax_full_t DataFrame\n",
    "print(tax_full_t.columns.to_list())\n",
    "\n",
    "# Perform the merge with custom suffixes to prevent 'X.x' and 'X.y'\n",
    "print(\"---------- Merge full dataset ----------\")\n",
    "full = tax_full_t.merge(full_long, on='x_t', how='left', suffixes=('_tax', '_long'))\n",
    "\n",
    "# Check the columns of the merged DataFrame\n",
    "print(\"Columns after merge:\", full.columns.to_list())\n",
    "\n",
    "# Define columns to drop after merge (including Unnamed: 0 if present)\n",
    "columns_to_drop = ['Unnamed: 0', 'X.y', 'X.x', 'randomized_group', 'cohort_number', 'record_id',\n",
    "                  'subject_id', 'character_id', 'cohort_number', 'age', 'race', 'sex', \n",
    "                  'time', 'timepoint', 'HOMA_IR', 'Insulin_endo', 'HDL_Total_Direct_lipid',\n",
    "                  'Glucose', 'LDL_Calculated', 'Triglyceride_lipid']\n",
    "\n",
    "# Drop columns only if they exist in the DataFrame (since some may not be present after merge)\n",
    "full = full.drop([col for col in columns_to_drop if col in full.columns], axis=1)\n",
    "\n",
    "# Check the final columns\n",
    "print(\"Final columns after drop:\", full.columns.to_list())\n",
    "\n",
    "# Clean up unnecessary variables\n",
    "print(\"---------- Clean up ----------\")\n",
    "del train_meta, test_meta, test_t, train_t, test_long, train_long, full_long, tax_full_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36455e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Remove NAs and filter by time ----------\n",
      "---------- Create demo datasets filtered by time ----------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Remove NAs and filter by time ----------\")\n",
    "full_no_na = full.dropna()\n",
    "test_tax_no_na = test_tax.dropna()\n",
    "train_tax_no_na = train_tax.dropna()\n",
    "\n",
    "print(\"---------- Create demo datasets filtered by time ----------\")\n",
    "demo_train = full_no_na[full_no_na['t'].astype(int) < 12]\n",
    "demo_test = full_no_na[full_no_na['t'].astype(int) == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8add04d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Select predictors for training set ----------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = demo_train\n",
    "X = train_set.drop(['t', 'outcome_BMI_fnl', 'all_samples'], axis=1)\n",
    "Y = train_set[['outcome_BMI_fnl']]\n",
    "Y = Y['outcome_BMI_fnl'].to_numpy() # Convert Y to numeric array\n",
    "clusters_train = train_set['all_samples'].to_numpy() # Get ID variables\n",
    "Z = np.ones((train_set.shape[0], 1)) # Create random effects matrix with ones\n",
    "time = train_set['t'].astype(float).to_numpy() # Get time values as numeric array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05ca2120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥° RUN MERF ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥° ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [merf.py:307] Training GLL is 168.59335666183713 at iteration 1.\n",
      "INFO     [merf.py:307] Training GLL is 268.99765560219475 at iteration 2.\n",
      "INFO     [merf.py:307] Training GLL is 306.1788402597862 at iteration 3.\n",
      "INFO     [merf.py:307] Training GLL is 323.4259416169389 at iteration 4.\n",
      "INFO     [merf.py:307] Training GLL is 331.5438569670572 at iteration 5.\n",
      "INFO     [merf.py:307] Training GLL is 333.6258751864621 at iteration 6.\n",
      "INFO     [merf.py:307] Training GLL is 337.0102529050606 at iteration 7.\n",
      "INFO     [merf.py:307] Training GLL is 341.6669153390822 at iteration 8.\n",
      "INFO     [merf.py:307] Training GLL is 340.46053931375917 at iteration 9.\n",
      "INFO     [merf.py:307] Training GLL is 340.96475290141143 at iteration 10.\n",
      "INFO     [merf.py:307] Training GLL is 341.3903734639695 at iteration 11.\n",
      "INFO     [merf.py:307] Training GLL is 340.4433590299796 at iteration 12.\n",
      "INFO     [merf.py:307] Training GLL is 343.5584397651649 at iteration 13.\n",
      "INFO     [merf.py:307] Training GLL is 341.44746305550956 at iteration 14.\n",
      "INFO     [merf.py:307] Training GLL is 338.23835403276945 at iteration 15.\n",
      "INFO     [merf.py:307] Training GLL is 334.72145682868745 at iteration 16.\n",
      "INFO     [merf.py:307] Training GLL is 336.3843427782297 at iteration 17.\n",
      "INFO     [merf.py:307] Training GLL is 334.67535745198626 at iteration 18.\n",
      "INFO     [merf.py:307] Training GLL is 339.8986613521358 at iteration 19.\n",
      "INFO     [merf.py:307] Training GLL is 338.581258697285 at iteration 20.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<merf.merf.MERF at 0x135c52c80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"---------- ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥° RUN MERF ðŸ¥°ðŸ¥°ðŸ¥°ðŸ¥° ----------\")\n",
    "mrf = MERF()\n",
    "mrf.fit(X.select_dtypes(include=[np.number]), Z, pd.Series(clusters_train), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41683c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
