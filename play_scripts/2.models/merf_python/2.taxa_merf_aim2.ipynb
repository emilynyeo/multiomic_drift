{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from merf import MERF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools \n",
    "sns.set_context(\"poster\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (11,8)\n",
    "from merf.merf import MERF\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from merf.viz import plot_merf_training_stats\n",
    "from em_utils import *\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_plots/2.taxa\"\n",
    "df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/2.taxa\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"---------- Read taxonomy data ---------- \")\n",
    "t_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim2_transformed/\"\n",
    "tax_test = read_data(t_dir, \"genus/aim2_clr_testing.csv\")\n",
    "tax_train = read_data(t_dir, \"genus/aim2_clr_training.csv\") \n",
    "tax_full = read_data(t_dir, \"genus/clr_taxa_all.csv\")\n",
    "\n",
    "print(\"---------- Read metadata ----------\")\n",
    "m1_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim2\"\n",
    "test = read_data(m1_dir, \"a2_test_samples_standard_clinical.csv\")\n",
    "train = read_data(m1_dir, \"a2_train_samples_standard_clinical.csv\")\n",
    "full = read_data(m1_dir, \"a2_meta_Transformed_standard_clinical.csv\")\n",
    "full_raw = read_data(m1_dir, \"a2_meta_not_Transformed_standard_clinical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Taxa Input data\n",
    "# FULL dataset\n",
    "# Split X column into character_id and timepoint\n",
    "print(\"---------- Split X column into character_id and timepoint ----------\")\n",
    "tax_full_t = tax_full.copy()\n",
    "X_LABEL = 'Unnamed: 0'\n",
    "print(tax_full_t[X_LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de4fba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_full_t[['character_id', 'timepoint']] = tax_full_t[X_LABEL].str.split('.', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Create time column ----------\")\n",
    "tax_full_t['t'] = create_t_column(tax_full_t)\n",
    "\n",
    "print(\"---------- Create x_t column combining character_id and t ----------\")\n",
    "tax_full_t['x_t'] = tax_full_t['character_id'] + '.' + tax_full_t['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Filter and select columns ----------\")\n",
    "tax = tax_full_t[~tax_full_t['t'].isin(['3', '18'])]\n",
    "tax = tax.drop(['t', 'timepoint', 'character_id', X_LABEL], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Build training dataset ----------\")\n",
    "train_t = tax_train.copy()\n",
    "train_t[['character_id', 'timepoint']] = train_t[X_LABEL].str.split('.', expand=True)\n",
    "train_t['t'] = create_t_column(train_t)\n",
    "train_t['x_t'] = train_t['character_id'] + '.' + train_t['t']\n",
    "train_t = train_t[~train_t['t'].isin(['3', '18'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf42cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Build testing dataset ----------\")\n",
    "test_t = tax_test.copy()\n",
    "test_t[['character_id', 'timepoint']] = test_t[X_LABEL].str.split('.', expand=True)\n",
    "test_t['t'] = create_t_column(test_t)\n",
    "test_t['x_t'] = test_t['character_id'] + '.' + test_t['t']\n",
    "test_t = test_t[~test_t['t'].isin(['3', '18'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6586df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_raw.columns.to_list() == train.columns.to_list())\n",
    "print(train.columns.to_list() == test.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each meta dataset\n",
    "print(\"---------- Convert metadata to long format ----------\")\n",
    "full_long = make_long(full_raw)\n",
    "full_long['x_t'] = full_long['subject_id'].astype(str) + '.' + full_long['time'].astype(str)\n",
    "\n",
    "train_long = make_long(train)\n",
    "train_long['x_t'] = train_long['subject_id'].astype(str) + '.' + train_long['time'].astype(str)\n",
    "\n",
    "test_long = make_long(test)\n",
    "test_long['x_t'] = test_long['subject_id'].astype(str) + '.' + test_long['time'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f861665",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Select and prepare metadata for merging ----------\")\n",
    "full_meta = full_long[['x_t', 'outcome_BMI_fnl']]\n",
    "test_meta = test_long[['x_t', 'outcome_BMI_fnl']]\n",
    "train_meta = train_long[['x_t', 'outcome_BMI_fnl']]\n",
    "print(\"full_meta shape = \", full_meta.shape)\n",
    "\n",
    "print(\"---------- Merge training data ----------\")\n",
    "full_train_tax = train_t.merge(full_meta, on='x_t', how='inner')\n",
    "train_tax = train_t.merge(train_meta, on='x_t')\n",
    "train_tax = train_tax.drop(['x_t', X_LABEL, 'character_id', 'timepoint'], axis=1)\n",
    "print(\"train_tax shape = \", train_tax.shape)\n",
    "print(\"full_train_tax shape = \", full_train_tax.shape)\n",
    "\n",
    "print(\"---------- Merge testing data ----------\")\n",
    "full_test_tax = test_t.merge(full_meta, on='x_t', how='inner')\n",
    "test_tax = test_t.merge(test_meta, on='x_t')\n",
    "test_tax = test_tax.drop(['x_t', X_LABEL, 'character_id', 'timepoint'], axis=1)\n",
    "print(\"test_tax shape = \", test_tax.shape)\n",
    "print(\"full_test_tax shape = \", full_test_tax.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the columns of the tax_full_t DataFrame\n",
    "print(tax_full_t.columns.to_list())\n",
    "\n",
    "# Perform the merge with custom suffixes to prevent 'X.x' and 'X.y'\n",
    "print(\"---------- Merge full dataset ----------\")\n",
    "full = tax_full_t.merge(full_long, on='x_t', how='left', suffixes=('_tax', '_long'))\n",
    "print(\"Columns after merge:\", full.columns.to_list())\n",
    "\n",
    "# Define columns to drop after merge (including Unnamed: 0 if present)\n",
    "columns_to_drop = ['Unnamed: 0', 'X.y', 'X.x', 'randomized_group', 'cohort_number', 'record_id',\n",
    "                  'subject_id', 'character_id', 'cohort_number', 'age', 'race', 'sex', \n",
    "                  'time', 'timepoint', 'HOMA_IR', 'Insulin_endo', 'HDL_Total_Direct_lipid',\n",
    "                  'Glucose', 'LDL_Calculated', 'Triglyceride_lipid']\n",
    "\n",
    "# Drop columns only if they exist in the DataFrame (since some may not be present after merge)\n",
    "full = full.drop([col for col in columns_to_drop if col in full.columns], axis=1)\n",
    "print(\"Final columns after drop:\", full.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36455e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Remove NAs and filter by time ----------\")\n",
    "full_no_na = full.dropna()\n",
    "\n",
    "# Get rows where t is NaN and display them\n",
    "nan_rows = full[full['t'].isna()]\n",
    "print(\"\\nRows with NaN in 't' column:\")\n",
    "print(nan_rows)\n",
    "print(f\"\\nTotal rows with NaN in 't': {len(nan_rows)}\")\n",
    "\n",
    "test_tax_no_na = test_tax.dropna()\n",
    "train_tax_no_na = train_tax.dropna()\n",
    "full_train_tax = full_train_tax.dropna()\n",
    "full_test_tax = full_test_tax.dropna()\n",
    "\n",
    "print(\"test_tax_no_na shape = \", test_tax_no_na.shape)\n",
    "print(\"train_tax_no_na shape = \", train_tax_no_na.shape)\n",
    "print(\"---------- raw train and tax ----------\")\n",
    "print(\"full_train_tax shape = \", full_train_tax.shape)\n",
    "print(\"full_test_tax shape = \", full_test_tax.shape)\n",
    "\n",
    "print(\"---------- Create demo datasets filtered by time ----------\")\n",
    "demo_train = full_no_na[full_no_na['t'].astype(int) < 12]\n",
    "demo_test = full_no_na[full_no_na['t'].astype(int) == 12]\n",
    "print(\"demo_test shape = \", demo_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20f611ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim2_transformed/genus/merf_ready_sets/\"\n",
    "#test_tax_no_na.to_csv(os.path.join(data_dir, 'test_tax_no_na.csv'), index=False)  # Save test_tax_no_na\n",
    "#train_tax_no_na.to_csv(os.path.join(data_dir, 'train_tax_no_na.csv'), index=False)  # Save train_tax_no_na\n",
    "#full_train_tax.to_csv(os.path.join(data_dir, 'full_train_tax.csv'), index=False)  # Save full_train_tax\n",
    "#full_test_tax.to_csv(os.path.join(data_dir, 'full_test_tax.csv'), index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b22e2e",
   "metadata": {},
   "source": [
    "Make train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Select predictors for training set ----------\")\n",
    "train_set = full_train_tax\n",
    "X = train_set.drop(['t', 'outcome_BMI_fnl', 'all_samples'], axis=1)\n",
    "X = X.drop(columns=['Unnamed: 0_tax', 'x_t'], errors='ignore')\n",
    "Y = train_set[['outcome_BMI_fnl']]\n",
    "Y = Y['outcome_BMI_fnl'].to_numpy() # Convert Y to numeric array\n",
    "clusters_train = train_set['all_samples'].to_numpy() # Get ID variables\n",
    "Z = np.ones((train_set.shape[0], 1)) # Create random effects matrix with ones\n",
    "time = train_set['t'].astype(float).to_numpy() # Get time values as numeric array "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e29f7",
   "metadata": {},
   "source": [
    "Make test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Select predictors for test set ----------\")\n",
    "test_set = full_test_tax\n",
    "X_new = test_set.drop(['t', 'outcome_BMI_fnl', 'all_samples'], axis=1)\n",
    "# Drop any unwanted columns and align test set features with training features\n",
    "X_new = test_set.drop(['t', 'outcome_BMI_fnl', 'all_samples'], axis=1)  # Drop non-predictor columns\n",
    "X_new = X_new[X.columns]  # Reorder and select columns to match training set\n",
    "X_new = X_new.astype(X.dtypes)  # Ensure data types match\n",
    "X_new = X_new.drop(columns=['Unnamed: 0_tax', 'x_t'], errors='ignore')\n",
    "X_new = X_new.drop(columns=['Unnamed: 0', 'character_id', 'timepoint'], errors='ignore')\n",
    "\n",
    "\n",
    "Y_new = test_set['outcome_BMI_fnl'].to_numpy()  # Convert Y to numeric array\n",
    "clusters_new = pd.Series(test_set['all_samples'])  # Convert to pandas Series\n",
    "# Create random effects matrix with ones\n",
    "Z_new = np.ones((len(X_new), 1))\n",
    "time_new = test_set['t'].astype(float).to_numpy()  # Convert time values to numeric array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08686072",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- MERF with finetuning RE 🤞🏼 ----------\")\n",
    "\n",
    "train_set = full_train_tax\n",
    "columns_to_drop = ['t', 'outcome_BMI_fnl', 'all_samples', \n",
    "                   'Unnamed: 0_tax', 'x_t', 'character_id', \n",
    "                   'timepoint', 'Unnamed: 0']\n",
    "\n",
    "# Create training features\n",
    "X = train_set.drop(columns=columns_to_drop, errors='ignore')\n",
    "y = train_set[['outcome_BMI_fnl']]\n",
    "y = y['outcome_BMI_fnl'].to_numpy() # Convert Y to numeric array\n",
    "clusters = train_set['all_samples'].to_numpy() # Get ID variables\n",
    "z = np.ones((train_set.shape[0], 1)) # Create random effects matrix with ones\n",
    "\n",
    "# Hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [0.05, 0.1, 0.15],\n",
    "    'max_iter': [2, 10],\n",
    "    'n_splits': [3, 5, 10]  # Added n_splits for cross-validation\n",
    "}\n",
    "\n",
    "best_score = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Initialize a list to store the results of each iteration\n",
    "results = []\n",
    "\n",
    "# Loop through all possible combinations of parameters\n",
    "for params in itertools.product(*param_grid.values()):\n",
    "        n_estimators, max_depth, min_samples_split, max_iter, n_splits = params\n",
    "        print(f\"Combination: {params}\\n\")\n",
    "        scores = []\n",
    "        prev = []\n",
    "        ptev = []\n",
    "        oob_scores = []  # Initialize a list to store OOB scores\n",
    "\n",
    "        # K-fold cross-validation with variable n_splits\n",
    "        kf = KFold(n_splits=n_splits)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]  # Use .iloc for row selection\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            clusters_train, clusters_test = clusters[train_index], pd.Series(clusters[test_index])\n",
    "            z_train, z_test = z[train_index], z[test_index]\n",
    "            model = MERF(\n",
    "                # Specify the fixed effects model as a Random Forest Regressor\n",
    "                fixed_effects_model=RandomForestRegressor(\n",
    "                    n_estimators=n_estimators,  # Number of trees in the forest\n",
    "                    max_depth=max_depth,  # Maximum depth of each tree\n",
    "                    min_samples_split=min_samples_split,  # Minimum samples required to split an internal node\n",
    "                    n_jobs=1,  # Number of jobs to run in parallel\n",
    "                    oob_score=True  # Whether to use out-of-bag samples to estimate the R^2 on unseen data\n",
    "                ),\n",
    "                # Generalized Linear Model (GLM) early stopping threshold\n",
    "                gll_early_stop_threshold=None,  # No early stopping threshold set\n",
    "                # Maximum number of iterations for the MERF algorithm\n",
    "                max_iterations=max_iter  # Maximum number of iterations to run the MERF algorithm\n",
    "            )\n",
    "            model.fit(X_train.select_dtypes(include=[np.number]), z_train, pd.Series(clusters_train), y_train)\n",
    "            y_pred = model.predict(X_test, z_test, clusters_test)\n",
    "            scores.append(np.mean((y_pred - y_test) ** 2)) # MSE\n",
    "            \n",
    "            # Calculate ptev and prev\n",
    "            total_variance = np.var(y_test) #calculates the total variance of the predicted values\n",
    "            random_effect_variance = np.var(y_test - y_pred)  # Variance of residuals\n",
    "            fixed_effect_variance = total_variance - random_effect_variance\n",
    "\n",
    "            ptev.append(np.mean(fixed_effect_variance / total_variance if total_variance > 0 else 0))\n",
    "            prev.append(np.mean(random_effect_variance / total_variance if total_variance > 0 else 0))\n",
    "\n",
    "            # Calculate OOB score\n",
    "            forest = model.trained_fe_model\n",
    "            oob_score = round(forest.oob_score_*100, 1)  # percent variation\n",
    "            oob_scores.append(oob_score)  # Append OOB score to the list\n",
    "\n",
    "            # Print ptev, prev, and OOB score for the current iteration\n",
    "            print(f\"Combination, ptev: {np.mean(ptev):.4f}, prev: {np.mean(prev):.4f}, OOB Score: {oob_score:.4f}\")\n",
    "\n",
    "        # Calculate the mean of the scores for the current combination of parameters\n",
    "        mean_score = np.mean(scores)\n",
    "        mean_prev = np.mean(prev)\n",
    "        mean_ptev = np.mean(ptev)\n",
    "        mean_oob_score = np.mean(oob_scores)  # Calculate the mean of OOB scores\n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = params\n",
    "\n",
    "        # Append the results of the current iteration to the results list\n",
    "        # Create a result dictionary with individual scores and mean scores\n",
    "        result_dict = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'max_iter': max_iter,\n",
    "            'n_splits': n_splits,  # Added n_splits to the result dictionary\n",
    "            'mse_score_1': scores[0] if len(scores) > 0 else None,\n",
    "            'mse_score_2': scores[1] if len(scores) > 1 else None,\n",
    "            'mse_score_3': scores[2] if len(scores) > 2 else None,\n",
    "            'mse_score_4': scores[3] if len(scores) > 3 else None,\n",
    "            'mse_score_5': scores[4] if len(scores) > 4 else None,\n",
    "            'mse_score_6': scores[5] if len(scores) > 5 else None,\n",
    "            'mse_score_7': scores[6] if len(scores) > 6 else None,\n",
    "            'mse_score_8': scores[7] if len(scores) > 7 else None,\n",
    "            'mse_score_9': scores[8] if len(scores) > 8 else None,\n",
    "            'mse_score_10': scores[9] if len(scores) > 9 else None,\n",
    "            'mean_mse_score': mean_score,\n",
    "            'prev_1': prev[0] if len(prev) > 0 else None,\n",
    "            'prev_2': prev[1] if len(prev) > 1 else None,\n",
    "            'prev_3': prev[2] if len(prev) > 2 else None,\n",
    "            'prev_4': prev[3] if len(prev) > 3 else None,\n",
    "            'prev_5': prev[4] if len(prev) > 4 else None,\n",
    "            'prev_6': prev[5] if len(prev) > 5 else None,\n",
    "            'prev_7': prev[6] if len(prev) > 6 else None,\n",
    "            'prev_8': prev[7] if len(prev) > 7 else None,\n",
    "            'prev_9': prev[8] if len(prev) > 8 else None,\n",
    "            'prev_10': prev[9] if len(prev) > 9 else None,\n",
    "            'mean_prev': mean_prev,\n",
    "            'ptev_1': ptev[0] if len(ptev) > 0 else None,\n",
    "            'ptev_2': ptev[1] if len(ptev) > 1 else None,\n",
    "            'ptev_3': ptev[2] if len(ptev) > 2 else None,\n",
    "            'ptev_4': ptev[3] if len(ptev) > 3 else None,\n",
    "            'ptev_5': ptev[4] if len(ptev) > 4 else None,\n",
    "            'ptev_6': ptev[5] if len(ptev) > 5 else None,\n",
    "            'ptev_7': ptev[6] if len(ptev) > 6 else None,\n",
    "            'ptev_8': ptev[7] if len(ptev) > 7 else None,\n",
    "            'ptev_9': ptev[8] if len(ptev) > 8 else None,\n",
    "            'ptev_10': ptev[9] if len(ptev) > 9 else None,\n",
    "            'mean_ptev': mean_ptev,\n",
    "            'oob_1': oob_scores[0] if len(oob_scores) > 0 else None,\n",
    "            'oob_2': oob_scores[1] if len(oob_scores) > 1 else None,\n",
    "            'oob_3': oob_scores[2] if len(oob_scores) > 2 else None,\n",
    "            'oob_4': oob_scores[3] if len(oob_scores) > 3 else None,\n",
    "            'oob_5': oob_scores[4] if len(oob_scores) > 4 else None,\n",
    "            'oob_6': oob_scores[5] if len(oob_scores) > 5 else None,\n",
    "            'oob_7': oob_scores[6] if len(oob_scores) > 6 else None,\n",
    "            'oob_8': oob_scores[7] if len(oob_scores) > 7 else None,\n",
    "            'oob_9': oob_scores[8] if len(oob_scores) > 8 else None,\n",
    "            'oob_10': oob_scores[9] if len(oob_scores) > 9 else None,\n",
    "            'oob_score': mean_oob_score\n",
    "        }\n",
    "        # Append the result dictionary to the results list\n",
    "        results.append(result_dict)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "# Convert the results list to a DataFrame and save it to a CSV file\n",
    "df_dir = \"/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/play_scripts/2.models/merf_python/merf_dfs/2.taxa\"\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{df_dir}/dec6_maggie_params_tuning_raw_taxa_oob.csv', index=False)\n",
    "\n",
    "# this took 130 minutes to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea524214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: \" + str(best_params) + \"\\n\")\n",
    "print(\"Best score: \" + str(best_score) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b34655",
   "metadata": {},
   "source": [
    "    'n_estimators': [100],\n",
    "    'max_depth': [100],\n",
    "    'min_samples_split': [2],\n",
    "    'max_iter': [2, 3, 10, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e66aa0",
   "metadata": {},
   "source": [
    "Once fit, the model can be used to predict on new samples given X, Z, and id's. The predict code handles whether or not to apply the random effect correction based on if the id of the new sample was seen in training or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142786b",
   "metadata": {},
   "source": [
    "Look up longitudinal R - squared values "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
