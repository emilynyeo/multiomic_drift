---
title: "1.meta_aim2"
author: "Emily Yeo"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(knitr, data.table, dplyr, tidyr,readxl,
               readr, car, LongituRF)
```

## Load Data
```{r}
m1_dir <- "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim2"
test <- read.csv(paste(m1_dir, "a2_test_samples_standard_clinical.csv", sep = "/"))
train <- read.csv(paste(m1_dir, "a2_train_samples_standard_clinical.csv", sep = "/"))
full <- read.csv(paste(m1_dir, "a2_meta_Transformed_standard_clinical.csv", sep = "/"))
full_raw <- read.csv(paste(m1_dir, "a2_meta_not_Transformed_standard_clinical.csv", sep = "/"))

full_long <- full_raw %>%
  pivot_longer(
    cols = ends_with(c("BL", "6m", "12m")),  # Select columns that end with BL, 6m, or 12m
    names_to = c(".value", "time"),          # 2 new cols: .value for measurement types & time points
    names_pattern = "(.+)_(BL|6m|12m)") %>%  # Regex to separate measurement type and time point
  mutate(
    time = case_when(
      time == "BL" ~ 0,
      time == "6m" ~ 6,
      time == "12m" ~ 12,
      TRUE ~ as.numeric(time)  # In case there are any unexpected values
    ))

# Looking at NAs
# Find rows with NA values in any column
rows_with_na <- which(apply(full_long, 1, function(row) any(is.na(row))))
na_record_ids <- full_long[rows_with_na, "record_id"]
unique(na_record_ids)
missing <- full_long %>% filter(record_id %in% na_record_ids$record_id)
full_no_na <- full_long %>% filter(!record_id %in% na_record_ids$record_id)
```

Does it allow you to have different number of repeated observations across individuals?
If so, I wonder if you could include all timepoints for the training data and only BL for the test set.?
 
```{r}
demo_train <- full_no_na #%>% filter(time < 12)
demo_test <- full_no_na %>% filter(time == 0)
```

# Long RF {.tabset}

 Nice Tutorial to Follow 

https://www.christopherloan.com/blog/running-longitudinal-random-forests-with-longiturf/

Could try Python:
https://github.com/manifoldai/merf

In the algorithm you're describing, it seems to be an EM (Expectation-Maximization)-like method, iterating between:
- Estimating fixed effects (likely via tree-based methods).
- Estimating random effects and a mean behavior function f.
The algorithm iterates between these steps, updating the estimates of the model parameters each time. The process continues until convergence is reached, meaning:

The estimates of the model parameters (like Z and ω, which might represent random effects or latent variables) are no longer changing significantly.The mean behavior function ff stabilizes, and the likelihood function stops improving (or stops improving beyond a very small margin).

## Set up meta 

#### Convert to long 

unnecessary actually 

```{r}
# Convert to long format
train_long <- train %>%
  pivot_longer(
    cols = ends_with(c("BL", "6m", "12m")),  # Select columns that end with BL, 6m, or 12m
    names_to = c(".value", "time"),          # 2 new cols: .value for measurement types & time points
    names_pattern = "(.+)_(BL|6m|12m)") %>%  # Regex to separate measurement type and time point
  mutate(
    time = case_when(
      time == "BL" ~ 0,
      time == "6m" ~ 6,
      time == "12m" ~ 12,
      TRUE ~ as.numeric(time)  # In case there are any unexpected values
    ))
```

default settings. I’ve commented these out to show you the settings and how to specify it

```{r}
# the predictors you want 
X <- 
  demo_train %>% 
  dplyr::select(
    -time,
    -X, 
    -record_id,
    -subject_id,
    -outcome_BMI_fnl) 

list_dat <- 
  list(
    # predictors, level1 and level2
    X = X, 
    # outcome
    Y = as.numeric(pull(demo_train, outcome_BMI_fnl)), 
    # id variables for each unique school
    id = as.numeric(pull(demo_train, record_id)), 
    # random effects (I'm using only a random intercept)
    Z = as.matrix(rep(1, nrow(demo_train))), 
    # years where wave 1 = 0, wave 2 = 1, wave 3 = 2
    time = as.numeric(pull(demo_train, time)))
```

### MERT 

```{r}
start_time <- proc.time()
mert1 <- 
  MERT(
    X = data.frame(list_dat$X),
    Y = list_dat$Y,
    id = list_dat$id,
    Z = list_dat$Z,
    time = list_dat$time,
    sto = 'OrnUhl', # Ornstein–Uhlenbeck
    #iter = 100, 
    #delta = 0.001)
  )

stop_time <- proc.time()
run_time <- stop_time - start_time
run_time
```

### REEMtree

```{r}
start_time <- proc.time()
reemtree1 <- 
  REEMtree(
    X = data.frame(list_dat$X),
    Y = list_dat$Y,
    id = list_dat$id,
    Z = list_dat$Z,
    time = list_dat$time,
    sto = 'OrnUhl',
    #iter = 100,
    #delta = 0.001
  )
stop_time <- proc.time()
run_time <- stop_time - start_time
run_time
```

### MERF

```{r}
start_time <- proc.time()
merf1 <- 
  MERF(
    X = data.frame(list_dat$X),
    Y = list_dat$Y,
    id = list_dat$id,
    Z = list_dat$Z,
    time = list_dat$time,
    sto = 'OrnUhl',
    #iter = 100,
    #delta = 0.001
    #mtry = ceiling(ncol(data.frame(list_dat$X))/3),
    #ntree = 500
  )
stop_time <- proc.time()
run_time <- stop_time - start_time
run_time
```

```{r}
plot(merf1$Vraisemblance) # evolution of the log-likelihood.
```

# Test Models {.tabset}

### Make test data long 
```{r}
test_long <- test %>%
  pivot_longer(
    cols = ends_with(c("BL", "6m", "12m")),  # Select columns that end with BL, 6m, or 12m
    names_to = c(".value", "time"),          # 2 new cols: .value for measurement types & time points
    names_pattern = "(.+)_(BL|6m|12m)") %>%  # Regex to separate measurement type and time point
  mutate(
    time = case_when(
      time == "BL" ~ 0,
      time == "6m" ~ 6,
      time == "12m" ~ 12,
      TRUE ~ as.numeric(time)  # In case there are any unexpected values
    ))
```

### Prep test data

I don't really get the filter part. 
```{r}
X_test <- 
  demo_test %>% 
  filter(record_id %in% merf1$id) %>% 
  select(
    -time,
    -X, 
    -subject_id,
    -record_id,
    -outcome_BMI_fnl)

list_test <- 
  list(
    X = X_test,
    Y = as.numeric(demo_test %>% filter(record_id %in% merf1$id) %>% pull(outcome_BMI_fnl)),
    id = as.numeric(demo_test %>% filter(record_id %in% merf1$id) %>% pull(record_id)),
    Z = as.matrix(rep(1, nrow(demo_test))), 
    time = demo_test %>% filter(record_id %in% merf1$id) %>% pull(time))
```

The native prediction function from LongituRF removed the predictions for cases that weren’t observed in the data (i.e., schools which didn’t report data before 2018). For that reason, I made the fixed_prediction_function() (below) that creates a data frame of predictions for all cases. The way we predict cases that are new is simply with the fixed effects.

```{r}
fixed_prediction_function <- 
  function(object, X, id, Z, time, new_df, id_var_name, ...)
  {
  `%notin%` <- Negate(`%in%`)
  if("tidyverse" %notin% (.packages())){suppressMessages(library(tidyverse))}
  
  preds_existing <- 
    predict(
      object = object,
      X = X,
      id = id,
      Z = Z,
      time = time)
  
  temp <- 
    new_df %>% 
    filter({{id_var_name}} %notin% object$id) %>% 
    mutate(predictions = predict(object = object$forest, newdata = .))
  
  final_df <- 
    new_df %>% 
    filter({{id_var_name}} %in% object$id) %>% 
    mutate(predictions = preds_existing) %>% 
    bind_rows(temp) %>% 
    select(record_id, predictions)
  return(final_df)
}
```

# {-}

# Make predictions {.tabset}

### First using MERT 
```{r}
predictions_mert_df <- 
  fixed_prediction_function(
    object = mert1,
    X = data.frame(list_test$X),
    id = list_test$id,
    Z = list_test$Z,
    time = list_test$time, 
    new_df = demo_test,
    id_var_name = record_id)

compare_mert <- cbind(predictions_mert_df, demo_test, by = "record_id")
cor(compare_mert$predictions, compare_mert$outcome_BMI_fnl)^2
```

```{r}
# Save summary of the linear model
sum_lm <- summary(lm(predictions ~ outcome_BMI_fnl, data = compare_mert))
coef_lm <- sum_lm$coefficients
plot(compare_mert$outcome_BMI_fnl,
     compare_mert$predictions,
     xlab = "Actual BMI",
     ylab = "Predicted 12 month BMI",
     main = "MERT Predicted and actual 12 month BMI based on BL and 6 month predictors") +
abline(a = coef_lm[1, 1], # Set the abline as the coefficients
       b = coef_lm[2, 1], 
       col = "lightpink",
       lwd = 2) +
mtext(paste0("R^2 = ", round(sum_lm$r.squared, 2),
              ", p-value = ", round(coef_lm[2, 4], 2),
              ", y = ", round(coef_lm[2, 1], 1),
              "x + ", round(coef_lm[1, 1], 2)),
      side = 3, line = 0.5)
```


### REEMtree

```{r}
predictions_reem_df <- 
  fixed_prediction_function(
    object = reemtree1,
    X = data.frame(list_test$X),
    id = list_test$id,
    Z = list_test$Z,
    time = list_test$time, 
    new_df = demo_test,
    id_var_name = record_id)

pred_reem1 <- predict(reemtree1, 
                     X=list_test$X,
                     Z=list_test$Z,
                     id=list_test$id, 
                     time=list_test$time)

compare_reem <- cbind(pred_reem1, demo_test, by = "record_id")

sum_lm <- summary(lm(pred_reem1 ~ outcome_BMI_fnl, data = compare_reem))
coef_lm <- sum_lm$coefficients
plot(compare_reem$outcome_BMI_fnl,
     compare_reem$pred_reem1,
     xlab = "Actual BMI",
     ylab = "Predicted 12 month BMI",
     main = "REEM Predicted and actual 12 month BMI based on BL and 6 month predictors") +
abline(a = coef_lm[1, 1], # Set the abline as the coefficients
       b = coef_lm[2, 1], 
       col = "lightblue",
       lwd = 2) +
mtext(paste0("R^2 = ", round(sum_lm$r.squared, 2),
              ", p-value = ", round(coef_lm[2, 4], 2),
              ", y = ", round(coef_lm[2, 1], 1),
              "x + ", round(coef_lm[1, 1], 2)),
      side = 3, line = 0.5)
```


### using MERF

```{r}
pred.merf1 <- predict(merf1, 
                     X=list_test$X,
                     Z=list_test$Z,
                     id=list_test$id, 
                     time=list_test$time)


# predictions_merf_df <- 
#   fixed_prediction_function(
#     object = merf1,
#     X = data.frame(list_test$X),
#     id = list_test$id,
#     Z = list_test$Z,
#     time = list_test$time, 
#     new_df = demo_test,
#     id_var_name = record_id)

compare_merf <- cbind(pred.merf1, demo_test, by = "record_id")

sum_lm <- summary(lm(pred.merf1 ~ outcome_BMI_fnl, data = compare_merf))
coef_lm <- sum_lm$coefficients
plot(compare_merf$outcome_BMI_fnl,
     compare_merf$pred.merf1,
     xlab = "Actual BMI",
     ylab = "Predicted 12 month BMI",
     main = "MERF Predicted and actual 12 month BMI based on BL and 6 month predictors") +
abline(a = coef_lm[1, 1], # Set the abline as the coefficients
       b = coef_lm[2, 1], 
       col = "lightgreen",
       lwd = 2) +
mtext(paste0("R^2 = ", round(sum_lm$r.squared, 2),
              ", p-value = ", round(coef_lm[2, 4], 2),
              ", y = ", round(coef_lm[2, 1], 1),
              "x + ", round(coef_lm[1, 1], 2)),
      side = 3, line = 0.5)
```


