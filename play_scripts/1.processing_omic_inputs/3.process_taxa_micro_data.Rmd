---
title: "7.imputing_microbiome_data"
author: "Emily Yeo"
date: "`r Sys.Date()`"
output: html_document
---

The purpose of this script is to process the clr taxonomic data. This includes:

1. Removing taxa with below a 10 % prevelance
2. Removing taxa with below % variance
3. Splitting into aim 1 (baseline only) testing and training data frames* 
4. Splitting into aim 2 (all time points) testing and training data frames*

* testing and training was done on a 80 % split that matched the samples split in the meta data processing script. 

Tutorials:
https://mibwurrepo.github.io/Microbial-bioinformatics-introductory-course-Material-2018/set-up-and-pre-processing.html#general-overview

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(knitr, data.table, dplyr, tidyr, tableone, kableExtra, readxl,
               readr, car, RColorBrewer, gridExtra, mlbench, earth, ggplot2, 
               AppliedPredictiveModeling, caret, reshape2, corrplot, stringr,
               summarytools, grid, mice, plyr, mlmRev, cowplot, ape, tibble,
               jtools, broom, patchwork, phyloseq, microbiome, glmnet, ISLR,
               MicrobiomeStat, ANCOMBC, ape, vegan, zCompositions, janitor,
               RColorBrewer, DT, ggpubr, microbiomeutilities, compositions)
```

# Read in Taxonomy data {.tabset}

```{r}
# Phyloseq Object
load("~/projects/research/Stanislawski/BMI_risk_scores/microbiome_rs/data/PhyloseqObj.RData")
# Ancom results 
#load("~/projects/research/Stanislawski/BMI_risk_scores/microbiome_rs/Code_for_ANCOM/emily_acom_outputs/ancom_sig_bmi.04.15.RData")
# Phyloseq species object
load("/Users/emily/projects/research/Stanislawski/BMI_risk_scores/microbiome_rs/data/Genus_Sp_tables.RData")

rm(drift.phy.count.r21116, drift.phy.ra, genus.clr, genus.count, genus.ra,
   sp.ra, sp.count)
```

## Taxa info

```{r}
sps <- summarize_phyloseq(drift.phy.count)
print_ps(drift.phy.count)
```

## Taxa reads by timepoint

```{r}
ntaxa(drift.phy.clr)
ntaxa(drift.phy.count)
nsamples(drift.phy.clr)
nsamples(drift.phy.count)

myTaxa = names(sort(taxa_sums(drift.phy.count), decreasing = TRUE)[1:10])
ex1 = prune_taxa(myTaxa, drift.phy.count)
plot <- plot_tree(ex1, color = "timepoint", 
          label.tips = "Phylum", 
          ladderize = "left", justify = "left" , size = "Abundance")
plot
```

Remove taxa not seen more than 2 times in at least 20% of the samples. 
This protects against an OTU with small mean & trivially large C.V.

```{r message=FALSE, warning=FALSE}
# With clr data - don't think it's accurate to use clr instead of count for this 
GP_clr = filter_taxa(drift.phy.clr, 
                 function(x) sum(x > 3) > (0.1*length(x)), TRUE)
print(paste0("Number of Taxa with at least 3 counts in min of 10% of samples if using CLR: ", ntaxa(GP_clr)))

# With count data
GP_count = filter_taxa(drift.phy.count, 
                 function(x) sum(x > 3) > (0.1*length(x)), TRUE)
print(paste0("Number of Taxa with at least 3 counts in min of 10% of samples if using count: ", ntaxa(GP_count)))

# with core function
# must be detected in at least 3 counts across all samples
ps_ct <- core(drift.phy.count, detection = 3, prevalence = 20 / 100)
print(paste0("Number of Taxa with at least 3 counts in min of 20% of samples using the Core function: ", ntaxa(ps_ct)))
```

## look at variation

Coefficient of variation (C.V), i.e. sd(x)/mean(x)
Filter the taxa using a cutoff of 1.0 for the Coefficient of Variation
So you are selecting taxa based on their variability relative to their mean abundance across samples.

```{r message=FALSE, warning=FALSE}
gpsf_clr = filter_taxa(GP_clr, function(x) sd(x)/mean(x) > 1.0, TRUE)
gpsf_count = filter_taxa(GP_count, function(x) sd(x)/mean(x) > 1.0, TRUE)
gpsf_ps_ct = filter_taxa(ps_ct, function(x) sd(x)/mean(x) > 1.0, TRUE)
print(paste0("Number of Taxa with a coefficient of variation greater than 10 if using clr: ", ntaxa(gpsf_clr)))
print(paste0("Number of Taxa with a coefficient of variation greater than 10 if using count: ", ntaxa(gpsf_count)))
print(paste0("Number of Taxa with a coefficient of variation greater than 10 if using ps_ct: ", ntaxa(gpsf_ps_ct)))
```

log transformations and distribuitions of count data (doing clr instead)

```{r}
p1 <- plot_taxa_cv(gpsf_count, plot.type = "scatter")
p1_count <- p1 + scale_x_log10()
```

## Convert new filtered count df to clr 
First create taxa tables, then make the columns unique by adding a numer to the end of the duplicates, then turn into relative abundance, then transform into clr.
clr from compositions package used. 
center log ratio transformation seems do-able with log(df$count + k) - mean(log(df$count + k)), where k is a small constant. 

```{r warning=FALSE, message=FALSE, include=FALSE}
# For genus
tax_genus <- tax_glom(gpsf_count, "Genus")
genus_filtered_count <- otu_table(tax_genus) 
genus_filtered_count <- t(genus_filtered_count) %>% as.data.frame()
colnames(genus_filtered_count) <- as.data.frame(tax_table(tax_genus))$Genus

# For species
tax_species <- tax_glom(gpsf_count, "Species")
species_filtered_count <- otu_table(tax_species) 
species_filtered_count <- t(species_filtered_count) %>% as.data.frame()
colnames(species_filtered_count) <- as.data.frame(tax_table(tax_species))$Species
```

Some species and taxa genus names are duplicated "S__" and "G__". This function adds
a number to the end of each duplicate.

```{r}
# Function to make column names unique
make_unique_names <- function(names) {
  name_counts <- table(names)  # Create a table of name counts
  occurrence <- integer(length(names)) # Vector to track occurrences
  
  # Loop through each name and assign a unique suffix if necessary
  for (i in seq_along(names)) {
    if (name_counts[names[i]] > 1) {
      occurrence[i] <- sum(names[1:i] == names[i])  # Count occurrences up to current index
      names[i] <- paste0(names[i], "_", occurrence[i])  # Append the occurrence number
    }
  }
  
  # Ensure unique names
  for (i in seq_along(names)) {
    while (sum(names[i] == names) > 1) {
      occurrence[i] <- occurrence[i] + 1
      names[i] <- sub("_\\d+$", "", names[i])  # Remove existing suffix
      names[i] <- paste0(names[i], "_", occurrence[i])  # Append new occurrence number
    }
  }
  return(names)
}

# Apply the function to rename the columns of both dataframes
colnames(genus_filtered_count) <- make_unique_names(colnames(genus_filtered_count))
colnames(species_filtered_count) <- make_unique_names(colnames(species_filtered_count))
```

#### Turn into relative abundance 
```{r}
# first make it relative abundance
Genus_relative_abundance <- genus_filtered_count %>%
  rownames_to_column(var = "subject_id") %>%  # Convert row names to a column
  dplyr::rowwise() %>%
  mutate(total = sum(c_across(g__Parabacteroides_B_862066:`g__Massilistercora`), na.rm = TRUE)) %>%
  mutate(across(g__Parabacteroides_B_862066:`g__Massilistercora`, ~ .x / total)) %>%
  dplyr::select(-total) %>%
  column_to_rownames(var = "subject_id")

Species_relative_abundance <- species_filtered_count %>%
  rownames_to_column(var = "subject_id") %>%  # Convert row names to a column
  dplyr::rowwise() %>%
  mutate(total = sum(c_across(2:265), na.rm = TRUE)) %>%
  mutate(across(2:265, ~ .x / total)) %>%
  dplyr::select(-total) %>%
  column_to_rownames(var = "subject_id")
```

#### Perform CLR transformation
```{r}
species_clr_transformed <- apply(Species_relative_abundance, 2, clr) %>% as.data.frame()
genus_clr_transformed <- apply(Genus_relative_abundance, 2, clr) %>% as.data.frame()
```


## Make it match testing and training sets of metadata

```{r}
train_Transformed  <- fread("/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim1/train_samples_standard_clinical.csv")

test_Transformed  <- fread("/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim1/test_samples_standard_clinical.csv")

a1_T <- fread("/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim1/a1_meta_Transformed_standard_clinical.csv")
```

## Make Taxa data splits 

CTL data has already been center log transformed. So perhaps sticking to that is best. 
CLR for RF. 
16S sometimes wide eye for genus
```{r}
clr_transformed_0 <- genus_clr_transformed 
clr_transformed_0$SampleID <- rownames(clr_transformed)

# CENTER AND SCALE
# Preprocess the data - imputation and scaling 
preProcValues <- preProcess(clr_transformed_0[,1:179], 
                            method = c("scale",
                                       #"center", 
                                       "nzv"),
          thresh = 0.95, # cutoff for cumulative % of variance to be retained by PCA
          pcaComp = NULL, #no. PCA components to keep. If specified, over-rides thresh
          na.remove = TRUE, # should missing values be removed from the calculations
          k = 5, # number of nearest neighbors from training set to use for imputation
          knnSummary = mean, # function to average neighbor values/column during imputation
          #outcome = "outcome_BMI_fnl_BL",
          fudge = 0.2, # a tolerance value: Box-Cox transformation lambda values
          numUnique = 15, # no. unique values y has to estimate Box-Cox transformation
          verbose = TRUE, # a logical: prints a log as the computations proceed
          freqCut = 95/5, # cutoff for ratio of most to 2nd most common value.
          uniqueCut = 10, # cutoff % of distinct values out of no. total samples
          cutoff = 0.85, # a numeric value for the pair-wise absolute correlation cutoff.
          rangeBounds = c(0, 1))


clr_transformed_processed <- predict(preProcValues, clr_transformed_0[, 1:179])
clr_transformed <- cbind(clr_transformed_processed, clr_transformed_0[, 180, drop = FALSE])

dim(clr_transformed)
```

```{r}
# All samples 
sample_names <- rownames(clr_transformed)

# make just baseline
baseline_samples <- rownames(clr_transformed)[grep("\\.BL$", sample_names)] %>% 
  unique()

bl_clr <- clr_transformed[grep("\\.BL$", rownames(clr_transformed)), ]

# Function to process the names BL
process_names_bl <- function(names) {
  bl_names <- grep("\\.BL$", names, value = TRUE) # ending with "BL"
  extracted_numbers_BL <- sub(".*-(\\d+)\\.BL$", 
                           "\\1", bl_names) # Numbers after "-", before "."
  cleaned_numbers_bl <- sub("^0+", "", extracted_numbers_BL) # Remove leading zeros
  cleaned_numbers_bl} # Return the cleaned numbers

# Function to process the names BL
process_names_all <- function(names) {
  all_names <- grep("\\..*$", names, value = TRUE) # all samples 
  extracted_numbers_all <- sub(".*-(\\d+)\\..*$", 
                           "\\1", all_names) 
  cleaned_numbers_all <- sub("^0+", "", extracted_numbers_all) # Remove leading zeros
  cleaned_numbers_all} # Return the cleaned numbers


# Apply the function to the sample names
bl_clr$bl_samples <- process_names_bl(rownames(bl_clr))
clr_transformed$all_samples <- process_names_all(rownames(clr_transformed))

# Make training & testing to match the samples in training and testing of ANCOMBC
training_sample_names <- train_Transformed$record_id
testing_sample_names <- test_Transformed$record_id

# Filter rows in BL_clr that match training and testing samples 
# Step 1: Make column names unique
colnames(bl_clr) <- make.names(colnames(bl_clr), unique = TRUE)
# Step 2: Filter the data
BL_clr_testing <- bl_clr %>% filter(bl_samples %in% testing_sample_names)
BL_clr_training <- bl_clr %>% filter(bl_samples %in% training_sample_names)

# Step 1: Make column names unique
colnames(clr_transformed) <- make.names(colnames(clr_transformed), unique = TRUE)
# Step 2: Filter the data
all_clr_training <- clr_transformed %>% filter(all_samples %in% training_sample_names)
all_clr_testing <- clr_transformed %>% filter(all_samples %in% testing_sample_names)

### Make time column for both
all_clr_training <- all_clr_training %>%
  mutate(time = case_when(grepl("BL", SampleID) ~ 0,
    grepl("6m", SampleID) ~ 6, grepl("12m", SampleID) ~ 12,
    TRUE ~ NA_real_)) # In case there's an unmatched value

all_clr_testing <- all_clr_testing %>%
  mutate(time = case_when(grepl("BL", SampleID) ~ 0,
    grepl("6m", SampleID) ~ 6, grepl("12m", SampleID) ~ 12,
    TRUE ~ NA_real_)) # In case there's an unmatched value
```


## Save files 

```{r}
### Aim 1 files
write.csv(BL_clr_training, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim1_transformed/genus/BL_clr_training_feb20.csv")

write.csv(BL_clr_testing, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim1_transformed/genus/BL_clr_testing_feb20.csv")

write.csv(bl_clr, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim1_transformed/genus/BL_clr_taxa_all_feb20.csv")


### Aim 2 files
write.csv(all_clr_training, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim2_transformed/genus/aim2_clr_training_feb20.csv")

write.csv(all_clr_testing, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim2_transformed/genus/aim2_clr_testing_feb20.csv")

write.csv(clr_transformed, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/taxa/aim2_transformed/genus/clr_taxa_all_feb20.csv")
```


# {-}




