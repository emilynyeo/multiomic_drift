---
title: "8.process_functional_micro_data"
author: "Emily Yeo"
date: "`r Sys.Date()`"
output: html_document
---
The purpose of this script is to process the taxonomic functional gene pathways. This includes:

1. Removing pathways with below a 10 % prevelance
2. Removing pathways with below % variance
2. Center and scale 
3. Splitting into aim 1 (baseline only) testing and training data frames* 
4. Splitting into aim 2 (all time points) testing and training data frames*

* testing and training was done on a 80 % split that matched the samples split in the meta data processing script. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(knitr, data.table, dplyr, tidyr, tableone, kableExtra, readxl,
               readr, car, RColorBrewer, gridExtra, mlbench, earth, ggplot2, 
               AppliedPredictiveModeling, caret, reshape2, corrplot, stringr,
               summarytools, grid, mice, plyr, mlmRev, cowplot, tibble, compositions,
               jtools, broom, patchwork, phyloseq, microbiome, glmnet, ISLR,
               MicrobiomeStat, ANCOMBC, ape, vegan, zCompositions, janitor)
```

# Read in Functional data {.tabset}

Using the Picrust functional data pathways 

```{r}
# picrust outputs 
#ko <- fread("/Users/emily/projects/research/Stanislawski/BMI_risk_scores/picrust2/june7/KO_metagenome_out/pred_metagenome_unstrat_descrip.tsv")

#ko_ab <- fread("/Users/emily/projects/research/Stanislawski/BMI_risk_scores/picrust2/june7/KO_metagenome_out/pred_metagenome_unstrat.tsv")

pathways <- fread("/Users/emily/projects/research/Stanislawski/BMI_risk_scores/picrust2/june7/pathways_out/path_abun_unstrat_descrip.tsv")

# Testing and training meta data 
train_Transformed  <- fread("/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim1/train_samples_standard_clinical.csv")

test_Transformed  <- fread("/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/aim1/test_samples_standard_clinical.csv")
```

remove those with very low variability. Make sure it's normal. Look into CLR transform.
Ask John or Jennifer. 
Micom - standard center scale T

## Split data 

Edit pathway data frame
```{r}
pathways_1 <- pathways[, -1]  # Remove the first column (pathway)
pathways_2 <- t(pathways_1)
pathways_3 <- as.data.frame(pathways_2) %>% 
              row_to_names(1) %>% 
              rownames_to_column("SampleID")

# Only baseline samples
sample_names <- pathways_3$SampleID
baseline_samples <- pathways_3$SampleID[grep("\\.BL$", sample_names)]

# All time samples 
path_all_time <- pathways_3

# Convert all columns except the first one to numeric
path_all_time[-1] <- lapply(path_all_time[-1], as.numeric)

rm(pathways_1, pathways_2, pathways_3, sample_names, sp.clr, sp.count, sp.data)
```

# {-}

# Remove variables with low presence thresholds {.tabset}

```{r}
# Set the threshold for percentage of zeros
threshold <- 0.20

# Calculate the percentage of zeros for each column
zero_percentage <- colSums(path_all_time == 0, na.rm = TRUE) / nrow(path_all_time)

# Keep only columns with less than 20% zeros
path_all_time_cleaned <- path_all_time[, zero_percentage < threshold]

# View the cleaned dataframe
dim(path_all_time_cleaned) # 124 removed 
```

# Center and Scale 

```{r}
# CENTER AND SCALE
# Preprocess the data - imputation and scaling 
preProcValues <- preProcess(path_all_time_cleaned[,2:267], 
                            method = c("scale",
                                       #"center",
                                       "nzv"),
          thresh = 0.95, # cutoff for cumulative % of variance to be retained by PCA
          pcaComp = NULL, #no. PCA components to keep. If specified, over-rides thresh
          na.remove = TRUE, # should missing values be removed from the calculations
          k = 5, # number of nearest neighbors from training set to use for imputation
          knnSummary = mean, # function to average neighbor values/column during imputation
          #outcome = "outcome_BMI_fnl_BL",
          fudge = 0.2, # a tolerance value: Box-Cox transformation lambda values
          numUnique = 15, # no. unique values y has to estimate Box-Cox transformation
          verbose = TRUE, # a logical: prints a log as the computations proceed
          freqCut = 95/5, # cutoff for ratio of most to 2nd most common value.
          uniqueCut = 10, # cutoff % of distinct values out of no. total samples
          cutoff = 0.85, # a numeric value for the pair-wise absolute correlation cutoff.
          rangeBounds = c(0, 1))

path_all_time_cs <- predict(preProcValues, path_all_time_cleaned[,1:267])
dim(path_all_time_cs)
```

## Only baseline

```{r}
path_BL <- path_all_time_cs %>% 
           filter(SampleID %in% baseline_samples)
```

#### Plot only baseline
```{r}
# Reshape the data to long format
long_data_BL <- path_BL %>%
  pivot_longer(cols = -SampleID, 
               names_to = "Pathway", 
               values_to = "pathway_counts")
colnames(long_data_BL)

# Step 1: Identify the top 10 pathways for each SampleID
top_pathways_each_sample <- long_data_BL %>%
  #dplyr::group_by(SampleID, Pathway) %>%
  #summarize(Total_Abundance = sum(Relative_Abundance, na.rm = TRUE), .groups = "drop") %>%
  group_by(SampleID) %>%
  top_n(10, pathway_counts) %>%
  ungroup()

# Step 2: Calculate proportions for the top pathways
proportional_data <- top_pathways_each_sample %>%
  group_by(SampleID) %>%
  mutate(Proportion = pathway_counts / sum(pathway_counts)) %>%
  ungroup()

# Step 3: Create the proportional bar plot
# Select a subset of samples (e.g., first 15)
subset_data <- proportional_data %>%
  filter(SampleID %in% unique(SampleID)[1:100])  # Change 1:15 to whatever range you want

p <- ggplot(subset_data, aes(x = SampleID, y = Proportion, fill = Pathway)) +
  geom_bar(stat = "identity", position = "fill") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Proportion of Top 10 Pathways (First 15 Samples)",
       x = "Sample ID",
       y = "Proportion of Relative Abundance")

# Extract the legend
legend <- get_legend(p + theme(legend.position = "right"))
plot <- p + theme(legend.position = "none")
legend
plot
```

# {-}

# Remove variable with low variance {.tabset}

nearZeroVar diagnoses predictors with 1 unique value (i.e. zero variance predictors) or predictors that are have both of the following characteristics: 

1. Very few unique values relative to sample numbers
2. Ratio of the frequency of the most common value / frequency of the 2nd most common value is large.

checkConditionalX looks at the distribution of the columns of x conditioned on the levels of y and identifies columns of x that are sparse within groups of y.

```{r}
#nzv <- nearZeroVar(path_BL, saveMetrics= TRUE)
#nzv[nzv$nzv,][2:10,]

#nzv_all <- nearZeroVar(path_all_time_cs,
#  freqCut = 95/5, # cutoff ratio of most common value to 2nd most common value
#  uniqueCut = 10, # cutoff % distinct values out of number of total samples
#  saveMetrics = FALSE,
#  names = FALSE,
#  foreach = FALSE,
#  allowParallel = TRUE)

#nzv_BL <- nearZeroVar(path_BL,
#  freqCut = 95/5,
#  uniqueCut = 10,
#  saveMetrics = FALSE,
 # names = FALSE,
#  foreach = FALSE,
#  allowParallel = TRUE)

#path_no_nzv_all <- path_all_time_cs[, -nzv_all]
#path_no_nzv_BL <- path_BL[, -nzv_BL]

# Number of near zero variance variables for just baseline samples 
#length(setdiff(colnames(path_all_time_cs), colnames(path_no_nzv_all)))

# Number of near zero variance variables for just baseline samples 
#length(setdiff(colnames(path_BL), colnames(path_no_nzv_BL)))
```

## Plot

```{r}
# Combine original and transformed data for easy comparison
melted_all <- melt(path_all_time_cs)
melted_BL <- melt(path_BL)

# Plot histograms across all time
ggplot(melted_all, aes(x = value, fill = variable)) + 
    geom_histogram(bins = 30, alpha = 0.5) + 
    ggtitle("Histograms of functional gene pathways across all timepoints") +
    theme_minimal() + 
    theme(legend.position = "none")

# across just baseline samples 
ggplot(melted_BL, aes(x = value, fill = variable)) + 
    geom_histogram(bins = 30, alpha = 0.5) + 
    ggtitle("Histograms of functional gene pathways baseline") +
    theme_minimal() + 
    theme(legend.position = "none")
```

## Density plots 

```{r}
ggplot(melted_all, aes(x = value, color = variable)) +
    geom_density() +
    ggtitle("Density Plots of All Functional Genes Across all Time Points") +
    theme_minimal() + 
    theme(legend.position = "none")

ggplot(melted_BL, aes(x = value, color = variable)) +
    geom_density() +
    ggtitle("Density Plots of All Functional Genes Across just BL") +
    theme_minimal() + 
    theme(legend.position = "none")
```

# Transformations 

Apply log transformation
```{r}
log_all_melt <- path_all_time_cs %>%
  mutate(across(-1, log1p)) %>%  # Apply log1p to all columns except the first
  melt(id.vars = colnames(path_all_time_cs)[1])  # Melt the dataframe, keeping the first column as identifier

log_BL_melt <- path_BL %>%
  mutate(across(-1, log1p)) %>%  # Apply log1p to all columns except the first
  melt(id.vars = colnames(path_BL)[1])  # Melt the dataframe, keeping the first column as identifier
```

Voom SM Normalizations : CLR is ideal for compositional data, while Boom SM normalization is more versatile for adjusting various forms of high-dimensional data.

### clr transformations 

i dont think this should be done. skipping

##### First turn into relative abundance before clr
```{r}
# Replace spaces with underscores in column names
colnames(path_all_time_cs) <- gsub(" ", "_", colnames(path_all_time_cs))
all_path_relative_abundance <- path_all_time_cs %>%
  #rownames_to_column(var = "subject_id") %>%  # Convert row names to a column
  dplyr::rowwise() %>%
  dplyr::mutate(total = sum(c_across(2:267), na.rm = TRUE)) %>%
  dplyr::mutate(across(2:267, ~ .x / total)) %>%
  dplyr::select(-total)# %>%
  #column_to_rownames(var = "SampleID")

# Replace spaces with underscores in column names
colnames(path_BL) <- gsub(" ", "_", colnames(path_BL))
bl_path_relative_abundance <- path_BL %>%
  #rownames_to_column(var = "subject_id") %>%  # Convert row names to a column
  dplyr::rowwise() %>%
  dplyr::mutate(total = sum(c_across(2:267), na.rm = TRUE)) %>%
  dplyr::mutate(across(2:267, ~ .x / total)) %>%
  dplyr::select(-total) #%>%
  #column_to_rownames(var = "SampleID")
```

Purpose: The CLR transformation is primarily used to handle compositional data, where the data represents proportions or parts of a whole (e.g., relative abundances of species)

This transformation helps to stabilize the variance and makes the data more suitable for statistical analysis by removing the effects of the relative scale of measurements.

```{r}
clr_path_all <- all_path_relative_abundance
clr_path_all[,2:267] <- clr(clr_path_all[,2:267])
clr_melt_path_all <- melt(clr_path_all)

clr_path_BL <- bl_path_relative_abundance
clr_path_BL[,2:267] <- clr(clr_path_BL[,2:267])
clr_melt_path_BL <- melt(clr_path_BL)
```

plot clr transformations - don't do 

```{r}
ggplot(clr_melt_path_all, aes(x = value, color = variable)) +
    geom_density() +
    ggtitle("Density Plots of All Functional Genes Across all Time Points") +
    theme_minimal() + 
    theme(legend.position = "none")

ggplot(clr_melt_path_BL, aes(x = value, color = variable)) +
    geom_density() +
    ggtitle("Density Plots of All Functional Genes Baseline") +
    theme_minimal() + 
    theme(legend.position = "none")
```

## Split into training and testing to match meta 

```{r}
# Function to process the names BL
process_names_bl <- function(names) {
  bl_names <- grep("\\.BL$", names, value = TRUE) # ending with "BL"
  extracted_numbers_BL <- sub(".*-(\\d+)\\.BL$", 
                           "\\1", bl_names) # Numbers after "-", before "."
  cleaned_numbers_bl <- sub("^0+", "", extracted_numbers_BL) # Remove leading zeros
  cleaned_numbers_bl} # Return the cleaned numbers

# Function to process the names All
process_names_all <- function(names) {
  all_names <- grep("\\..*$", names, value = TRUE) # all samples 
  extracted_numbers_all <- sub(".*-(\\d+)\\..*$", 
                           "\\1", all_names) 
  cleaned_numbers_all <- sub("^0+", "", extracted_numbers_all) # Remove leading zeros
  cleaned_numbers_all} # Return the cleaned numbers

# Function to process the names, ensuring no mismatches
process_names_all <- function(names) {
  cleaned_numbers_all <- character(length(names)) #vector to store cleaned numbers
  all_names <- grep("\\..*$", names, value = TRUE) #names matching the pattern
  for (i in seq_along(names)) { # Extract numbers and remove leading zeros
    if (names[i] %in% all_names) {
      extracted_number <- sub(".*-(\\d+)\\..*$", "\\1", names[i])
      cleaned_number <- sub("^0+", "", extracted_number)
      cleaned_numbers_all[i] <- cleaned_number
    } else {
      # If the name does not match, keep the original
      cleaned_numbers_all[i] <- names[i]
    }
  }
  return(cleaned_numbers_all)  # Return the cleaned numbers
}
```

### Apply the function 

```{r}
# Apply the function to the sample names
path_BL$bl_samples <- process_names_bl(path_BL$SampleID)
path_all_time_cs$all_samples <- process_names_all(path_all_time_cs$SampleID)

# Make training & testing to match the samples in training and testing of ANCOMBC
training_sample_names <- train_Transformed$record_id
testing_sample_names <- test_Transformed$record_id

# Filter rows in BL_clr that match training and testing samples 
# Step 1: Make column names unique
colnames(path_BL) <- make.names(colnames(path_BL), unique = TRUE)
# Step 2: Filter the data
BL_clr_testing <- path_BL %>% filter(bl_samples %in% testing_sample_names)
BL_clr_training <- path_BL %>% filter(bl_samples %in% training_sample_names)

# Step 1: Make column names unique
colnames(path_all_time_cs) <- make.names(colnames(path_all_time_cs), unique = TRUE)
# Step 2: Filter the data
all_clr_training <- path_all_time_cs %>% filter(all_samples %in% training_sample_names)
all_clr_testing <- path_all_time_cs %>% filter(all_samples %in% testing_sample_names)
```


## Save files 

```{r}
#aim 1 files
write.csv(BL_clr_training, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/functional/aim1/path_bl_clr_training_feb20.csv")
write.csv(BL_clr_testing, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/functional/aim1/path_bl_clr_testing_feb20.csv")
write.csv(clr_path_BL, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/functional/aim1/clr_path_BL_feb20.csv")
# 
# # aim 2 files
write.csv(all_clr_training, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/functional/aim2/all_clr_training_feb20.csv")
write.csv(all_clr_testing, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/functional/aim2/all_clr_testing_feb20.csv")
write.csv(clr_path_all, "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/functional/aim2/clr_taxa_all_feb20.csv")
```





