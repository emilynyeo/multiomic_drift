---
title: "1.the_perfect_meta"
author: "Emily Yeo"
date: "`r Sys.Date()`"
output: html_document
---
http://rismyhammer.com/ml/Pre-Processing.html#imputation

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(knitr, data.table, dplyr, tidyr, tableone, kableExtra, readxl,
               readr, car, RColorBrewer, gridExtra, mlbench, earth, ggplot2, stringr,
               AppliedPredictiveModeling, caret, reshape2, corrplot)
```

# Read in meta data 
used ashleys editted metadata
```{r include=FALSE}
slim <- read.csv("/Users/emily/projects/research/Stanislawski/BMI_risk_scores/new_meta_data/DRIFT_meta_deltas_03.12.2024.csv")

all <- read.csv("/Users/emily/projects/research/Stanislawski/BMI_risk_scores/new_meta_data/DRIFT_meta_longitudinal_03.12.2024.csv")

all_deltas <- read_excel("/Users/emily/projects/research/Stanislawski/BMI_risk_scores/new_meta_data/DRIFT2\ Analysis\ Data\ sets.xlsx", sheet = "longitudinal_delta")

long_survey <- read_excel("/Users/emily/projects/research/Stanislawski/BMI_risk_scores/new_meta_data/DRIFT2\ Analysis\ Data\ sets.xlsx", sheet = "longitudinal_survey")

meta <- read_csv("~/projects/research/Stanislawski/BMI_risk_scores/data/correct_meta_files/ashleys_meta/DRIFT_working_dataset_meta_deltas_filtered_05.21.2024.csv")

# Replace spaces with underscores in column names
colnames(meta) <- gsub(" ", "_", colnames(meta))

# Drop non-consenting individuals 
meta <- meta[meta$consent != "no", ]
```

# Create variables 
Categorize those with metabolic syndrome
```{r include=FALSE}
# Stratify by sex 
meta_male <- meta %>% dplyr::filter(meta$sex == "1")
meta_female <- meta %>% dplyr::filter(meta$sex == "0")

# Glucose, 
meta$met_gluc <- ifelse(meta$Glucose_BL >= 100, 1, 0)
meta$met_tg <- ifelse(meta$Triglyceride_lipid_BL >= 150, 1, 0)
meta$met_bp <- ifelse(meta$avg_systolic_BL >= 130, 1,
                      ifelse(meta$avg_diastolic_BL >= 85, 1, 0))

# Sex diff hdl
meta_female$met_hdl <- ifelse(meta_female$HDL_Total_Direct_lipid_BL <= 50, 1, 0)
meta_male$met_hdl <- ifelse(meta_male$HDL_Total_Direct_lipid_BL <= 40, 1, 0)
# Sex diff waist circ
meta_female$met_wc <- ifelse(meta_female$wc_average_BL >= 89, 1, 0)
meta_male$met_wc <- ifelse(meta_male$wc_average_BL >= 102, 1, 0)

# merge
mf <- meta_female %>% dplyr::select(record_id, met_hdl, met_wc)
mm <- meta_male %>% dplyr::select(record_id, met_hdl, met_wc)
mfm <- rbind(mf, mm)
mmm <- merge(mfm, meta, by = "record_id")

# Calculate the sum of the specified columns and create the new variable
# criteria is greater than 3
mmm$metS_BL <- ifelse(rowSums(mmm[c("met_hdl", "met_wc", "met_gluc", 
                                      "met_tg", "met_bp")]) >= 3, 
                                       1, 0)
meta <- mmm
remove(mmm, mm, mfm, mf, meta_female, meta_male)
table(meta$metS_BL)
```

# Drop and rename variables
Predictor variables will be only baseline for aim 1, and longitudinal for aim 2. That means two separate data sets. 

### Aim 1 data set 
Only baseline clinical variables 
```{r echo=TRUE}
a1_meta <- meta %>% 
  dplyr::select(c(record_id, randomized_group, age, sex, race, cohort_number,
                  ethnicity, job_activity, income, marital_status,
                  height_cm, rmr_kcald_BL, spk_EE_int_kcal_day_BL,
                  WBTOT_FAT_BL, WBTOT_LEANmass_BL, wc_average_BL,
                  avg_systolic_BL, avg_diastolic_BL, C_Reactive_Protein_BL,
                  Cholesterol_lipid_BL, Triglyceride_lipid_BL, 
                  HDL_Total_Direct_lipid_BL, LDL_Calculated_BL,
                  Ghrelin_BL, Leptin_BL, Peptide_YY_BL,
                  Glucose_BL, Hemoglobin_A1C_BL, Insulin_endo_BL, HOMA_IR_BL, 
                  outcome_BMI_fnl_BL))

stand <- meta %>% 
  dplyr::select(c(record_id,
                  age, 
                  sex, 
                  Triglyceride_lipid_BL, 
                  HDL_Total_Direct_lipid_BL, 
                  LDL_Calculated_BL,
                  Glucose_BL, Insulin_endo_BL, 
                  HOMA_IR_BL, 
                  outcome_BMI_fnl_BL))

a1_meta <- stand
# Intervention : IMF = 1 , DCR = 2
head(a1_meta)
```

# Variable distribuitons {.tabset}

## These tabs are kind of exploratory, so scroll

I was just looking at variable correlations, variations, summary stats and PCAs

## Looking at correlations between vars
```{r echo=FALSE, warning=FALSE}
scatterplotMatrix(stand[4:10])
```

```{r echo=FALSE, warning=FALSE}
regVar <- c("age", "income", "HOMA_IR_BL", "spk_EE_int_kcal_day_BL",
            "C_Reactive_Protein_BL", "Ghrelin_BL", "Leptin_BL", "Peptide_YY_BL",
            "Cholesterol_lipid_BL", "Triglyceride_lipid_BL" ,
            "HDL_Total_Direct_lipid_BL", "LDL_Calculated_BL")

regVar2 <- c("age", 
                  "sex", 
                  "Triglyceride_lipid_BL", 
                  "HDL_Total_Direct_lipid_BL", 
                  "LDL_Calculated_BL",
                  "Glucose_BL", "Insulin_endo_BL", 
                  "HOMA_IR_BL", 
                  "outcome_BMI_fnl_BL")

subset_df <- a1_meta %>% dplyr::select(all_of(regVar2))
str(subset_df)

theme1 <- trellis.par.get()
theme1$plot.symbol$col = rgb(.2, .2, .2, .4)
theme1$plot.symbol$pch = 12
theme1$plot.line$col = rgb(1, 0, 0, .7)
theme1$plot.line$lwd <- 2
trellis.par.set(theme1)
featurePlot(x = subset_df, 
            y = a1_meta$outcome_BMI_fnl_BL, 
            plot = "scatter", 
            type = c("p", "smooth"),
            span = .5,
            layout = c(4, 3),
            labels = c("number", "BL BMI"))
```

## Correlation function
The function â€œmosthighlycorrelated()â€? will print out the linear correlation coefficients for each pair of variables in your data set, in order of the correlation coefficient. This lets you see very easily which pair of variables are most highly correlated.
```{r include=FALSE}
mosthighlycorrelated <- function(mydataframe,numtoreport)
  {
     # find the correlations
     cormatrix <- cor(mydataframe)
     # set the correlations on the diagonal or lower triangle to zero,
     # so they will not be reported as the highest ones:
     diag(cormatrix) <- 0
     cormatrix[lower.tri(cormatrix)] <- 0
     # flatten the matrix into a dataframe for easy sorting
     fm <- as.data.frame(as.table(cormatrix))
     # assign human-friendly names
     names(fm) <- c("First.Variable", "Second.Variable","Correlation")
     # sort and print the top n correlations
     head(fm[order(abs(fm$Correlation),decreasing=T),],n=numtoreport)
  }
```

top 10 correlated variables a1 data set
```{r}
mosthighlycorrelated(a1_meta[2:9], 10)
```

## Variable variations

A Profile Plot Function

Another type of plot that is useful is a profile plot, which shows the variation in each of the variables, by plotting the value of each of the variables for each of the samples.  
Function: 
```{r include=FALSE}
makeProfilePlot <- function(mylist, names) {
    require(RColorBrewer)
    
    # Find out how many variables we want to include
    numvariables <- length(mylist)
    
    # Choose 'numvariables' random colors
    colours <- brewer.pal(numvariables, "Set1")
    
    # Find out the minimum and maximum values of the variables
    mymin <- 1e+20
    mymax <- 1e-20
    for (i in 1:numvariables) {
        vectori <- mylist[[i]]
        mini <- min(vectori, na.rm = TRUE)
        maxi <- max(vectori, na.rm = TRUE)
        if (mini < mymin) { mymin <- mini }
        if (maxi > mymax) { mymax <- maxi }
    }
    
    # Initialize empty plot with appropriate limits
    plot(NULL, xlim=c(1, length(mylist[[1]])), ylim=c(mymin, mymax), type="n")
    
    # Plot lines and labels
    for (i in 1:numvariables) {
        vectori <- mylist[[i]]
        namei <- names[i]
        colouri <- colours[i]
        lines(vectori, col=colouri)
        
        lastxval <- length(vectori)
        lastyval <- vectori[length(vectori)]
        
        # Offset label positions to avoid overlap
        text_x <- lastxval * 0.95  # Position near the right edge
        text_y <- mymax - (mymax - lastyval) * 0.05  # Start close to the top
        
        # Add vertical offset to avoid overlap
        vertical_offset <- (i - 1) * 0.05 * (mymax - mymin)
        
        # Adjust the y position for each label
        text_y <- text_y - vertical_offset
        
        # Ensure text is within plot area
        if (text_y < mymin) text_y <- mymin
        
        # Change text color to match the line color
        text(text_x, text_y, namei, col=colouri, cex=0.6, pos=4)
    }
}
```

The arguments to the function are a vector containing the names of the varibles that you want to plot, and a list variable containing the variables themselves.
```{r include=FALSE}
socio <- c("age","race","income","job_activity","marital_status","ethnicity","outcome_BMI_fnl_BL")

blood_bp <- c("avg_systolic_BL", "avg_diastolic_BL", "C_Reactive_Protein_BL",
              "Cholesterol_lipid_BL","Triglyceride_lipid_BL", "outcome_BMI_fnl_BL")

sugar <- c("Glucose_BL", "Hemoglobin_A1C_BL", "Insulin_endo_BL", 
           "HOMA_IR_BL","outcome_BMI_fnl_BL")

hunger <- c("Ghrelin_BL", "Leptin_BL", "Peptide_YY_BL","outcome_BMI_fnl_BL")
body <- c("height_cm", "wc_average_BL", "WBTOT_FAT_BL", "WBTOT_LEANmass_BL","outcome_BMI_fnl_BL")
energy <- c("spk_EE_int_kcal_day_BL", "rmr_kcald_BL","outcome_BMI_fnl_BL")


socio_list <- list(a1_meta$age, a1_meta$race, a1_meta$income, a1_meta$job_activity, 
                   a1_meta$marital_status, a1_meta$ethnicity, a1_meta$outcome_BMI_fnl_BL)

blood_bp_list <- list(a1_meta$avg_systolic_BL, a1_meta$avg_diastolic_BL, 
                      a1_meta$C_Reactive_Protein_BL, a1_meta$Cholesterol_lipid_BL, 
                      a1_meta$Triglyceride_lipid_BL, a1_meta$outcome_BMI_fnl_BL)

sugar_list <- list(a1_meta$Glucose_BL, a1_meta$Hemoglobin_A1C_BL, a1_meta$Insulin_endo_BL, 
                   a1_meta$HOMA_IR_BL, a1_meta$outcome_BMI_fnl_BL)

hunger_list <- list(a1_meta$Ghrelin_BL, a1_meta$Leptin_BL, 
                    a1_meta$Peptide_YY_BL, a1_meta$outcome_BMI_fnl_BL)

body_list <- list(a1_meta$height_cm, a1_meta$wc_average_BL, a1_meta$WBTOT_FAT_BL, 
                  a1_meta$WBTOT_LEANmass_BL, a1_meta$outcome_BMI_fnl_BL)

energy_list <- list(a1_meta$spk_EE_int_kcal_day_BL, a1_meta$rmr_kcald_BL,
                    a1_meta$outcome_BMI_fnl_BL)

stand <- regVar2
stand_list <- list(a1_meta$age, 
                   a1_meta$sex, 
                   a1_meta$Triglyceride_lipid_BL, 
                   a1_meta$HDL_Total_Direct_lipid_BL, 
                   a1_meta$LDL_Calculated_BL,
                   a1_meta$Glucose_BL,
                   a1_meta$Insulin_endo_BL, 
                   a1_meta$HOMA_IR_BL, 
                   a1_meta$outcome_BMI_fnl_BL)
```

variation in standard variables 
```{r}
makeProfilePlot(stand_list, stand)
```

I probably need to scale all my variables before this'll make any sense


## Mean and Std. Dev. 
Function by group
```{r include=FALSE}
printMeanAndSdByGroup <- function(variables,groupvariable)
  {
     # find the names of the variables
     variablenames <- c(names(groupvariable),names(as.data.frame(variables)))
     # within each group, find the mean of each variable
     groupvariable <- groupvariable[,1] # ensures groupvariable is not a list
     means <- aggregate(as.matrix(variables) ~ groupvariable, FUN = mean)
     names(means) <- variablenames
     print(paste("Means:"))
     print(means)
     # within each group, find the standard deviation of each variable:
     sds <- aggregate(as.matrix(variables) ~ groupvariable, FUN = sd)
     names(sds) <- variablenames
     print(paste("Standard deviations:"))
     print(sds)
     # within each group, find the number of samples:
     samplesizes <- aggregate(as.matrix(variables) ~ groupvariable, FUN = length)
     names(samplesizes) <- variablenames
     print(paste("Sample sizes:"))
     print(samplesizes)
  }
```

Mean and Std. by sex
```{r}
printMeanAndSdByGroup(a1_meta[2:10],a1_meta[3])
```

## Standardizations

"If you want to compare different variables that have different units, are very different variances, it is a good idea to first standardize the variables.
For a principal component analysis (PCA), the first principal component would be dominated by the variables which show the largest variances.
Thus, its better to first standardize the variables so that they all have variance 1 and mean 0, and to then carry out the principal component analysis on the standardized data. This would allow us to find the principal components that provide the best low-dimensional representation of the variation in the original data, without being overly biased by those variables that show the most variance in the original data."

You can standardize variables in R using the scale function.
```{r}
scaled_a1 <- as.data.frame(scale(a1_meta[, c(2:10)[-3]])) # don't standardize sex
head(scaled_a1)
```

## PCA 

find the best low-dimensional representation of the variation in a multivariate data set.

https://little-book-of-r-for-multivariate-analysis.readthedocs.io/en/latest/src/multivariateanalysis.html#principal-component-analysis
```{r}
# use standardized variables for PCA
noNA_scaled_a1 <- scaled_a1[complete.cases(scaled_a1), ]
a1_meta_pca <- prcomp(noNA_scaled_a1)
summary(a1_meta_pca)
```

Standard deviation of PCAs
```{r}
a1_meta_pca$sdev
```

Total variance explained by the components
```{r}
sum((a1_meta_pca$sdev)^2) # should be the same as number of variants
```

How many PCA to retain
```{r}
screeplot(a1_meta_pca, type="lines")
```

## Zero & near zero predictors 

In some situations, the data generating mechanism can create predictors that only have a single unique value (i.e. a “zero-variance predictor”). 
For many models (excluding tree-based models), this may cause the model to crash or the fit to be unstable.

Similarly, predictors might have only a handful of unique values that occur with very low frequencies.
```{r}
nzv <- nearZeroVar(scaled_a1, saveMetrics= TRUE)
nzv[nzv$nzv,][2:10,]

dim(a1_meta)

nzv <- nearZeroVar(a1_meta)
filteredDescr <- a1_meta[, -nzv]
dim(filteredDescr)
setdiff(colnames(a1_meta), colnames(filteredDescr))
```

No zero variance predictors

## Linear Dependencies 

The function findLinearCombos uses the QR decomposition of a matrix to enumerate sets of linear combinations (if they exist).
findLinearCombos will return a list that enumerates these dependencies. For each linear combination, it will incrementally remove columns from the matrix and test to see if the dependencies have been resolved. findLinearCombos will also return a vector of column positions can be removed to eliminate the linear dependencies.

```{r}
#noNA_scaled_a1 <- na.omit(scaled_a1)
#comboInfo <- findLinearCombos(scaled_a1)
#comboInfo
```

nothing to remove

# {-}

# Split into training and testing {.tabset}

## Basic

Which is what I am currently doing. Just an 80 /20 split 

```{r}
# Extract the continuous target variable
myTarget <- a1_meta$outcome_BMI_fnl_BL

# Remove the target column from the features
myData <- a1_meta[, !names(a1_meta) %in% "target"]

# Split the data into training and test sets
set.seed(123)  # Set seed for reproducibility

# Calculate the number of training samples (80% of total)
train_size <- floor(0.8 * nrow(myData))
inTrain <- sample(seq(nrow(myData)), size = train_size)

# Create the training and test sets
training <- myData[inTrain, ]
test <- myData[-inTrain, ]

# a1 data training and testing sets
dim(training) # 127, 10
dim(test) # 32, 10

trainTarget <- myTarget[inTrain]
testTarget <- myTarget[-inTrain]
```

## Split based on outcome 

using createDataPartition - haven't tried this 

The function createDataPartition can be used to create balanced splits of the data. If the y argument to this function is a factor, the random sampling occurs within each class and should preserve the overall class distribution of the data.

The list = FALSE avoids returning the data as a list. This function also has an argument, times, that can create multiple splits at once; the data indices are returned in a list of integer vectors. Similarly, createResample can be used to make simple bootstrap samples and createFolds can be used to generate balanced cross–validation groupings from a set of data.

```{r}
set.seed(3456)
trainIndex <- createDataPartition(a1_meta$outcome_BMI_fnl_BL, p = .8, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
a1_meta_Train <- a1_meta[ trainIndex,]
a1_meta_Test  <- a1_meta[-trainIndex,]
```

## Split for time series 
 More relevant for DF 2

# {-}

# Variable transformations using Caret {.tabset}

Transformation & imputation using the preProcess step in the caret package. 
Pre-processing transformation (centering, scaling etc.) is estimated from the training data and applied to any data set with the same variables.

I played around with the settings and thresholds of this function and then looked at what it did to the distribuitions of the data. 

## Impute w/ caret
```{r}
# Preprocess the data - imputation and scaling 
preProcValues <- preProcess(training, 
                            method = c("center", 
                                       "scale", 
                                       "YeoJohnson",
                                       "knnImpute",
                                       "nzv"),
          thresh = 0.95, # cutoff for cumulative % of variance to be retained by PCA
          pcaComp = NULL, #no. PCA components to keep. If specified, over-rides thresh
          na.remove = TRUE, # should missing values be removed from the calculations
          k = 5, # number of nearest neighbors from training set to use for imputation
          knnSummary = mean, # function to average neighbor values/column during imputation
          outcome = "outcome_BMI_fnl_BL",
          fudge = 0.2, # a tolerance value: Box-Cox transformation lambda values
          numUnique = 15, # no. unique values y has to estimate Box-Cox transformation
          verbose = TRUE, # a logical: prints a log as the computations proceed
          freqCut = 95/5, # cutoff for ratio of most to 2nd most common value.
          uniqueCut = 10, # cutoff % of distinct values out of no. total samples
          cutoff = 0.85, # a numeric value for the pair-wise absolute correlation cutoff.
          rangeBounds = c(0, 1)) # 2-element numeric interval for range transformation

# Apply tranformation
train_Transformed <- predict(preProcValues, training)
test_Transformed <- predict(preProcValues, test)
a1_meta_Transformed <- predict(preProcValues, a1_meta)
```

## Differences w/ Caret

Lookiing at the differences in original vs. transformed data

histograms:
```{r echo=FALSE, message=FALSE, warning=FALSE}
training_old <- training %>% 
                dplyr::select(c("age", 
                  "sex", 
                  "Triglyceride_lipid_BL", 
                  "HDL_Total_Direct_lipid_BL", 
                  "LDL_Calculated_BL",
                  "Glucose_BL", "Insulin_endo_BL", 
                  "HOMA_IR_BL", 
                  "outcome_BMI_fnl_BL"))

# Combine original and transformed data for easy comparison
original_melted_training_old <- melt(training_old)
transformed_melted <- melt(train_Transformed)

# Plot histograms
ggplot(original_melted_training_old, aes(x = value, fill = variable)) + 
    geom_histogram(bins = 30, alpha = 0.5) + 
    ggtitle("Histograms of Original Training Data") +
    theme_minimal()

ggplot(transformed_melted, aes(x = value, fill = variable)) + 
    geom_histogram(bins = 30, alpha = 0.5) + 
    ggtitle("Histograms of Transformed Training Data") +
    theme_minimal()
```

density plots
```{r}
# Density plots
ggplot(original_melted_training_old, aes(x = value, color = variable)) +
    geom_density() +
    ggtitle("Density Plots of Original Training Data") +
    theme_minimal()

ggplot(transformed_melted, aes(x = value, color = variable)) +
    geom_density() +
    ggtitle("Density Plots of Transformed Training Data") +
    theme_minimal()
```

Boxplots
```{r}
# Box plots
ggplot(original_melted_training_old, aes(x = variable, y = value, fill = variable)) +
    geom_boxplot() +
    ggtitle("Box Plots of Original Training Data") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(transformed_melted, aes(x = variable, y = value, fill = variable)) +
    geom_boxplot() +
    ggtitle("Box Plots of Transformed Training Data") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

corr heatmaps
```{r}
# Compute correlations
original_cor <- cor(training, use = "pairwise.complete.obs")
transformed_cor <- cor(train_Transformed, use = "pairwise.complete.obs")

# Plot correlation heatmaps
corrplot(original_cor, method = "color", 
         title = "Correlation Heatmap - Original Training Data",
         mar = c(0, 0, 0, 0))
corrplot(transformed_cor, method = "color", 
         title = "Correlation Heatmap - Transformed Training Data",
         mar = c(0, 0, 0, 0))
```
About preProcessing function:
Pre-processing transformation (centering, scaling etc.) can be estimated from the training data and applied to any data set with the same variables.

The operations are applied in this order: zero-variance filter, near-zero variance filter, correlation filter, Box-Cox/Yeo-Johnson/exponential transformation, centering, scaling, range, imputation, PCA, ICA then spatial sign.

k-nearest neighbor imputation is carried out by finding the k closest samples (Euclidian distance) in the training set. Imputation via bagging fits a bagged tree model for each predictor (as a function of all the others). This method is simple, accurate and accepts missing values, but it has much higher computational cost. Imputation via medians takes the median of each predictor in the training set, and uses them to fill missing values. This method is simple, fast, and accepts missing values, but treats each predictor independently, and may be inaccurate.

method: 
a character vector specifying the type of processing. Possible values are:
"BoxCox" - developed for transforming the response variable. Must be positive.
"YeoJohnson" - Similar to the Box-Cox model but can accommodate predictors with zero and/or negative values. 
"expoTrans"- The exponential transformation of Manly can also be used for positive or negative data. 
"center" - Subtracts the mean of the predictor's data (again from the data in x) from the predictor values.
"scale" - Divides by the standard deviation.
"range" - The "range" transformation scales the data to be within rangeBounds. If new samples have values larger or smaller than those in the training set, values will be outside of this range.
"knnImpute" - k-nearest neighbor imputation is carried out by finding the k closest samples (Euclidian distance) in the training set. 
"bagImpute" - Imputation via bagging fits a bagged tree model for each predictor (as a function of all the others). This method is simple, accurate and accepts missing values, but it has much higher computational cost. 
"medianImpute" - Imputation via medians takes the median of each predictor in the training set, and uses them to fill missing values. This method is simple, fast, and accepts missing values, but treats each predictor independently, and may be inaccurate.
"pca" - A warning is thrown if both PCA and ICA are requested. ICA, as implemented by the fastICA package automatically does a PCA decomposition prior to finding the ICA scores.
"ica", 
"spatialSign", 
"corr" - "corr" seeks to filter out highly correlated predictors.
"zv" - identifies numeric predictor columns with a single value (i.e. having zero variance) and excludes them from further calculations.  
"nzv" - "nzv" does the same by applying nearZeroVar exclude "near zero-variance" predictors.
"conditionalX" - For classification, method = "conditionalX" examines the distribution of each predictor conditional on the outcome. If there is only one unique value within any class, the predictor is excluded from further calculations (see checkConditionalX for an example). When outcome is not a factor, this calculation is not executed.

thresh:
a cutoff for the cumulative percent of variance to be retained by PCA. Set to 0.95.

pcaComp:
the specific number of PCA components to keep. If specified, this over-rides thresh


# {-}

# Data summary of transformed {.tabset}

## First looking at the variatioons in the data

```{r}
socio_t <- c("age","race","income","job_activity","marital_status",
             "ethnicity","outcome_BMI_fnl_BL")

blood_bp_t <- c("avg_systolic_BL", "avg_diastolic_BL", "C_Reactive_Protein_BL",
              "Cholesterol_lipid_BL","Triglyceride_lipid_BL", "outcome_BMI_fnl_BL")

sugar_t  <- c("Glucose_BL", "Hemoglobin_A1C_BL", "Insulin_endo_BL", 
              "HOMA_IR_BL","outcome_BMI_fnl_BL")

hunger_t  <- c("Ghrelin_BL", "Leptin_BL", "Peptide_YY_BL","outcome_BMI_fnl_BL")

body_t  <- c("height_cm", "wc_average_BL", "WBTOT_FAT_BL",
             "WBTOT_LEANmass_BL","outcome_BMI_fnl_BL")

energy_t  <- c("spk_EE_int_kcal_day_BL", "rmr_kcald_BL","outcome_BMI_fnl_BL")

socio_list_t  <- list(train_Transformed$age, train_Transformed$race,
                      train_Transformed$income, train_Transformed$job_activity,
                      train_Transformed$marital_status, train_Transformed$ethnicity,
                      train_Transformed$outcome_BMI_fnl_BL)

blood_bp_list_t  <- list(train_Transformed$avg_systolic_BL,
                         train_Transformed$avg_diastolic_BL,
                         train_Transformed$C_Reactive_Protein_BL,
                         train_Transformed$Cholesterol_lipid_BL, 
                         train_Transformed$Triglyceride_lipid_BL,
                         train_Transformed$outcome_BMI_fnl_BL)

sugar_list_t  <- list(train_Transformed$Glucose_BL,
                      train_Transformed$Hemoglobin_A1C_BL,
                      train_Transformed$Insulin_endo_BL, 
                      train_Transformed$HOMA_IR_BL,
                      train_Transformed$outcome_BMI_fnl_BL)

hunger_list_t  <- list(train_Transformed$Ghrelin_BL, train_Transformed$Leptin_BL, 
                    train_Transformed$Peptide_YY_BL,
                    train_Transformed$outcome_BMI_fnl_BL)

body_list_t  <- list(train_Transformed$height_cm, train_Transformed$wc_average_BL,
                     train_Transformed$WBTOT_FAT_BL, 
                     train_Transformed$WBTOT_LEANmass_BL,
                     train_Transformed$outcome_BMI_fnl_BL)

energy_list_t  <- list(train_Transformed$spk_EE_int_kcal_day_BL,
                       train_Transformed$rmr_kcald_BL,
                       train_Transformed$outcome_BMI_fnl_BL)

stand_t <- c("age", "sex", "Triglyceride_lipid_BL", "HDL_Total_Direct_lipid_BL", 
                  "LDL_Calculated_BL", "Glucose_BL", "Insulin_endo_BL", 
                  "HOMA_IR_BL", "outcome_BMI_fnl_BL")

stand_list_t <- list(train_Transformed$age,
                     train_Transformed$sex,
                     train_Transformed$Triglyceride_lipid_BL,
                     train_Transformed$HDL_Total_Direct_lipid_BL,
                     train_Transformed$LDL_Calculated_BL,
                     train_Transformed$Glucose_BL,
                      train_Transformed$Insulin_endo_BL, 
                      train_Transformed$HOMA_IR_BL,
                      train_Transformed$outcome_BMI_fnl_BL)
```


Clinical standard variable transformed variation 
```{r}
makeProfilePlot(stand_list_t, stand_t)
```

## Mean and std. 

```{r}
printMeanAndSdByGroup(train_Transformed[2:10],train_Transformed[3])
```

## Correlation when transformed 

```{r}
mosthighlycorrelated(train_Transformed[2:9], 10) # top 10 most correlated variables
```



# {-}




## Save meta data and splits for samples 

```{r}
#write.csv(train_Transformed, 
#        "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/train_samples_standard_clinical.csv")

#write.csv(test_Transformed, 
#        "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/test_samples_standard_clinical.csv")

#write.csv(a1_meta_Transformed, 
#        "/Users/emily/projects/research/Stanislawski/comps/mutli-omic-predictions/data/clinical/transformed/a1_meta_Transformed_standard_clinical.csv")
```


# Model training with imputed data {.tabset}

### random forest with imputed training data 
 mtry is a hyperparameter that controls the number of variables (predictors) that are randomly selected for consideration at each split in the decision trees that make up the forest.
```{r}
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           repeats = 10, ## k-fold repeated ten times
                           p = 0.80,
                           verboseIter = TRUE,
                           summaryFunction = defaultSummary,
                           selectionFunction = "best",
                           savePredictions = "final")

gbmFit1 <- train(outcome_BMI_fnl_BL ~ ., data = train_Transformed, 
                 method = "rf", 
                 trControl = fitControl,
                 verbose = TRUE)

gbmFit1
plot(gbmFit1)
```

```{r}
gbmFit1$bestTune
head(gbmFit1$results)
```

```{r}
trellis.par.set(caretTheme())
plot(gbmFit1, metric = "Rsquared")
```

```{r}
ggplot(gbmFit1) 
```

### Variable importances

The function automatically scales the importance scores to be between 0 and 100. 
Using scale = FALSE avoids this normalization step.

```{r}
gbmImp <- varImp(gbmFit1, scale = TRUE)
plot(gbmImp)
```

### Feature selections

```{r}
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(train_Transformed[,2:30], 
               train_Transformed[,31], sizes=c(1:16), 
               rfeControl=control)
# summarize the results
print(results)
predictors(results) # list the chosen features
plot(results, type=c("g", "o")) # plot the results
```

### Changing tolerance

Tolerance selects the least complex model within some % tolerance of the best value.
Less complex model based on (x-xbest)/xbestx 100, which is the % difference. 
For example, to select parameter values based on a 12% loss of performance:

```{r}
whichTwoPct <- tolerance(gbmFit1$results, metric = "Rsquared", 
                         tol = 12, maximize = TRUE)  
cat("best model within 12 pct of best:\n")
gbmFit1$results[whichTwoPct,1:6]
```

so then the simpler model is better (just 2 variables)

# {-}

# Put it all together {.tabset}

so the splitting and imputing above can all be combined into the "training" step below. 
For the ranfom forest model, 
- first I'll select the number of folds.
- 2nd will be the trainControl parameters
- lastly will be training 

## folds 

to do 

## trainControl settings 1

Lots of settings here 

```{r eval=FALSE, include=TRUE}
trn_ctrl_1 <- trainControl(method = "cv", # cross val
                         #number = "10", # 10 fold
                         #repeats = 5, # no. complete sets of folds to compute
                         number = ifelse(grepl("cv", "cv"), 10, 25),
                         repeats = ifelse(grepl("[d_]cv$", "cv"), 1, NA),
                         p = 0.80, # the training percentage
                         search = "grid", # tuning parameter grid determination,
                         verboseIter = TRUE, # print log
                         returnData = TRUE, # save data
                         #returnResamp = "all", # resampling summary metrics saved
                         savePredictions = "all", # final would save the optimal
                         classProbs = FALSE, # for classification models 
                         summaryFunction = defaultSummary,
                         selectionFunction = "best", # for best tuning parameter
                         preProcOptions = list("scaling", "centering", "knn",
                                               thresh = 0.95, 
                                               ICAcomp = 3, 
                                               k = 5, freqCut = 95/5, 
                                               uniqueCut = 10, 
                                               cutoff = 0.9),
                         sampling = NULL,
                         index = NULL,
                         indexOut = NULL,
                         indexFinal = NULL,
                         timingSamps = 0,
                         predictionBounds = rep(FALSE, 2),
                         seeds = NA,
                         adaptive = list(min = 5, 
                                         alpha = 0.05, 
                                         method = "gls",
                                         complete = TRUE),
                         trim = FALSE,
                         allowParallel = TRUE)
```

## Train Control 2

```{r eval=FALSE, include=TRUE}
trn_ctrl_2 <- trainControl(
  method = "cv",                  # Use cross-validation
  number = 10,                    # Number of folds
  p = 0.80,                       # % of data used for training (only applicable for some methods)
  search = "grid",                # Grid search for tuning
  verboseIter = TRUE,             # Print iteration details
  returnData = TRUE,              # Return the data used for resampling
  savePredictions = "all",        # Save all predictions
  classProbs = FALSE,             # Whether to compute class probabilities (for classification)
  summaryFunction = defaultSummary,  # Function to summarize model performance
  selectionFunction = "best",     # Select the best tuning parameter
  allowParallel = TRUE)            # Allow parallel processing

# Define trainControl with cross-validation
trn_ctrl_3 <- trainControl(
  method = "cv",                  # Cross-validation
  number = 10,                    # 10-fold cross-validation
  savePredictions = "all",        # Save all predictions
  classProbs = FALSE,             # Not a classification problem
  summaryFunction = defaultSummary,
  allowParallel = TRUE,
  preProcOptions = list("scaling", 
                        "centering", 
                        "knn",
                         thresh = 0.95, 
                         ICAcomp = 3, 
                         k = 5, freqCut = 95/5, 
                         uniqueCut = 10, 
                         cutoff = 0.9)) # Enable parallel processing
```

## Train RF model 

```{r eval=FALSE, include=TRUE}
indep_var = colnames(a1_meta) != "outcome_BMI_fnl_BL"
model_rf = train(x = a1_meta[indep_var], 
                 y = a1_meta$outcome_BMI_fnl_BL,
                 method = "rf",   # Random Forest method
                 metric = "RMSE",                # Performance metric
                 maximize = FALSE,               # Whether to maximize the metric
                 trControl = trn_ctrl_2,           # Control parameters
                 tuneGrid = NULL,                # Grid for tuning parameters
                 tuneLength = 3,
                 preProcess = list("scaling", 
                        "centering", 
                        "knnIm")) # Number of tuning parameters to try

model <- train(x = a1_meta[indep_var], 
               y = a1_meta$outcome_BMI_fnl_BL,             # Outcome variable
               method = "rf",                  # Random Forest method
               metric = "RMSE",                # Performance metric
               maximize = FALSE,               # Whether to maximize the metric
               trControl = trn_ctrl_1,           # Control parameters
               tuneGrid = NULL,                # Grid for tuning parameters
               tuneLength = 3)                # Number of tuning parameters to try

# Train the model
model <- train(
  outcome_BMI_fnl_BL ~ .,         # Formula specifying the outcome
  data = a1_meta,                 # Dataset
  method = "rf",                  # Random forest method
  metric = "RMSE",                # Performance metric
  maximize = FALSE,               # Minimize RMSE
  trControl = trn_ctrl,
)
```


#{-}
_________________________________________________________________________________________
# Ok take 2

I was confused about imputation with k-fold cross validation. 
Should this be done before or after or on each split. 
I decided to follow this tutorial:
https://quantdev.ssri.psu.edu/tutorials/supervised-machine-learning-caret-package
file:///Users/emily/Downloads/Supervised_Machine_Learning_The_Caret_Package.html
http://topepo.github.io/caret/visualizations.html


## 1. Imputing using KNN, also centering & scaling numerical columns 

I dont know if I should do this before splitting data, or within each fold ? 

```{r}
a1_meta_pre <- preProcess(a1_meta, method = c("knnImpute","center","scale"))
a1_meta_imp <-predict(a1_meta_pre, a1_meta)
```











# Take 3

```{r}
library(randomForest)
rf_model <- randomForest(outcome_BMI_fnl_BL ~ ., 
                         data=train_Transformed, importance=TRUE)

# Evaluate the model:
predictions <- predict(rf_model, newdata=test_Transformed)
confusion_matrix <- table(test_Transformed$outcome_BMI_fnl_BL, predictions)
print(confusion_matrix)

# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)

# Feature importance 
importance(rf_model)
varImpPlot(rf_model)
```

